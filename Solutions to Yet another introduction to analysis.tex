\documentclass{article} 
\usepackage{amsmath, mathtools} 
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage[left=1in, right=1in]{geometry}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{float}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\newcounter{chapter}[section] %formatting edited 09/20/20
\newcounter{example}[chapter]

\newcommand{\chapter}[1]{\noindent\indent\large\textbf{\thesection.\refstepcounter{chapter}\thechapter\enspace #1}\addcontentsline{toc}{subsection}{\thesection.\thechapter\enspace #1} \hfill\break\par}

\newcommand{\solution}[1]{\setlength{\hangindent}{\parindent} \indent\indent \textbf{Solution: }#1\hfill\break}

\newcommand{\exercise}[1]{
	
	\refstepcounter{example}
    \hangafter=1
    \setlength{\hangindent}{ 
    	\widthof{
			\large\textbf{Exercise \thesection.\thechapter.\theexample\enspace}
    	}-.5\parindent
    }
    {\setlength{\parindent}{0in}\large\textbf{Exercise \thesection.\thechapter.\theexample\enspace}#1}\hfill\break\par
}

%\title{Brief Article} \author{The Author}
%\maketitle

\begin{document}
\tableofcontents


\newpage
\section{Firm Foundations}
\setcounter{chapter}{1}
\chapter{A fresh beginning}
\exercise{(page 5) By representing two typical rational numbers by $m/n$ and $p/q$, where $m,n,p$ and $q$ are integers, show that the sum, difference, product and quotient of two rational numbers are all rational numbers. (Of course we shall always assume that we will only divide one number by another when the latter one is non-zero).\\ %2/24
\indent Deduce that the sum and difference of a rational number $r$ with an irrational number $s$ gives irrational answers and that the product and quotient of a non-zero rational number $r$ with an irrational number $s$ gives irrational answers.}
\solution{For addition $m/n + p/q = (mq+np)/nq$ which is a rational number. For subtraction $m/n-p/q = (mq-np)/nq$ is a rational number, multiplication is $m/n\times p/q = mp/nq$ and division is $m/n \div p/q = mq/np$ which are all represented by the division of two integers, so a rational number.  \\
\indent Let $r$ be rational and $s$ be irrational. If $r+s = m/n$, a rational number, then we can rewrite $s = m/n-r$ which we just showed is rational. For subtraction $r-s = m/n$ implies $s = m/n + r$ which is the sum of two rational numbers and therefore rational. For multiplication $rs =m/n$ means that $s=m/n\div r$ which is a rational divided by a rational and therefore rational. For division $r/s=m/n$ means $s = r\times m/n$ so again the product is rational. \\
\indent In each case the result contradicts that $s$ is irrational, hence the result of any of the four operations between rational and irrational number always results in an irrational answer.}%reviewed 9/01/20
\exercise{In one of the above examples, $3\frac{1}{7} = 3.142857142857\dots$, with a repeating string of six digits. Show why in the decimal expansion of $m/n$ (where $m$ and $n$ are integers and $n>0$) there is eventually bound to be a recurring 0 or a recurring string of less than $n$ digits.} %2/24
\solution{When dividing two integers $m$ and $n$, the second integer can be regarded as ending in an infinitely repeating sequence of zeroes, for example $n=34$ can be written $n=34.000\dots$. \\ \indent Let the decimal digits of $m$ be noted by $a_1, a_2, \dots, a_k, \dots$ in order from most significant to least significant ending in an infinite sequence of zeroes, and let $a_ia_ja_k$ represent the number that results from concatenating those digits in sequence, i.e. if $a_i = 1$, $a_j=2$ and $a_k=3$ then $a_ia_ja_k = 123$. In the process of dividing $m/n$, the decimal digits of the quotient are generated in order starting from the most significant digit $a_j$ of $m$ such that $n$ is smaller than the number $a_1a_2\dotsb a_j$, that is the number represented by all of the digits up to and including $a_j$. The process of division iterates down the list, taking as $q_1$ the quotient of of $a_1a_2\dotsb a_j$ divided by $n$ less the remainder $b_1$, as $q_2$ the quotient of $b_1a_{j+1}$ divided by $n$ less the remainder $b_2$, and in general $q_i = b_{i-1}a_{j+i-1}$ less the remainder $b_i$. \\ \indent The process of division of $m$ and $n$ will terminate if the process has passed the last non-zero digit and $b_i=0$, the remainder is zero. Because $m$ ends in an infinite number of zeroes, if division does not terminate  it will proceed infinitely following a sequence of remainders $b_i0$ divided by $n$. At this point, if $b_i = b_j$ then the sequence will repeat. Since there are only up to $n-1$ possible remainders of a number divided by $n$, this repeated decimal sequence is at most $n-1$ digits long.}
\exercise{It's a surprising fact that given any positive integer $n$ some multiple of it is of the form $99\dots 9900\dots 00$. For example given the number 74 it turns out that $135\times 74 = 9990$. (Perhaps this is connected with the fact that $$\frac{1}{74} = 0.0135135135135\dots)$$ Prove the general result.} %2/24 
\solution{If you take $1/n$ for an integer $n$ then since it's rational the decimal expansion is always repeating or ending in zeroes. If $1/n$ is repeating, then let $m$ be the non-repeating portion and $r$ be the repeating portion so that $1/n = m + r$. Let $j$ be the number such that $r'=10^jr$ is a repeating sequence of $k$ digits with the form $r'= 0\dotsb000.a_1\dotsb a_ka_1\dotsb a_ka_1\dotsb$. Then $10^kr' - r'$ is a positive integer $i$. Combining the two equations $$ 10^{j+k}/n = 10^{j+k}m +10^kr' \text{\quad and \quad} 10^j/n = 10^jm+r' $$ gives the equation \begin{align*}  10^{j+k}/n - 10^j/n &= 10^{j+k}m - 10^jm + 10^kr' - r' \\ (10^{j+k} - 10^j) &= n(10^{j+k} - 10^j)m  + n i \\ (10^{j+k} - 10^j) &= n [(10^{j+k} - 10^j)m + i]\end{align*}
\indent The expression $(10^{j+k} - 10^j)m + i$ is an integer, such that there is an integer multiple of $n$ that is the difference of two powers of 10, $10^{j+k} - 10^j$ which is of the form $99\dots 9900\dots00.$ \\ 
\indent In the case that the decimal expansion of $1/n$ is not repeating it must end in zeroes, $r=0$. Then with $j$ as defined above, for any integer $k>0$ it is true that $10^{j+k} r = 10^jr = 0$ such that $(10^{j+k} - 10^j) = n[10^{j+k}-10^j)m + 0]$, and a multiple of $n$ gives an integer of the desired form.} %reviewed 9/01/20

\newpage
\chapter{A not-so-simple equation}
\exercise{(page 8) Show that $\sqrt{3}$ and $\sqrt[3] 2$ are not rational} %2/24
\solution{If $\sqrt 3$ is rational it can be written $n/m$ and it has factors $\frac{ab\dots c}{xy\dots z}$ and then $(n/m)^2$ just duplicates the same factors so that $(n/m)^2 = \frac{aabb\dots cc}{xxyy\dots zz}$ and still nothing cancels, so it cannot equal the integer 3. Likewise cubing any rational does not change the factors of the numerator or denominator and so it can't cancel to 2. }%reviewed 9/01/20
\exercise{Are you happy to accept that an eventual conclusion from primary school arithmetic is that every integer larger than 1 can be uniquely expressed as a product of prime numbers? (For example $$1320 = 2\times 3\times 2\times 5\times 11\times 2$$ where obviously the order of the factors is irrelevant.) If so, use this fact to show that if $m$ and $n$ are positive integers then it is impossible to have $m^2 = 2\times n^2$. (Assume that $m$ is the product of $M$ primes, and $n$ the product of $N$ primes, and see what conclusion you come to.)\\
\indent If you're keen, show that if $q$ is a positive integer then the only way that $\sqrt q$ can be rational is when $q$ is a perfect square, in which case $\sqrt q$ is itself an integer.}%2/24
\solution{If $m$ is the product of $M$ primes then $m^2$ is the product of $2M$ primes, and likewise $n^2$ is the product of $2N$ primes. Then $2n^2$ has $2N+1$ primes which is odd and so cannot equal $2M$. So they have different numbers of prime factors and $m^2\neq 2n^2$. \\
\indent Let $q$ is a positive integer and $\sqrt q = m/n$ is rational. If $m$ the product of $M$ primes and $n$ is the product of $N$ primes, $m^2$ and $n^2$ are the products of $M$ and $N$ pairs of primes respectively and after dividing $q=m^2/n^2$ what is left is pairs of primes. Then $q$ is the product of $Q$ pairs of primes such that $\sqrt q$ is the product of $Q$ primes and is an integer.}%reviewed 9/02/20
\exercise{(i) Suppose you are given a positive number $\alpha$ with $\alpha^2 > 2$. Then let $$\beta =\frac{\alpha}{2} + \frac{1}{\alpha}$$ Show that $0<\beta<\alpha$ and that $\beta^2 > 2$. Explain why this shows that there is no smallest positive number whose square is more than 2. \\
\indent (ii) Suppose now that you are given a positive number $\alpha$ with $\alpha^2 <2$. By considering $2/\alpha$ and using (i), show that there is a number $\beta$ with $\beta> \alpha$ and $\beta^2 < 2.$ Deduce that there is no biggest number whose square is less than 2.} %2/24
\solution{(i) First $0<\beta$ since it is the sum of two positive numbers. Then $\alpha^2 > 2$ implies that $\frac{1}{\alpha} < \frac{\alpha}{2}$ so that $$\beta = \frac{\alpha}{2}+\frac{1}{\alpha} < \frac{\alpha}{2} + \frac{\alpha}{2} = \alpha.$$ Then $$\beta^2 = \frac{\alpha^2}{2} + \frac{1}{\alpha^2} + 1 > \frac{2}{2} + \frac{1}{\alpha^2} + 1 = 2+\frac{1}{\alpha^2} > 2.$$ \indent Suppose $\alpha$ is the smallest positive number whose square is greater than 2. Then the number $\beta = \alpha/2 + 1/\alpha$ is another positive number, smaller than $\alpha$ and whose square is still greater than 2. So no such number exists. \\
\indent (ii) For any $\alpha$ such that $\alpha^2<2$, let $\alpha_1 = 2/\alpha$. Then you have $$\alpha_1 = \frac{2}{\alpha} > \alpha > 0$$ and  $$(\alpha_1)^2 = \left(\frac{2}{\alpha}\right)^2 = \frac{2^2}{\alpha^2} > \frac{2^2}{2} = 2.$$ \indent We just showed in part (i) that for any $\alpha_1$ satisfying $\alpha_1 >0$ and $(\alpha_1)^2>2$, there is a $\beta_1$ such that $\beta_1 < \alpha_1$ and $(\beta_1)^2 > 2$. Then for $\beta = 2/\beta_1,$ rearranging the equations gives $$\beta_1 = \frac{2}{\beta}  <  \frac{2}{\alpha} = \alpha_1$$ such that $$\alpha < \beta$$ and $$\beta^2 = \frac{2^2}{(\beta_1)^2} < 2$$ \indent So for any positive number $\alpha$ whose square is less than two there is a larger positive number $\beta$ whose square is also less than two.} %this answer is incorrect - fixed 3/28 [re-fixed and reviewed 9/02/20]

\newpage
\chapter{Piggy-in-the-middle}
\exercise{(page 13) Given any positive number $u$ let $[u]$ denote its 'integer part'. Show that $[u] + 1$ is a positive integer which is larger than $u$. Deduce that the set $\mathbb{N}$ of positive integers has no upper bound.}
\solution{A real number $u$ can be written as a decimal expansion, the integer part plus some non-negative real number less than 1.  Adding one to the integer part of $u$ gives the next largest integer if $u$ is not an integer, and if $u$ is an integer then $[u]+1 = u+1>u$. \\ \indent Suppose $u$ is an upper bound of the set $\mathbb{N}$. Then $[u]+1$ is a positive integer larger than $u$, and $u$ is not an upper bound of $\mathbb{N}$. So the set $\mathbb{N}$ has no upper bound.}
\exercise{(i) Which of these sets are bounded above? What are their suprema? \\ 
\indent $A = $ \{The prime numbers\} \\
\indent $B = $ $\{1/p:  p $ is a prime number \} \\
\indent $C = \{ \frac{1}{2}, \frac{2}{3}, \frac{3}{4}, \frac{4}{5}, \frac{5}{6}, \frac{6}{6}, \frac{7}{8}, \frac{8}{9}, \frac{9}{10},\dots \}$ \\
\indent $D = \{1, \frac{2}{3}, \frac{3}{5}, \frac{4}{7}, \frac{5}{9}, \frac{6}{11}, \frac{7}{13}, \frac{8}{15},\dots \}$ \\
\indent (ii) Show that if $A$ and $B$ are any non-empty sets with $a+b \leq \alpha$ for each $a\in A$ and $b\in B$ then $A$ and $B$ are bounded above and $$\sup A + \sup B \leq \alpha$$}
\solution{(i) The set $A$ is not bounded above, since if $u$ is an upper bound of $A$ then for any integer $n\geq u$, $n!+1$ is a prime number greater than $u$. \\ \indent The set $B$ is bounded above and its supremum is 1/2 since 2 is the smallest prime number. \\ \indent The set $C$ is bounded above and its supremum is 1 since the fraction $n/n+1$ gets arbitrarily close to 1. \\ \indent The set $D$ is bounded above, and its supremum is $1$ which is its largest element. \\
\indent (ii) Firstly $A$ and $B$ are bounded above by $\alpha - b$ and $\alpha - a$ respectively, so the supremum exists. The supremum of $A$ is less than or equal to every other upper bound of $A$, so $a \leq \alpha - b$ for every $a\in A$ and $b\in B$ implies $\sup A \leq \alpha - b$ for every $b\in B$. By the same logic $b \leq \alpha - \sup A$ for every $b \in B$ implies $\sup B \leq \alpha - \sup A$ which gives the desired inequality $\sup A + \sup B \leq \alpha$.}%reviewed 9/02/20
\exercise{(i) Show that a non-empty set $M$ which is bounded below has a biggest lower bound (called the $\textit{infimum}$ and denoted by $\inf M$). \\
\indent (ii) Which of the sets in exercise 2(i) are bounded below? What are their infima? \\ 
\indent (iii) Now let $L$ and $M$ be any non-empty sets with $l \leq m$ for each $l\in L$ and $m\in M$ and such that there is a $\textit{unique}$ number $\alpha$ `between' $L$ and $M$ (i.e. with $l\leq \alpha \leq m$ for each $l\in L$ and $m\in M$). Show that $$\alpha = \sup L = \inf M$$ 
\indent (iv) Let $A$ be a non-empty set which is bounded below and let $B$ be the set $\{-a: a\in A\}$. Show that $B$ is bounded above and that $$\sup B = -\inf A$$} %add 9/02/20 - missed this one on first runthrough? 
\solution{(i) Let $L$ be the set of lower bounds of $M$, by the completeness axiom there is an $\alpha$ such that $l\leq \alpha \leq m$ for each $l\in L$ and $m\in M$.\\
\indent (ii) The set $A$ is bounded below, and the greatest lower bound is 2, the smallest prime. \\ \indent The set $B$ is bounded below by 0; the set of primes is not bounded above, so for any number $1/x$ there is a smaller number $1/p$ with $p>x$. So 0 is the infimum of $B$. \\ \indent The set $C$ is bounded below, and its infimum is $\frac{1}{2}$. Since $n/(n+1)$ increases as $n$ increases, the smallest number in $C$ is when $n = 1$. \\ \indent $D$ is bounded below, and its infimum is also $\frac{1}{2}$ because as $n$ increases, the expression $n/(2n+1)$ decreases and gets arbitrarily close to $1/2$. \\ 
\indent (iii) Since $l\leq m$ for each $l \in L$ and $m\in M$, the set of upper bounds of $L$ includes $M$. Then the supremum of $L$ is such that $\sup L \leq m$ for each $m \in M$ and by definition $\sup L > l$ for each $l\in L$. Then $l \leq \sup L \leq m$ for each $l\in L$ and $m \in M$, and $\sup l=\alpha$. \\
\indent Likewise, $L$ is a subset of the lower bounds of $M$, and the infimum of $M$ satisfies $l \leq \inf M \leq m$ for each $l \in L$ and $m \in M$. Again $\alpha$ is the unique number satisfying that inequality, so $\alpha = \sup L = \inf M$. \\ 
\indent (iv) Let $l$ be a lower bound of $A$. Then $l\leq a$ for $a \in A$ and $-l \geq -a$ for each $-a \in B$. So $B$ is bounded above by $-l$. Likewise if $u$ is an upper bound of $B$ then $u\geq (-a)$ for each $-a\in B$ and $-u \leq a$ for each $a\in a$, so $-u$ is a lower bound of $A$. \\ 
\indent Let $L$ be the set of lower bounds of $A$ and $M$ be the set of upper bounds of $B$. The supremum $\sup B$ satisfies $-a \leq \sup B \leq m$ for each $-a\in B$ and $m\in M$. Then multiplying by -1, $a \geq -\sup B \geq -m$, but $-m$ is a lower bound of $A$, so $a\geq -\sup B \geq l$ for each $a \in A$, and $-\sup B$ is the infimum $\inf A$ as desired.} %9/02/20
\exercise{(i) Let $E$ be a set and consider the following two statements about $E$: \\
\indent (1) there exists a number $b$ with $-b \leq e \leq b$ for all $e \in E$;\\
\indent (2) $E$ is bounded (i.e. bounded above and bounded below).\\
\indent Show that if (1) is true then so is (2), and that if (2) is true then so is (1).\\
\indent (ii) Prove that the union of two bounded sets is bounded. (Remember that the union $E\cup E'$ of the sets $E$ and $E'$ consists of all the elements which were in $E$ or in $E'$ or both.)}
\solution{(i) If (1) is true then $E$ is bounded below by $-b$ and above by $b$. If (2) is true, let $u$ be an upper bound and $l$ be a lower bound of $E$, and choose $b$ as the greater of $|u|$ and $|l|$. Then $b$ satisfies (1). \\
\indent (ii) Let $b$ be an upper bound of $E$ and $b'$ be an upper bound of $E'$. Then the greater of $b$ and $b'$ is an upper bound for $E\cup E'$. Likewise for lower bounds, so the union is bounded.} %reviewed 9/02/20
\exercise{Let $x$ and $y$ be different real numbers and let $0\leq \beta \leq 1$. Show that the number $x + \beta (y-x)$ is between $x$ and $y$. By choosing appropriate values of $\beta$ show that between any two different rational numbers there are both rational numbers and irrational numbers, and that between a rational and an irrational number there is an irrational number.}
\solution{We can rewrite $x + \beta (y-x) = (1-\beta) x + \beta y$ and note that $\beta$ is positive. First if $y<x$, $$(1-\beta) x + \beta y < (1-\beta)x + \beta x = x$$ Also $$ (1-\beta) x  + \beta y > (1-\beta) y + \beta y = y $$ so it is between $x$ and $y$. If $x<y$ then $$(1-\beta)x + \beta y < (1-\beta ) y + \beta y = y$$ and $$(1-\beta) x + \beta y > (1-\beta) x + \beta x = x$$ \indent  Now if $x$ and $y$ are rational, choosing $\beta$ irrational results in the expression evaluating to an irrational number between $x$ and $y$ since the result of the basic arithmetic operations between a rational and irrational number is irrational. On the other hand if $\beta$ is rational then the expression evaluates to a rational number between $x$ and $y$.\\
\indent If one of $x$ or $y$ is irrational then regardless of whether $\beta$ is rational or irrational the arithmetic operations in the expression produce an irrational number between $x$ and $y$.}%reviewed 9/02/20 
\exercise{One of the following school exercises is wrong: which one, and why?\\
\indent (i) The attendance at a football match is 23 000 to the nearest thousand. What is the largest number of people that could have been at the match?\\
\indent (ii) An angle is measured to the nearest degree and found to be 48. What is the largest possible value of the angle?}
\solution{The second problem is wrong since angles are real numbers and there's no largest real number less than 48.5. People are integers so there is a largest integer less than 23 500, which is 23 499.}%reviewed 9/02/20

\newpage
 %2/26
\chapter{Some natural consequences} 
\exercise{(page 18) Which of the following sets has a maximum member and which has a minimum member?}
\begin{itemize} \item $\varnothing = $ the empty set \item $A = \{x\in \mathbb{Q}: 1\leqslant x \leqslant \sqrt{2}\}$ \item $B =\{1/p: p$ is a prime $\}$ \item $C = \{1, 1+ \frac{1}{2}, 1 + \frac{1}{2} + \frac{1}{4}, 1+\frac{1}{2} + \frac{1}{4} + \frac{1}{8}, \dots \}$ \item $D = \{1, 1-\frac{1}{3}, 1-\frac{1}{3}-\frac{1}{9},\dots\}$ \end{itemize}
\solution{The empty set has no maximum and no minimum. Set $A$ has a minimum, 1, but no maximum. Set $B$ has a maximum, 1/2, but no minimum. Set $C$ has a minimum, 1, but no maximum. Set $D$ has a maximum of 1 but no minimum.}%reviewed 9/02/20
\exercise{Show that if a set has a maximum member then it has a supremum which is contained in the set. Conversely show that if the set has a supremum which is contained in it then the set has a maximum member.} 
\solution{If $x$ is the maximum of a set $A$ then $x\geq a$ for every $a\in A$ and $x\in A$. Hence $x$ is an upper bound of $A$, and since $x\in A$ there does not exist an upper bound $u$ such that $u<x$ or else $u$ would not be an upper bound, so $x$ is the supremum of $A$. \\ 
\indent If $x$ is the supremum of $A$ and $x\in A$ then by definition $x\geq a \in A$ and $x$ is the maximum element of $A$.}%reviewed 9/02/20
\exercise{Let $x$ and $y$ be real numbers with $y> x+1$. By considering the largest member of the set $$\{n\in \mathbb{Z}:  n<y\}$$ show that there exists an integer between $x$ and $y$}
\solution{Since $[y-1]<y$ the set is nonempty, and it has a largest member. Its largest member is less than y because it is a member of the set, and if it were less than or equal to $x$, then $x+1$ would be an larger integer which is a member of the set, which is a contradiction. So there exists a largest member of the set and it is an integer between $x$ and $y$.}%reviewed 9/02/20
\exercise{We shall now try to establish that between any two different numbers there is a rational number. Suppose that $x$ and $y$ are two real numbers with $x<y$. Let $N$ be an integer chosen with $N> 1/(y-x)$. Use the previous exercise to show that there exists an integer $M$ with $Nx < M < Ny$ and deduce that there is a rational number between $x$ and $y$.}
\solution{Since $Nx < Ny$ and $N(y-x) > 1$ (which means that $Ny > 1+ Nx$), there is an integer $M$ such that $Nx < M < Ny$. Then $x < M/N < y$.}%reviewed 9/02/20
\exercise{Prove by induction that for each positive integer $n$ $$(i) \frac{1}{1\times 2} + \frac{1}{2\times 3} +\dotsb + \frac{1}{n(n+1)} = 1 - \frac{1}{n+1}$$ $$(ii) 1^2 + 2^2 + 3^2 + \dotsb + n^2 = \tfrac{1}{6} n(n+1)(2n+1)$$} 
\solution{(i) For $n=1$ we get $\frac{1}{1\times 2} = \frac{1}{2} = 1- \frac{1}{1+1}.$ In general if it holds for $n$ then $$\frac{1}{1\times 2} + \dotsb + \frac{1}{n(n+1)} + \frac{1}{(n+1)(n+2)} = \left(1 - \frac{1}{n+1}\right) +\frac{1}{(n+1)(n+2)}$$ which gives $1-\tfrac{1}{n+2}$ and the inductive hypothesis holds. \\
\indent (ii) For $n = 1$, $1^2 = 1 = \tfrac{1}{6}1(1+1)(2\times 1+1)= \tfrac{1}{6}(3)(2) = 1.$ If the result holds for $n-1$ then for $n$,  $$1^2 + \dotsb + (n-1)^2 + n^2 = \left[\tfrac{1}{6}(n-1)n(2n-1)\right] + n^2$$ and the right hand side simplifies to \begin{align*} \tfrac{1}{6}n (2n^2 - 3n + 1) + n^2 &= \tfrac{1}{6}n( 2n^2 - 3n + 1 + 6n) \\&= \tfrac{1}{6}n(2n^2 +3n +1)\\&=\tfrac{1}{6}n(n+1)(2n+1)\end{align*} as desired.}%reviewed 9/02/20
\exercise{Prove by induction that for each positive integer $n$ $$\text{(i)}\quad (1+x)^n \geqslant 1 + nx$$ where $x$ is any number with $x\geqslant -1$. This result is known as \textit{Bernoulli's inequality} and is credited to Jacob Bernoulli, one of a great Swiss mathematical family of the seventeenth and eighteenth centuries. $$\text{(ii)} \quad (1+x)^n = \binom{n}{0} + \binom{n}{1}x + \dotsb + \binom{n}{r} x^r + \dotsb \binom{n}{n}x^n$$ where $x$ is any number.} %2/26
\solution{(i) If $n =1$ then $1+x \geq 1 +x $ for all $x$ (including those $x\geqslant -1$). Now if it holds for $n-1$ then $(1+x)^{n-1} \geqslant 1 + (n-1)x = 1 + nx-x$ so that \begin{align*}(1+x)^n &= (1+x)(1+x)^{n-1}\\ &\geqslant (1+x)(1+nx-x)\\&=1+nx-x+x+nx^2-x^2 \\&= 1 + nx + x^2(n-1)\end{align*} which is greater than $1+nx$ when $x\geqslant -1$.\\
\indent (ii) When $n=1$ it is true that $1+x =\binom{n}{0} +\binom{n}{1}x$, and if the result holds for $n-1$ then \begin{align*} (1+x)^{n} &= (1+x)(1+x)^{n-1}\\ &= (1+x)(\binom{n-1}{0} + \dotsb + \binom{n-1}{n-1}x^n)\\&=\binom{n-1}{0}  + \dots + \left(\binom{n-1}{r}+ \binom{n-1}{r-1}\right)x^r + \dotsb + \binom{n-1}{n-1}x^n\\&=\binom{n}{0} + \binom{n}{1}x +\dotsb +\binom{n}{r}x^r + \dotsb + \binom{n}{n}x^n\end{align*} which simplifies to the desired result using the fact that $\binom{n-1}{0} = \binom{n}{0} = 1$, $\binom{n-1}{n-1} = \binom{n}{n} = 1$, and $\binom{n-1}{r-1} + \binom{n-1}{r} = \binom {n}{r}$.}%reviewed 9/02/20 
\exercise{Prove by induction that for each positive integer $n$ \begin{align*}\text{(i)} &\quad 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \dots + \frac{1}{2^{n-1}} \geqslant \frac{1}{2} (n+1)\\ \text{(ii)}&\quad 1 + \frac{1}{2^r} + \frac{1}{3^r} + \frac{1}{4^r} + \frac{1}{5^r} + \dots + \frac{1}{(2^n-1)^r} \leqslant \frac{1-\left(\tfrac{1}{2}\right)^{(r-1)n}}{1-\left(\tfrac{1}{2}\right)^{r-1}} (r\neq 1)\end{align*}} %2/26
\solution{(i) For $n=1$, we have that $\tfrac{1}{2^0} = 1 = \tfrac{1}{2}(1 +1)$ and the result holds. If it is true for $n-1$, then $$1 + \dots + \frac{1}{2^{n-2}} \geqslant \frac{1}{2}\cdot n$$ and we have that \begin{align*}1 + \dots + \frac{1}{2^{n-1}} &= 1 + \dots + \frac{1}{2^{n-2}} + \dots + \frac{1}{2^{n-1}}\\  &\geq \frac{n}{2} + \frac{1}{2^{n-2}+1} + \dots + \frac{1}{2^{n-1}} \\&\geq \frac{n}{2} + \frac{1}{2^{n-1}} (2^{n-2}) \\&= \frac{n}{2} + \frac{1}{2} \\&= \frac{1}{2} (n+1) \end{align*} which is the desired result. \\
\indent (ii) When $n=1$ we have $$1 \leqslant \frac{1-(\tfrac{1}{2})^{(r-1)}}{1-(\tfrac{1}{2})^{r-1}} = 1$$ so it is true in the base case. Assuming that it holds in the $n-1$ case, there are two sums: $$\left(1 + \frac{1}{2^r} + \frac{1}{3^r} +\frac{1}{4^r} + \dots + \frac{1}{(2^{n-1}-1)^r}\right) + \left(\frac{1}{(2^{n-1})^r} + \dots + \frac{1}{(2^n-1)^r}\right).$$ 
\indent For the left sum we use the induction hypothesis and for the right sum, we have $2^{n-1}$ terms, and every term is less than or equal to $\tfrac{1}{(2^{n-1})^r}$. So the total of the second sum is less than or equal to $2^{n-1}\tfrac{1}{(2^{n-1})^r} = \tfrac{1}{2^{(n-1)(r-1)}}$. Then we can say the whole sum is $$\leqslant \frac{1-\left(\frac{1}{2}\right)^{(r-1)(n-1)}}{1-\left(\frac{1}{2}\right)^{r-1}} + \left(\frac{1}{2}\right)^{(r-1)(n-1)} = \frac{1-(\frac{1}{2})^{(r-1)n}}{1-(\frac{1}{2})^{r-1}}$$ as desired.}%reviewed 9/02/20

\newpage
 %2/26
\chapter{Some loose ends}
\exercise{(page 22) Use your calculator (or computer) to work out the approximate value of the first few members of the set $E$ in the above theorem. Hence obtain an approximation for $e$.} 
\solution{$E$ is the set 
$$\left\{1, 1+ \frac{1}{1!}, 1 + \frac{1}{1!} + \frac{1}{2!}, 1 + \frac{1}{1!} + \frac{1}{2!} + \frac{1}{3!}, 1 + \frac{1}{1!} + \frac{1}{2!} + \frac{1}{3!} + \frac{1}{4!}, \dotsb\right\}.$$
\indent The first five terms, according to a calculator, are:
\begin{enumerate}
\item 1
\item 2
\item 2.5
\item 2.6667
\item 2.7083
\end{enumerate}} %reviewed 9/03/20
\exercise{Let $P$ be the set of numbers 
\begin{align*}
\biggl\{\sqrt 6, \sqrt {6(1+\tfrac{1}{4})},& \sqrt {6(1 +\tfrac{1}{4} + \tfrac{1}{9})},\\
&\sqrt {6(1 + \tfrac{1}{4} + \tfrac{1}{9} + \tfrac{1}{16})}, \sqrt {6(1 + \tfrac{1}{4} + \tfrac{1}{9} + \tfrac{1}{16} + \tfrac{1}{25})}, \dots\biggr\}
\end{align*} 
Use the fact that $1/m^2 < 1/m(m-1)$ together with exercise 5(i) on page 19 to show that the number $\sqrt 12$ is an upper bound of $P$. The members of $P$ are increasing towards its supremum: use your calculator or computer to work out some of the members of $P$ and hence obtain an estimate for $\sup P$. (In fact the supremum is $\pi$.)} 
\solution{Each member of the set $P$ is the square root of 6 times a finite series $\frac{1}{n^2}$. Since $\frac{1}{n^2} < \frac{1}{n(n-1)}$ we can say that each term of $P$ is less than $$\sqrt{6\left(1 + \frac{1}{2(1)} + \frac{1}{3(2)} + \frac{1}{4(3)} + \dotsb + \frac{1}{n(n-1)}\right)}$$ for some $n$. Exercise 5(i) on page 19 gives that $$\sum_{i=1}^n \frac{1}{n(n+1)} = 1 - \frac{1}{n+1}$$ so for each element $x$ of $P$, this shows that $x <\sqrt{6 (1 + 1 - \frac{1}{n+1})}$ for some $n$, and $\sqrt{6(2 - \frac{1}{n+1})} < \sqrt{6(2)} = \sqrt 12$ as desired. \\
\indent The first five terms of $P$, according to a calculator, are:
\begin{enumerate}
\item 2.449
\item 2.7386
\item 2.8577
\item 2.9226
\item 2.9634
\end{enumerate}} %reviewed 9/03/20
\exercise{In the previous two exercises we have used our calculators to obtain approximations to the supremum of a set, but only after we had proved mathematically that the supremum existed (by showing that each set was bounded above). It is dangerous to rely on intuition based on a few calculations when trying to show that a set is bounded above, and the point of this next exercise is to endorse that fact. \\\indent Let $E$ be the set $$\{1, 1 + \tfrac{1}{2}, 1 + \tfrac{1}{2} + \tfrac{1}{3}, 1 + \tfrac{1}{2} + \tfrac{1}{3} + \tfrac{1}{4}, 1 + \tfrac{1}{2} + \tfrac{1}{3} + \tfrac{1}{4} + \tfrac{1}{5}, \dots \}$$ Calculate a few terms of $E$. Do you think that the set is bounded above? \\
\indent In exercise 7(i) on page 19 we showed that $$1 + \tfrac{1}{2} + \tfrac{1}{3} + \tfrac{1}{4} + \tfrac{1}{5} + \dotsb + \tfrac{1}{2^{n-1}} \geqslant \tfrac{1}{2} (n+1)$$  Use this fact to show that $E$ is not bounded above. \\ 
\indent Use part (ii) of that same exercise to show, however, that for $r>1$ the set $$\left\{1, 1 + \frac{1}{2^r}, 1 + \frac{1}{2^r} + \frac{1}{3^r}, 1 + \frac{1}{2^r} + \frac{1}{3^r} + \frac{1}{4^r}, 1 + \frac{1}{2^r} + \frac{1}{3^r} + \frac{1}{4^r} + \frac{1}{5^r}, \dots \right\}$$ is bounded above.}
\solution{The first five terms of $E$ are:
\begin{enumerate}
\item 1
\item 1.5
\item 1.8333
\item 2.0833
\item 2.2833
\end{enumerate}
\indent Suppose $u$ is an upper bound of $E$. Then $2[u]+1$, where $[u]$ is the integer part of $u$, is an upper bound of $E$ as well. There is an element in $E$ equal to
$$1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \dotsb + \frac{1}{2^{2[u]}} \geqslant \frac{1}{2} (2[u]+2) \geq u$$ 
and $u$ is not an upper bound of $E$. \\
\indent Any element of the second set will satisfy
$$1+ \frac{1}{2^r} + \frac{1}{3^r}+ \frac{1}{4^r} + \dotsb + \frac{1}{k^r} < 1 +\frac{1}{2^r} + \frac{1}{3^r} + \frac{1}{4^r} + \dotsb + \frac{1}{(2^n-1)^r}$$
for when $2^n-1 > k$. Part (ii) of that exercise showed that the expression above will be less than
$$1 + \frac{1}{2^r} + \frac{1}{3^r} + \frac{1}{4^r} + \dotsb + \frac{1}{(2^n-1)^r} \leq \frac{1-\left(\frac{1}{2}\right)^{(r-1)n}}{1-\left(\frac{1}{2}\right)^{r-1}} < \frac{1}{1-\left(\frac{1}{2}\right)^{r-1}}$$ 
for some $n$. Since the right side of the inequality doesn't depend on the choice of $n$, the set is bounded above by that number for all $n$.}%reviewed 9/03/20

\newpage 
\section{Gradually getting there}
\chapter{Calculus at last?}
\exercise{(page 28) The figures show the graph of the function $g$ given by 
$$g(x) = \frac{1}{x} \quad x>0$$
\indent (i) The left-hand figure shows the chord from $P(2, \tfrac{1}{2})$ to $Q(3,\tfrac{1}{3})$ on the curve. Calculate the gradient of $PQ$. Now keep $P$ fixed and choose other values of $Q$ on the curve but closer to $P$ (for example you could take, in turn, those $Q$ with x-coordinates 2.5, 2.2, 2.1, and more if you can be bothered). Calculate the gradient of the chord $PQ$ in each case and hence obtain the first few terms of a sequence which is tending towards 'the gradient of $g$ at $P$'. \\
\indent (ii) The right-hand figure shows the are under the curve between $x=1$ and $x=2$ divided into 6 strips of equal width. Use your calculator to work out the total area of the 6 rectangles illustrated. Repeat the process for the area divided into more and more strips (for example you could try 8, 10 and 12 strips, and more if you could be bothered). Hence obtain the first few terms of a sequence which is tending towards 'the area under the graph of $g$ from $x=1$ to $x=2$'}
\solution{The slope of $PQ$ is equal to 
$$\frac{\tfrac{1}{3} - \tfrac{1}{2}}{3-2} = -\frac{1}{6}.$$
\indent The slope between $P$ and the point $(2.5, g(2.5))$ is $\frac{1/2.5-1/2}{2.5-2} = -\frac{1}{5}.$ For $P$ and $(2.2, \tfrac{1}{2.2})$ a calculator determines the slope to be -.227, and between $P$ and $(2.1, \tfrac{1}{2.1})$ the slope is -.238. \\
\indent (ii) The total area of the 6 rectangles between $x=1$ and $x=2$ is equal to 0.6532. For 8 rectangles, the total comes out to .6629, for 10 rectangles it is .6688 and for 12 it is .6727.}%reviewed 9/03/20
\exercise{In chapter 1 we calculated the number $e$ as approximately 2.718282. Let $g$ be the same function as in exercise 1: we wish to obtain an approximate value of the area under the graph of $g$ from $x=1$ to $x=e$. Divide that area into 10 (or 1000?) strips and form rectangles as in the previous exercise, and use your calculator (or ideally a computer) to calculate the approximate total area of those rectangles. Repeat the procedure for larger and larger numbers of strips. Hence obtain some terms of a sequence which is tending towards 'the area under the graph of $g(x) = 1/x$ from $x=1$ to $x=e$'.}
\solution{For 10 rectangles the computer gives the area as .9478124. For 1000 rectangles the approximate area is 0.9994572. In fact since the integral of $1/x$ is $\ln x$ the true area should be 1.}%reviewed 9/03/20
\exercise{We proved in chapter 1 that $\sqrt 2$ exists although we didn't specifically calculate it. We also saw, in exercise 3 on page 8, that if $\alpha$ is a positive number with $\alpha^2 >2$ then the number $\beta = \alpha / 2 + 1/\alpha$ is also positive with $\beta^2 > 2$ and with $\beta^2$ closer to 2. Choose any number $x_1$ which is clearly over $\sqrt 2$ (e.g. $x= 10!$) and use your calculator to work out the new number $$x_2 =\frac{1}{x_1} + \frac{x_1}{2}$$
By the above comments this will be closer to $\sqrt 2$. Then calculate
$$x_3 = \frac{1}{x_2}+\frac{x_2}{2},\quad x_4 =\frac{1}{x_3} + \frac{x_3}{2}, \quad x_5 = \frac{1}{x_4} + \frac{x_4}{2},\dotsb$$
and in this way obtain the first few terms of a sequence which seems to tend toward $\sqrt 2$.}
\solution{Using $x_1 = 10$, the terms of the sequence are $x_2 = 5.1$, $x_3 = 2.746$, $x_4 = 1.737$ and $x_5 = 1.444$.}%reviewed 9/03/20
 
\newpage 

\chapter{Sequences}
\exercise{(page 36) Show that in the sequence $$x_1 = 1, x_2 = 1-\frac{1}{2}, x_3 = 1-\frac{1}{2} + \frac{1}{4}, x_4 = 1 -\frac{1}{2} +\frac{1}{4} -\frac{1}{8} \dots$$ 
the subsequence $x_1, x_3, x_5,\dots$ is decreasing and that the subsequence \\$x_2, x_4, x_6, \dots$ is increasing. Show also that each even-numbered term is less than each odd-numbered term. \\
\indent Draw a rough sketch of the graph of the sequence. \\
\indent By using the formula for the sum of the geometric progression 
$$1 - \frac{1}{2} + \frac{1}{4} -\frac{1}{8} + \dotsb \pm \frac{1}{2^{n-1}}$$ 
make a guess at which number you think the sequence is tending towards.} %2/26 end %2/27
\solution{The sequence $x_1, x_3, x_5, \dots$ is described recursively by $x_1=1$ and $$x_{i} = x_{i-2} - \frac{1}{2^{i-2}} + \frac{1}{2^{i-1}} = x_{i-2} - \frac{1}{2^{i-1}} < x_{i-2}$$ so that $x_{i} < x_{i-2}$ for odd $i$. Then the subsequence is decreasing. For even $i$, the sequence $x_2, x_4, x_6,\dots$ is such that $$x_i = x_{i-2} + \frac{1}{2^{i-2}} - \frac{1}{2^{i-1}} = x_{i-2} +\frac{1}{2^{i-1}}>x_{i-2}$$ and the subsequence is increasing. \\
\indent The sequence $x_1, x_2, x_3$ describes the geometric sum of $\sum^{n-1}_{i=0}(-\frac{1}{2})^i.$ Using the equation to solve this sum shows that $$x_n = \frac{1-(-\frac{1}{2})^n}{1-(-\frac{1}{2})}=\frac{2}{3}(1-(-\tfrac{1}{2})^n).$$ Then for even $n$ and odd $m$, $$x_n = \frac{2}{3} - \frac{1}{2^n} < \frac{2}{3} < \frac{2}{3} + \frac{1}{2^m}=x_m$$ and every odd-numbered term is less than every even-numbered term. \\
\indent The formula for the sum of the geometric progression suggests that $\frac{2}{3}$ is an upper bound for the even numbered terms and a lower bound for the odd-numbered terms, so the sequence might tend towards $\frac{2}{3}$.}%[9/07/20 - come back to this after 1.5] [reviewed 09/16/20]
\exercise{For each integer $n$ let $x_n$ denote the area of the triangle shown. Without actually calculating numerical values of the $x_n$s explain informally why the sequence $x_1, x_2, x_3, \dots$ is decreasing. What number do you think the sequence is tending towards?\\
\indent Explain similarly why the sequence $$x_1, 2x_2, 4x_3, 8x_4, \dots$$ is increasing. Is it tending towards any particular number and, if so, what do you think that number is?} %2/27 
\solution{The figure depicts a triangle with two sides of length 1 and the angle between them $\frac{\pi}{2^n}$ radians. As $n$ increases, the angle gets shallower and shallower, while the lengths of the two adjacent sides stays the same. Thus the third side of the triangle, opposite the angle, grows smaller and smaller, and the area of the triangle decreases. The sequence is tending towards zero. \\
\indent The second sequence $x_1, 2x_2, 4x_3,\dots$ is increasing because decreasing the angle by a factor of two causes a decrease in the area of the triangle less than a factor of two. The sequence diverges to infinity.}%reviewed 09/16/20
\exercise{Let $f$ be a function whose domain is an interval. Then $f$ is called convex if whenever a chord is drawn between two points on its graph that chord lies either on or above the graph, as illustrated in the left-hand figure. \\
\indent Earlier we considered the convex function given by $f(x) = x^2\quad (x\in \mathbb{R})$ and calculated a sequence of gradients of chords from $P(1,1)$ to other points on the graph of $f$. These points were to the right of $P$ and closer and closer to it. The sequence we obtained was $$2.8, 2.4, 2.2, 2.1, 2.05,\dots$$ which is decreasing. We shall now see that a sequence obtained in this way for a convex function will always be decreasing. \\
\indent So now let $f$ be any convex function and consider the points $P(x_0, f(x_0))$ and $Q(x_1, f(x_1))$ on the graph of $f$. Let $x_2$ satisfy $x_0 < x_2 < x_1$. Find the coordinates of the point on the chord $PQ$ whose $x$-coordinate is $x_2$ and deduce that 
$$f(x_2) \leqslant \frac{f(x_0)(x_1-x_2) + f(x_1)(x_2-x_0)}{x_1-x_0}$$ 
Deduce further that if $Q'$ is the point $(x_2, f(x_2))$ on the graph of $f$ then 
$$\text{gradient of }PQ' \leqslant \text{gradient of }PQ$$
Hence show that a sequence of gradients of chords of $f$ from $P$ to points closer and closer to $P$ (and to the right of it) will be decreasing.}
\solution{The slope of the chord $PQ$ is 
$$m = \frac{f(x_1) - f(x_0)}{x_1-x_0}$$
so the $y$-coordinate of the point on $PQ$ at $x_2$ is $f(x_0) + m(x_2-x_0)$. If $f$ is convex then the chord is above the graph; the $y$-coordinate $f(x_2)$ on the graph of $f$ is less than the $y$-coordinate $f(x_0) + m(x_2-x_0)$ of the point on the chord $PQ$ at $x_2$. So, 
\begin{align*}
f(x_2) &\leqslant f(x_0) + m(x_2-x_0)\\ 
&= f(x_0) + \frac{(f(x_1)-f(x_0))(x_2-x_0)}{x_1-x_0}\\
&=\frac{f(x_0)(x_1-x_0) + (f(x_1) - f(x_0))(x_2-x_0)}{x_1-x_0}\\
&= \frac{f(x_0)x_1 + f(x_1)x_2 - f(x_1)x_0 - f(x_0)x_2}{x_1-x_0}\\
&= \frac{f(x_0)(x_1-x_2) + f(x_1)(x_2-x_0)}{x_1-x_0}.
\end{align*}
\indent Now if $Q'$ is the point $(x_2, f(x_2))$ on the graph of $f$ then the gradient of $PQ'$ is $\frac{f(x_2) - f(x_0)}{x_2-x_0}$ and so the slope of $PQ' \leq$ the slope of $PQ$. Then the sequence of gradients of chords between $x_0$ and points closer and closer to $P$ will be decreasing.}%reviewed 09/16/20
\exercise{A \textit{concave} function is one whose domain is an interval and is such that any of its chords lies on or below the graph of the function, as illustrated on the right above. By using a mirror or otherwise show that if a sequence of gradients is obtained exactly as in the previous exercise, then the sequence will be increasing.} %3/3
\solution{If any chord of the graph of $f$ lies below the function, then for the chord $PQ$ between $x_1$ and $x_2$, the slope of $PQ$ is less than the slope between $x_1$ and any point $x_0$ between $x_1$ and $x_2$. Therefore the sequence of gradients between $x_1$ and $x_0$ increases as $x_0$ gets closer to $x_1$.}%reviewed 09/16/20 - other way to think about it is, if $f$ is concave then $-f$ is convex, and the slope of the chords at the same x-values on $-f$ have negative of the slope of the chords on $f$. So if a sequence of chords on the convex $-f$ has decreasing slope, then the same sequence of chords on the concave $f$ has increasing slope. 
\exercise{In exercise 6 on page 19 we established Bernoulli's inequality, namely that $(1+x)^n\geqslant 1 + nx$ for $x\geqslant -1$. Use this inequality with $x = 1/n^2$ to show that for $n>1$ 
$$\left(1+\frac{1}{n}\right)^n \geqslant \frac{1}{(1-1/n)^{n-1}} = \left(1 + \frac{1}{n-1}\right)^{n-1}$$ 
Deduce that the following sequence is increasing:
$$2, (1\tfrac{1}{2})^2, (1\tfrac{1}{3})^3, (1\tfrac{1}{4})^4,\dots,\left(1+\frac{1}{n}\right)^n,\dots$$} %3/5
\solution{For $x= -1/n^2$, 
$$\left(1-\frac{1}{n^2}\right)^n \geqslant 1 -\frac{1}{n}$$
and 
$$ \left(1 - \frac{1}{n^2}\right)^n = \left(1+\frac{1}{n}\right)^n\left(1-\frac{1}{n}\right)^n $$
so that 
$$\left(1 + \frac{1}{n}\right)^n \geqslant \frac{1-1/n}{(1-1/n)^n} = \frac{1}{(1-1/n)^{n-1}} = \left(1 + \frac{1}{n-1}\right)^{n-1}$$ 
So in the sequence $a_n = (1 + \frac{1}{n})^n$ this shows that $a_n > a_{n-1}$, and the sequence is increasing.} %3/6 [Doesn't use all the givens; check the book solution!] %3/16 fixed [still have to review this one] [reviewed 09/18/20 - wow]

\newpage
\chapter{Tending towards...?}
\exercise{(page 42) Use the definition to show formally that the sequence 
$$1, \frac{2}{3}, \frac{3}{5}, \frac{4}{7}, \frac{5}{9}, \dots$$
converges to the limit $\frac{1}{2}$.} %3/6 
\solution{Given $\epsilon > 0$, choose $N$ to be an integer greater than $\frac{1}{4\epsilon} + \frac{1}{2}$. Then for $n>N$, the difference $x_n-x =\frac{n}{2n-1}-\frac{1}{2}$ will be 
$$\frac{2n}{2(2n-1)}-\frac{2n-1}{2(2n-1)}=\frac{1}{4n-2} < \frac{1}{4(\tfrac{1}{4\epsilon} + \tfrac{1}{2}) -2} = \frac{1}{1/\epsilon} = \epsilon$$ 
so $x_n = \frac{n}{2n-1}$ converges to $\frac{1}{2}$.}%3/7 [reviewed 09/18/20]
\exercise{Recall that (for $x> 0$) $\log_{10} x = y$ means that $10^y = x$. Use the definition of convergence to show formally that the sequence 
$$\frac{1}{\log_{10} 2},\frac{1}{\log_{10} 3}, \frac{1}{\log_{10} 4}, \frac{1}{\log_{10} 5} \dots$$
converges to 0.} %Mon 3/9 
\solution{The $n$th term of this sequence is 
$$x_n = \frac{1}{\log_{10} n+1}$$ 
so the difference between the $n$th term and the limit $x=0$ is $1/(\log_{10} n+1)$. Given any positive number $\epsilon,$ this difference is less than $\epsilon$ when $N$ is chosen to be any integer larger than $10^{\frac{1}{\epsilon}} -1$, and since $\log n > 0$ whenever $n\geq 1$ the sequence is non-negative. Then 
$$-\epsilon < \frac{1}{\log_{10}N+1} < \frac{1}{\log_{10}10^{\frac{1}{\epsilon}} -1 + 1} = \frac{1}{\log_{10}10^{\frac{1}{\epsilon}}} =\frac{1}{1/\epsilon} = \epsilon$$
so when $n\geq N$ it is true that $-\epsilon < x_n - 0 < \epsilon$ and the sequence satisfies the definition for convergence and tends to 0.}%3/9 [reviewed 09/18/20]
\exercise{Write down the definition of the sequence $x_1, x_2, x_3, \dots$ converging to $x$, and also write down the same definition applied to the sequence $x_1 - x, x_2-x, x_3-x, \dots$ converging to 0. Observe that the two statements are saying equivalent things. (Hence $x_1, x_2, x_3, \dots$ converges to $x$ if and only if $x_1-x, x_2-x, x_3-x, \dots$ converges to 0.) \\
\indent Deduce that if the sequence $x_1, x_2, x_3, \dots $ converges to $x$ then for any number $y$ the sequence $x_1 + y, x_2 + y, x_3 + y, \dots$ converges to $x+y$ (i.e. you can 'add a constant to a convergent sequence').} %3/9
\solution{The definition of the sequence $x_1, x_2, x_3, \dots$ converging to $x$ is that given $\epsilon > 0$ there exists an integer $N$ with 
$$x-\epsilon < x_n < x + \epsilon$$
for all $n\geq N$. The same definition applied to the sequence $x_1 - x, x_2-x, x_3-x,\dots$ converging to 0 is given $\epsilon >0$ there is an integer $N$ with 
$$0-\epsilon < x_n - x < 0 + \epsilon$$
for all $n \geq N$. Adding $x$ to each expression in this inequality gives 
$$-\epsilon + x < x_n < \epsilon + x$$ 
which is the same inequality as the definition of convergence for the sequence $x_1, x_2, x_3,\dots \to x$, so the two definitions are equivalent. Then the statement that the sequence $x_1, x_2, x_3,\dots$ converges to $x$ is equivalent to the statement that the sequence $x_1 -x, x_2- x, x_3-x,\dots$ converges to 0. \\
\indent Since $y - y = 0$, the sequence $x_1 - x, x_2 - x, x_3 -x,\dots$ which converges to 0 is equivalent to the sequence $x_1 -x + (y-y), x_2 - x, + (y-y), x_3 -x + (y-y), \dots$. Rearranging terms gives the equivalent sequence 
$$x_1 + y - (x + y), \enspace x_2 + y - (x+y), \enspace x_3 + y - (x+y) ,\dots$$ 
that also converges to 0. Using the fact that was just shown, the convergence of the above sequence to zero is the same as the convergence of the sequence
$$x_1 + y,\enspace  x_2+y, \enspace x_3+y,\dots$$
to $x+y$. Combining the first and last of the definitions that were just shown to be equivalent, $x_1, x_2, x_3, \dots$ converges to $x$ if and only if $x_1 +y, x_2+y, x_3+y, \dots$ converges to $x+y$.}%3/9 [reviewed 09/20/20, spent some time on 09/19/20 on it too]
\exercise{By a similar process to that in exercise 3 prove that the sequence \\$x_1, x_2, x_3, \dots$ converges to $x$ if and only if the sequence \\$-x_1, -x_2, -x_3, \dots$ converges to $-x$.} %3/9 
\solution{The definition of convergence of $x_1, x_2, x_3, \dots$ to $x$ is that, given any $\epsilon > 0$, there is an integer $N$ with 
$$x-\epsilon < x_n < x+\epsilon$$
for all $n\geq N$. Then multiplying each expression in this definition by -1 (and reversing the inequalities) gives
$$-x+\epsilon > -x_n > -x-\epsilon$$
and after rearranging terms,
$$(-x) - \epsilon < -x_n < (-x) + \epsilon$$ 
which is the definition of the sequence $-x_1, -x_2, -x_3, \dots$ converging to $-x$.}%3/9 [reviewed 09/21/90]
\exercise{Prove that the sequence $x_1, x_2, x_3, \dots$ converges to 0 if and only if the sequence $|x_1|, |x_2|, |x_3|, \dots$ converges to 0.\\
\indent Give an example of a sequence $x_1, x_2, x_3,\dots$ which is divergent but is such that the sequence $|x_1|, |x_2|, |x_3|, \dots$ is convergent.} %3/9 
\solution{The definition of $x_1, x_2, x_3, \dots$ converging to 0 is that, given $\epsilon > 0$, there exists an integer $N$ with 
$$-\epsilon < x_n < \epsilon$$
for all $n\geq N$. The definition of the sequence $|x_1|, |x_2|, |x_3|, \dots$ converging to 0 is given $\epsilon > 0$ there exists an integer $N$ with
$$-\epsilon < |x_n| < \epsilon$$
for all $n\geq N$. When $x_n$ is positive this exactly matches the above inequality, and if there are any terms $x_n < 0$ then the inequality becomes
$$-\epsilon < -x_n < \epsilon$$ 
and after multiplying by $-1$ the expressions are the same. Then the definitions of convergence are equivalent, and the sequence $|x_1|, |x_2|, |x_3|,\dots$ converges to 0 if and only if $x_1, x_2, x_3, \dots$ converges to 0. \\
\indent An example of a sequence $x_1, x_2, x_3, \dots$ that is divergent but is such that $|x_1|, |x_2|, |x_3|, \dots$ is convergent is the sequence 
$$-1, 1, -1, 1, -1, 1, \dots, (-1)^n, \dots$$ }%3/9 [reviewed 09/21/20
\exercise{Assume that the sequence $x_1, x_2, x_3, \dots$ of non-negative numbers converges to 0 and that the sequence $y_1, y_2, y_3,\dots$ satisfies $-x_n \leqslant y_n \leqslant x_n$ for each $n$. By the definition of the convergence of $x_1, x_2, x_3,\dots$, given any $\epsilon > 0$ there exists an integer $N$ such that $x_N, x_{N+1}, x_{N+2},\dots$ have a certain property: show that $y_N, y_{N+1}, y_{N+2},\dots$ have the same property and that the sequence $y_1, y_2, y_3, \dots$ also converges to 0.} %3/9 
\solution{By the definition of the sequence $x_1, x_2, x_3, \dots$ converging to 0, given $\epsilon >0$ there exists an integer $N$ with the property that 
$$-\epsilon < x_n < \epsilon$$
which is equivalent to 
$$-\epsilon < -x_n < \epsilon$$
by multiplying by -1. The fact that the sequence $y_1, y_2, y_3, \dots$ satisfies $-x_n \leqslant y_n$ and $y_n \leqslant x_n$ then gives 
$$-\epsilon < -x_n \leqslant y_n \leqslant x_n < \epsilon$$ 
so that
$$-\epsilon < y_n < \epsilon$$
which is the definition of the sequence $y_1, y_2, y_3, \dots$ converging to 0.} %3/9 [reviewed 09/21/20]

\newpage
\chapter{Bound to get there}
\exercise{(page 50) Show that if $x_1, x_2, x_3, \dots$ converges to $x$ then any of its subsequences also converges to $x$. \\
\indent Deduce that the sequence 
$$1, \tfrac{1}{2}, \tfrac{1}{3}, 1, \tfrac{1}{4}, \tfrac{1}{5}, 1, \tfrac{1}{6}, \tfrac{1}{7}, 1, \dots$$
is divergent.} %3/10
\solution{Let $x_1, x_2, x_3, \dots$ be a sequence that converges to $x$ and let $x_{n_1}, x_{n_2}, x_{n_3}, \dots$ be a subsequence. Each term of the subsequence comes at or later than the corresponding term of the original sequence, so $n_k \geq k$ for every positive integer $k$. The definition of convergence of $x_1, x_2, x_3,\dots$ says that given $\epsilon >0$ there is an integer $N$ with $x-\epsilon < x_k < x+\epsilon$ for all $k\geq N$. Then $x-\epsilon < x_{n_k} < x+\epsilon$ for all $n_k\geq k \geq N$, which is the definition of the subsequence $x_{n_1}, x_{n_2}, x_{n_3}$ converging to $x$. \\
\indent The sequence $1, \frac{1}{2}, \frac{1}{3}, 1, \dots$ has a subsequence $1, 1, 1, \dots$ that converges to 1 and a subsequence $\frac{1}{2}, \frac{1}{3}, \frac{1}{4}$ that converges to 0. If the sequence were convergent then every subsequence would converge to the same value, so the sequence diverges.}%3/10 [reviewed 09/23/20]
\exercise{Show that if $x_1, x_3, x_5, \dots$ converges to $x$ and $x_2, x_4, x_6,\dots$ converges to $x$, then the sequence $x_1, x_2, x_3, x_4, \dots$ converges to $x$.} %3/10 
\solution{Given any $\epsilon > 0$, there is an odd $N_1$ such that 
$$x-\epsilon < x_{N_1 + 2m} < x+\epsilon$$
where $m$ is a positive integer. There is also an even integer $N_2$ with $x-\epsilon < x_{N_2+2m}<\epsilon$ where $n$ is even and greater than $N_2$. Let $N$ be the greater of $N_1$ and $N_2$. Then for every $n\geq N$ either $n$ is odd and $n = N_1 + 2m$ or $n$ is even and $n = N_2 +2m$. In each case the inequality holds and the sequence $x_1, x_2, x_3, \dots$ converges to $x$.}%3/10 [reviewed 09/23/20]
\exercise{Prove that a sequence which is decreasing and bounded below converges.} %3/10 
\solution{Let $x_1, x_2, x_3, \dots$ be a decreasing sequence bounded below. Then there is a greatest lower bound $\beta$ of the sequence. Since $\beta$ is a lower bound, given any $\epsilon >0$, $\beta-\epsilon < \beta \leq x_n$ for all $n$. If there is an $\epsilon$ with $\beta + \epsilon < x_n$ for all $N$, then $\beta + \epsilon$ is a lower bound greater than $\beta$ which contradicts that $\beta$ is the greatest lower bound of the sequence. Therefore there is some $x_N$ for which $\beta + \epsilon > x_N$. Since the sequence is decreasing, this gives  
$$\beta-\epsilon < \beta \leq x_n < \beta + \epsilon $$ 
for all $n\geq N$, and the sequence converges to $\beta$. \\ 
\indent Alternatively, if $x_1, x_2, x_3, \dots$ is a decreasing sequence bounded below, then $-x_1, -x_2, -x_3,\dots $ is an increasing sequence bounded above from an earlier exercise, which is known to be convergent. Then the original sequence converges.}%3/10 [reviewed 09/23/20]
\exercise{Let $x_1, x_2, x_3, \dots$ be a sequence of non-negative terms (i.e. $x_n \geqslant 0$ for each $n$) and assume that the sequence converges to $x$. (We aim to show that $x$ is non-negative.) By assuming that $x<0$ and taking $\epsilon = -x$ in the definition of convergence, deduce a contradiction and hence show that $x \geqslant 0.$ \\
\indent Deduce that if $y_1, y_2, y_3\to y$ and each $y_n \geqslant a$, then $y \geqslant a$.\\
\indent Deduce further that if $z_1, z_2, z_3, \dots \to z$ and each $z_n \leqslant b$, then $z\leqslant b$. Hence show that any sequence in the closed and bounded interval $[a,b]$ has a subsequence which converges to some number in $[a,b]$.} %3/10 
\solution{Assuming that $x<0$, then for $\epsilon = -x > 0$, there is an $N$ with
$$x-\epsilon= 2x < x_n < 0 = x + \epsilon$$ 
for all $n\geq N$. But $x_n <0$ contradicts that $x_1, x_2, x_3,\dots$ is a sequence of non-negative terms, so $x\geq 0$. \\
\indent If $y_n \geq a$ then $y_n-a\geq 0$. Applying the previous result to the sequence $y_1-a, y_2-a,y_3-a,\dots$ gives $y-a\geq 0$ so that $y \geq a$.\\
\indent Likewise if $z_1, z_2, z_3, \dots \to z$. and $z_n \leq b$ then the sequence $b-z_1, b-z_2, b-z_3, \dots$ satisfies $b-z_n\geq 0$ so that $z \leq b$. \\
\indent Every bounded sequence has a convergent subsequence, and if $x_1,x_2,x_3,\dots\to x$ is a convergent sequence in the interval $[a,b]$ then the sequence satisfies $a\leq x_n\leq b$ for all $n$. By the facts shown above $a\leq x\leq b$.}%3/10 [reviewed 09/24/20]
\exercise{We mentioned earlier that the sequence $\sin 1, \sin 2, \sin 3,\dots$ is divergent and now we are going to verify that fact formally. We shall assume that in calculating $\sin x$ the $x$ is in radians. So for example $\sin(\pi/6) = \frac{1}{2}, \sin(\pi/2) = 1, \sin(5\pi/6) = \frac{1}{2}, \sin(7\pi/6) = -\frac{1}{2},$ etc, with the graph of the sine function taking its familiar shape. \\
In exercise 3 on page 18 we saw that if two numbers differ by more than 1 then there is an integer between them. Use the fact that $\pi >3$ to show that there exist integers $k_1, k_2, k_3, \dots$ with 
$$\frac{\pi}{6} < k_1 < \frac{5\pi}{6}, \frac{13\pi}{6} < k_2 < \frac{17\pi}{6}, \frac{25\pi}{6} < k_3 < \frac{29\pi}{6}, \dots$$
and that there exist integer $j_1, j_2, j_3, \dots$ with
$$\frac{7\pi}{6} < j_1 < \frac{11\pi}{6}, \frac{19\pi}{6}<j_2<\frac{23\pi}{6}, \frac{31\pi}{6} < j_3 < \frac{35\pi}{6}, \dots$$
Deduce that the sequence $\sin 1,\sin 2,\sin 3, \sin 4,\dots$ has a subsequence of terms all exceeding $\frac{1}{2}$ and another subsequence of terms all less than $-\frac{1}{2}$, and that the sequence is therefore divergent.}%3/10 
\solution{If $x>3$, then 
$$\frac{(k+4)x}{6} - \frac{kx}{6} = \frac{4x}{6} > \frac{4(3)}{6} = 2 > 1$$
So there is an integer between $\frac{kx}{6}$ and $\frac{(k+4)x}{6}$. Since $\pi>3$, there exist integers $k_1, k_2, k_3, \dots$ and $j_1, j_2, j_3, \dots$ as described above. The fact that $\sin k_n >\frac{1}{2}$ and $\sin j_n < -\frac{1}{2}$ along with the periodic property of the sine function means that 
$$\sin k_1 > \frac{1}{2}, \sin k_2 > \frac{1}{2}, \sin k_3 > \frac{1}{2}, \dots$$ 
and 
$$\sin j_1 < -\frac{1}{2}, \sin j_2 < -\frac{1}{2}, \sin j_3 < -\frac{1}{2}, \dots$$
and $k_1, k_2, k_3, \dots$ is a subsequence that converges to a limit greater than $\frac{1}{2},$ while $j_1, j_2, j_3, \dots$ is a subsequence that converges to a limit less than $-\frac{1}{2}$, so the sequence $\sin 1, \sin 2, \sin 3, \dots$ diverges.}%3/10 [reviewed 09/24/20]
\exercise{ Let $x_1, x_2, x_3, \dots$ be a sequence of non-zero terms which converges to the limit $x$, where $x>0.$ By taking $\epsilon = x/2$ in the definition of convergence show that there exists an $N$ with $x_N, x_{N+1}, x_{N+2}, \dots$ all greater than $x/2$. Deduce that the set 
$$\left\{\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \frac{1}{x_4},\dots\right\}$$
is bounded.} %3/10
\solution{Since the sequence $x_1, x_2, x_3,\dots$ converges to $x>0$, given $\epsilon = x/2 > 0$, there is an $N$ with 
$$x-\epsilon = x/2 < x_n < 3x/2 = x+\epsilon $$
for all $n\geq N$. Then the sequence $\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \dots$ can be split into two sets 
$$\left\{\frac{1}{x_1}, \dots \frac{1}{x_{N-1}}\right\} \cup \left\{\frac{1}{x_N}, \frac{1}{x_{N+1}}, \dots\right\}$$
where the left set is a finite and therefore bounded, and the right set is bounded above by $2/x$ and below by $0$. So the sequence $\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \dots$ is bounded.}%3/10 [reviewed 09/24/20]
\exercise{(i) Let the sequence $x_1, x_2, x_3, \dots$ of positive terms converge to 0. By taking $\epsilon = 1$ in the definition of convergence show that there exists an $N_1$ with $1/x_n > 1$ for all $n\geqslant N_1$.\\
\indent By taking $\epsilon = \frac{1}{2}$ in the definition of convergence show that there exists an $N_2$ with $1/x_n > 2$ for all $n\geqslant N_2$.\\
\indent Prove that the sequence 
$$\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3},\frac{1}{x_4},\dots$$
tends to $\infty.$\\
\indent (ii) Let $x_1, x_2, x_3, \dots$ be a sequence of positive numbers such that 
$$\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \frac{1}{x_4},\dots$$
tends to $\infty.$ By taking $k=1$ in the definition of 'tending to $\infty$' show that there exists an $N_1$ with $x_n<1$ for all $n\geq N_1$.\\
\indent By taking $k=2$ show that there exists an $N_2$ with $x_n < \frac{1}{2}$ for all $n\geqslant N_2$. Prove that the sequence $x_1, x_2, x_3, \dots$ converges to 0.\\
\indent (Hence a sequence of positive terms converges to 0 if and only if the sequence of their reciprocals tends to infinity.)} %3/10 
\solution{(i) Given $\epsilon =1$, there is an $N_1$ with $0<x_n < 1$ if $n\geqslant N_1$, so then the reciprocals $1/x_n > 1$. Given $\epsilon = \frac{1}{2}$, there is a $N_2$ with $0<x_n < \frac{1}{2}$ if $n \geqslant N_2$; the reciprocals $\frac{1}{x_n} > 2$.\\
\indent In general, given a $k$, by fixing $\epsilon = \frac{1}{k}$ there is an $N$ for which $x_n < \epsilon$ and $\frac{1}{x_n} > k$ for all $n\geqslant N$. Then the sequence 
$$\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \dots$$
tends to $\infty$. \\
\indent (ii) If the sequence $\frac{1}{x_1}, \frac{1}{x_2}, \frac{1}{x_3}, \dots$ tends to infinity then given $k$ there is an $N$ for which $1/x_n > k$ if $n\geqslant N$; taking $k=1$ and $k=2$ gives an $N_1\leq n$ with $\frac{1}{x_n} > 1$ and an $N_2\leq n$ with $\frac{1}{x_n}>2$, so that $x_n < 1$ and $x_n < \frac{1}{2}$ respectively. Then given $\epsilon > 0$, and choosing $k=\frac{1}{\epsilon}$, there is an $N$ with $\frac{1}{x_n} >k$ and $x_n <\epsilon$ for all $n\geqslant N$. Therefore $x_1, x_2, x_3,\dots$ converges to 0.}%3/10 [reviewed 09/24/20]

\newpage
\chapter{Some labor-saving devices}
\exercise{(page 62) Are the following sequences convergent? If so find their limits, justifying your answers.
$$\text{(i) } \left(\frac{2n^3 + 1}{3n^3 + n +2}\right)\quad \text{(ii) }\left(1+ \frac{1}{\sqrt n}\right)^2\quad \text{(iii) } (100 + 5^n)^{1/n}$$} %3/11
\solution{(i)
$$\frac{2n^3 + 1}{3n^3 + n + 2} = \frac{2 + \tfrac{1}{n^3}}{3 + \tfrac{1}{n^2} + \tfrac{2}{n^2}} \to \frac{2 + 0}{3 + 0 + 0} =\tfrac{2}{3}$$
The justification for letting $n\to \infty$ is that sums and products of sequences converge to the sums and products of their limits. \\
\indent (ii) Again letting $n$ go to infinity,
$$\left(1 + \frac{1}{\sqrt n}\right)^2 \to (1 + 0)^2 = 1$$ 
with the same justification. \\
\indent (iii) The expression simplifies to
$$(100 + 5^n)^{1/n} = (5^n(\tfrac{100}{5^n} + 1))^{1/n} = 5(\tfrac{100}{5^n}+1)^{1/n}\to 5$$
the justification being that $1/a^n\to 0$ and $1^{1/n}\to 1$.}%3/11 [reviewed 09/24/20]
\exercise{Let the sequence $(x_n)$ be given by 
$$x_1 = 10 \quad\text{ and }\quad x_n = \frac{x_{n-1}}{2} + \frac{1}{x_{n-1}} \quad\text{ for }\quad n>1$$
We observed in exercise 3 on page 29 that this sequence is decreasing and bounded below. Use those facts to show that the sequence is convergent and hence find its limit.} %3/12 8pm
\solution{The sequence is decreasing and bounded below, so it is convergent. Then we can write
$$x_n \to x \implies x = \frac{x}{2} + \frac{1}{x}\implies x^2 = 2$$
because any subsequence of a convergent sequence converges to the limit of the sequence. So the limit of the sequence is $x = \sqrt 2$.}%3/12 [reviewed 09/24/20]
\exercise{We saw in an earlier example that for $x>0$ the sequence $(x^{1/n})$ converges to 1. We now wish to investigate the behavior of the sequence $(n^{1/n})$ or $1, 2^{1/2}, 3^{1/3}, 4^{1/4}, \dots.$ Before proceeding calculate a few terms of the sequence and guess what its limit is going to be.\\
\indent In exercise (6)(i) on page 19 we established Bernoulli's inequality, namely $1 + nx \leqslant (1+x)^n$ for each positive integer $n$ and each number $x\geqslant -1$. Use this inequality with $x = 1/\sqrt n$ to show that 
$$ 1\leqslant n^{1/n} < (1+\sqrt n)^{2/n} \leqslant (1+1/\sqrt n)^2$$
Deduce that the sequence $(n^{1/n})$ converges to 1.} %3/12
\solution{The first few terms of the sequence are 1, 1.414, 1.442, 1.414, 1.379. 
Bernoulli's inequality says that 
$$1 + n/\sqrt n = 1+\sqrt n \leqslant (1 +1/\sqrt n)^n$$
Taking the $n$th root and squaring both sides gives
$$(1+2\sqrt n + n)^{1/n} = (1+\sqrt n)^{2/n} \leqslant (1+1/\sqrt n)^2$$
$n$ is positive so $1+2\sqrt n > 0$ and
$$n^{1/n} < (1+2\sqrt n + n)^{1/n}$$
and if $n\geqslant 1$ then $n^{1/k}\geqslant 1$ for any positive $k$, so
$$1\geqslant n^{1/n} < (1+\sqrt n)^{2/n} \geqslant (1+1/\sqrt n)^2$$ 
Then the sequence $n^{1/n}$ is sandwiched by 1 and the sequence ($1+1/n)^2\to 1$, so $n^{1/n}\to 1$}%4/15 finally finished this [reviewed 09/24/20]
\exercise{Let $x$ be any positive number and let $N$ be any integer larger than $x$. Show that from the $N$th term onwards the sequence $(x^n/n!)$ is decreasing. Deduce that the sequence is convergent and find its limit.} %3/12
\solution{When $N$ is an integer greater than $x$ and $n\geq N$, we have 
$$\frac{x_{n+1}}{x_n} = \frac{x^{n+1}}{(n+1)!} \cdot \frac{n!}{x^n} = \frac{x}{n+1} \leq \frac{x}{N+1} < \frac{x}{x+1} < 1$$
and the sequence is decreasing. Since $x$ is positive $x^n$ is positive for all $n$, so the sequence is bounded below by 0. Therefore the sequence is convergent. Then we can write its limit
$$x_n = \frac{x^n}{n!} \to x$$
and
$$x_{n+1} = \frac{x}{n+1} \cdot \frac{x^n}{n!} = \frac{x}{n+1}\cdot x_n\to 0 \cdot x = 0$$
but every subsequence of a convergent sequence converges to its limit. So $x = 0$ and the sequence $x_n$ converges to 0.}%3/12 [reviewed 09/24/20]

\newpage
\chapter{Infinite Sums}
\exercise{(page 73) Test the convergence of the following series:
$$\text{(i) } \sum\frac{(n^2+1)^3}{(n^4+1)^2}; \quad \text{(ii) } \sum\frac{5^{2n}(n!)^3}{(3n)!}; \quad \text{(iii) } \sum\sin n$$}%3/12 
\solution{(i) By the comparison test, 
$$0 \leq a_n = \frac{(n^2+1)^3}{(n^4+1)^2} \leq \frac{(2n^2)^3}{(n^4)^2} = \frac{8n^6}{n^8}$$ 
which differs from the convergent series $\sum\frac{1}{n^2}$ by a factor of a constant, so the series converges. \\
\indent (ii) The ratio test gives
\begin{align*}
\frac{5^{2(n+1)}((n+1)!)^3}{(3(n+1))!} \div \frac{5^{2n}(n!)^3}{(3n)!} &= \frac{5^2(n+1)^3}{(3n+3)(3n+2)(3n+1)}\\
&=\frac{25(1+1/n)(1+1/n)(1+1/n)}{(3+3/n)(3+2/n)(3+1/n)} \\
&\to \frac{25}{27} < 1
\end{align*}
and the series converges. \\
\indent (iii) We have shown that the sequence $\sin 1, \sin 2, \sin 3, \dots$ diverges, so the terms of the series $\sum\sin n$ do not converge to 0 and the series diverges.}%3/12 ii, iii %3/13 9am i [reviewed 09/24/20]
\exercise{Let $\sum a_n$ be a convergent series with sum $s$. Let $\sum b_n$ be another series which is the same as the series $\sum a_n$ from the $N$th term onwards. Let 
$$t = (b_1 + b_2 + \dots + b_{N-1}) - (a_1 + a_2 + \dots + a_{N-1})$$ 
Show that the series $\sum b_n$ converges with sum $s+t$.} %3/12 
\solution{Let $(s_n)$ be the partial sums of $\sum a_n$ and $(u_n)$ be the partial sums of $\sum b_n$. Then
$$s_n = a_1 + a_2 + a_3 + \dots + a_n \text{ and } u_n = b_1 + b_2 + b_3 + \dots + b_n$$
and if $n\geq N$,
$$s_n = (a_1 + \dots + a_{N-1}) + a_N + \dots + a_n \text{ and } u_n = (b_1 + \dots + b_{N-1}) + b_N + \dots + b_n$$
Now $s_n \to s$ and $a_N, a_{N+1}, \dots = b_N, b_{N+1}, \dots$ so that  
\begin{align*}
u_n &= (b_1 + \dots + b_{N-1}) + (b_N + \dots + b_n) \\
&= (b_1 + \dots + b_{N-1}) + \left[s_n - (a_1 + \dots + a_{N-1})\right] \\
&\to s + t
\end{align*}} %3/12 [reviewed 09/24/20]
\exercise{Show that the series $\sum 1/n^r$ diverges for $r\leqslant 1$ and converges for $r>1$.\\
(For the latter part you will need the result of exercise 3 on page 22.)} %3/12 
\solution{If $r\leq 1$ and the series $\sum \frac{1}{n^r}$ converges, then by the comparison test, the fact that 
$$0 \leq \frac{1}{n} \leq \frac{1}{n^r} \quad (r \leq 1)$$
means that the series $\sum\frac{1}{n}$ converges, which is a contradiction. So the series diverges for $r\leq 1$. \\
\indent If $r> 1$, as a result of exercise 3 on page 22 the sequence of partial sums 
$$1 + \frac{1}{2^r} + \frac{1}{3^r} + \dots$$
is bounded above. Each term $\frac{1}{n^r}$ is positive, so the sequence of partial sums is increasing. Therefore it is a monotone bounded sequence and converges to the sum of the series.}%3/13 [reviewed 09/24/20]
\exercise{Let $\sum a_n$ be a series with partial sums $s_1, s_2, s_3 \dots.$ Show that if the sequence $s_2, s_4, s_6, \dots$ converges and the terms $a_1, a_2, a_3, \dots$ converge to 0 then the series $\sum a_n$ converges. (If you're keen show that the condition that $(s_{2n})$ converges can be reduced to the fact that $(s_{Mn})$ converges for some fixed positive integer $M$.)}
\solution{We have that $s_{2n}$ converges to $s$ and $a_n$ converges to 0, so 
$$(s_{2n+1}) = s_{2n} + a_{2n+1} \to s + 0 = s$$ 
Therefore the odd and even subsequences of the partial sums of $\sum a_n$ converge to the same value and the series $\sum a_n$ converges to $s$ (by exercise 2 on page 50). \\
\indent If instead $(s_{Mn})$ converges, then the subsequences
\begin{align*}
s_{Mn + 1} &= s_{Mn} + a_{Mn+1} \to s + 0 = s\\
s_{Mn + 2} &= s_{Mn+1} + a_{Mn+2} \to s + 0 = s \\
&\vdots\\
s_{Mn+(M-1)} &= s_{Mn+(Mn-2)} + a_{Mn+(M-1)} \to s + 0 = s
\end{align*}
and all the different subsequences of partial sums converge to the same value. In general, given $\epsilon>0$ there exist $N_0, N_1, \dots N_{M-1}$ with $s-\epsilon < s_{Mn + k} < s+\epsilon$ for all $n \geq N_k$. Then, choosing $N$ as the greatest of $N_0, \dots, N_{M-1}$, the convergence condition $s-\epsilon < s_n < s+\epsilon$ holds for all $n\geq N$. Therefore the sequence of partial sums converges to $s$.}%3/13 [reviewed 09/24/20]
\exercise{We know from our primary arithmetic that changing the order of a sum of a finite number of terms will not affect the answer; e.g.
$$ 7 -3\tfrac{1}{2} + \tfrac{1}{4} - 1 - 2 = \tfrac{3}{4} = -1 -3\tfrac{1}{2} + 7 -2 + \tfrac{1}{4}$$
and the same actually turns out to be true of any rearrangement of an absolutely convergent series. But for those series which are only conditionally convergent rearranging the order of the terms in them can actually change their sum! This exercise illustrates that fact.\\
\indent Let $s_n$ be the $n$th partial sum of the series 
$$1-\tfrac{1}{2} + \tfrac{1}{3} - \tfrac{1}{4} + \tfrac{1}{5} - \tfrac{1}{6} + \tfrac{1}{7} - \tfrac{1}{8} + \dots$$ 
(We know that this series converges, with sum $s$ say.)\\
\indent Let $t_n$ be the $n$th partial sum of the rearranged series
$$1 - \tfrac{1}{2} - \tfrac{1}{4} + \tfrac{1}{3} -\tfrac{1}{6} - \tfrac{1}{8} + \tfrac{1}{5} -\tfrac{1}{10} - \dots$$
Show that $t_{3n} = \tfrac{1}{2} s_{2n}$.  \\
\indent Use exercise 4 to deduce that this latter series converges with sum $\frac{1}{2}s$; i.e. by rearranging the series we have halved its sum!} %3/13
\solution{If $a_n$ is the sequence $a_n = \tfrac{1}{n}$ then the partial sum $t_{3n}$ can be recursively defined 
$$t_{3} = a_1 - a_2 - a_4; \quad t_{3n} = s_{2n} - a_{4n-2} - a_{4n}\text { for } n>1$$
Then for $n>1$ with the inductive hypothesis $t_{3n} = \tfrac{1}{2} s_{2n}$, in the case that $n=1$, 
$$t_3 = a_1 -a_2-a_4 = 1 - \frac{1}{2} -\frac{1}{4} = \frac{1}{4} = \frac{1}{2}\left(1-\frac{1}{2}\right) = \tfrac{1}{2}s_2$$
and the hypothesis holds. If the hypothesis holds for $n=n-1$, then
\begin{align*}
t_{3n} &= t_{3(n-1)} + a_{2n-1} - a_{4n-2} - a_{4n} \\
&= \tfrac{1}{2}s_{2(n-1)} + \left(\frac{1}{2n-1} - \frac{1}{4n-2} - \frac{1}{4n}\right) \\
&= \tfrac{1}{2}s_{2(n-1)} + \frac{4n(4n-2) -4n(2n-1)-(4n-2)(2n-1)}{4n(4n-2)(2n-1)} \\
&= \tfrac{1}{2}s_{2(n-1)} +\frac{1}{2n(4n-2)} \\
&= \tfrac{1}{2} s_{2(n-1)} + \frac{1}{2}\left(\frac{1}{2n-1} - \frac{1}{2n}\right)
\end{align*}
and the identity 
$$\tfrac{1}{2}s_{2n} = \tfrac{1}{2}s_{2(n-1)} + \tfrac{1}{2}(a_{2n-1} - a_{2n})$$
gives that 
\begin{align*}
t_{3n} &= \tfrac{1}{2}s_{2(n-1)} + \tfrac{1}{2}(a_{2n-1} - a_{2n})\\
&= \tfrac{1}{2}s_{2n}
\end{align*}
Then $t_{3n} = \frac{1}{2}s_{2n}$ by induction on $n$. \\
\indent The sequence $a_n = 1/n$ converges to 0 and $t_{3n}$ converges to $\frac{1}{2}s$, so $t_n$ converges with the same limit. \\
\indent Alternatively, the same fact can be proved without induction:
\begin{align*}
t_{3n} &= \sum_{i=1}^n (a_{2i-1} - a_{4i-2} - a_{4i}) \\
&= \sum_{i=1}^n a_{2i-1} -\sum_{i=1}^n a_{4i-2} - \sum_{i=1}^na_{4i}\\
&= \left(\sum_{i=1}^{2n} a_{i}-\sum_{i=1}^na_{2i}\right) -\left(\sum_{i=1}^{2n} a_{2i} - \sum_{i=1}^n a_{4i} \right) - \sum_{i=1}^na_{4i}\\
&= \sum_{i=1}^{2n} a_{i}-\sum_{i=1}^na_{2i} -\sum_{i=1}^{2n} a_{2i} \\
&= \sum_{i=1}^{2n} a_{i}-\frac{1}{2}\sum_{i=1}^na_{i} -\frac{1}{2}\sum_{i=1}^{2n} a_{i} \\
&= \frac{1}{2}\left(\sum_{i=1}^{2n} a_{i}-\sum_{i=1}^na_{i}\right) \\
&= \frac{1}{2}\left(\sum_{i=1}^{2n} a_{i}-\sum_{i=1}^{2n}2a_{2i}\right) \\
&= \tfrac{1}{2} \left(1-\tfrac{1}{2}+\tfrac{1}{3}-\tfrac{1}{4}+\dotsb-\frac{1}{2n}\right)\\
&= \tfrac{1}{2} s_{2n}
\end{align*}
which converges to $\tfrac{1}{2}s$. } %3/13 %[reviewed 10/6/20]
\exercise{We have defined the function $\log$ (on page 47) but have not yet established that it has any of the expected logarithmic-type properties. If you're happy to accept for the moment that $\log 2n - \log n$ is $\log(2n/n)$ which is $\log 2$, then you are actually able to calculate the sums of the series in exercise 5. \\
\indent As before let $s_n$ be the $n$th partial sum of the series
$$1 - \tfrac{1}{2} + \tfrac{1}{3} -\tfrac{1}{4} + \tfrac{1}{5} - \tfrac{1}{6} + \tfrac{1}{7} -\tfrac{1}{8} + \dots$$
and also let $u_n$ be the $n$th partial sum of the series 
$$1 + \tfrac{1}{2} + \tfrac{1}{3} + \tfrac{1}{4} + \tfrac{1}{5} + \tfrac{1}{6} + \tfrac{1}{7} + \tfrac{1}{8} + \dots$$
\indent (i) Use the result of the example on page 46 and 47 to show that the sequence $(u_n -\log n)$ converges. (Its limit is again $\gamma$, Euler's constant.) \\
\indent (ii) Show that 
$$s_{2n} = u_{2n} - u_n = (u_{2n} - \log (2n)) - (u_n - \log n) + \log 2$$
\indent (iii) Deduce that the sum of the series
$$1 - \tfrac{1}{2} + \tfrac{1}{3} - \tfrac{1}{4} + \tfrac{1}{5} - \tfrac{1}{6} + \tfrac{1}{7} + \tfrac{1}{8} + \dots $$
is $\log 2$ and (from exercise 5) that the sum of the series 
$$ 1 - \tfrac{1}{2} - \tfrac{1}{4} + \tfrac{1}{3} - \tfrac{1}{6} - \tfrac{1}{8} + \tfrac{1}{5} - \tfrac{1}{10} - \dots$$
is $\tfrac{1}{2} \log 2$. Use your calculator or computer to work out some of the partial sums of these series to confirm directly that these answers look reasonable.} %3/13
\solution{(i) The example on page 46 and 47 shows that the sequence 
$$1 + \frac{1}{2} + \frac{1}{3} + \dotsb +\frac{1}{n-1} - \log n$$ 
converges to Euler's constant $\gamma$, arguing that $\log n$ is the area under the graph of $1/x$ and $1/n$ is the area of the width 1 rectangle with the left edge at $x=n$. Since each term adds a sliver of area, the sequence is increasing, and since the total area is bounded above by a 1$\times$1 square the sequence converges. \\
Then the sequence $(u_n - \log n)$ is the sequence 
\begin{align*}
u_n-\log n&= 1 + \frac{1}{2} +\frac{1}{3} + \dotsb + \frac{1}{n} -\log n\\
&= \left(1 + \frac{1}{2} +\dotsb +\frac{1}{n-1} -\log n\right) + \frac{1}{n}
\end{align*}
which converges to $\gamma + 0 = \gamma$. \\ 
\indent (ii) The terms of $s_{2n}$ can be represented
\begin{alignat*}{10}
s_{2n} &= 1  \quad&& - \frac{1}{2}  \quad&& +  \frac{1}{3}  \quad&& - \frac{1}{4}  \quad&& +  \frac{1}{5}  \quad&&- \frac{1}{6}  \quad&& +  \frac{1}{7}  \quad&& -  \frac{1}{8}  \quad && +  \dots  && -   \frac{1}{2n}\\ 
u_{2n} &= 1&& +\frac{1}{2}&& + \frac{1}{3}&& + \frac{1}{4}&& + \frac{1}{5}&& + \frac{1}{6}&& + \frac{1}{7}&& + \frac{1}{8}&& + \dots&& + \frac{1}{2n}\\
-u_n &= && - 1  \quad&& && - \frac{1}{2}&& &&- \frac{1}{3}&& && - \frac{1}{4}&& + \dots &&+ \frac{1}{n} 
\end{alignat*}
\indent so that each term of $-u_n$ is -2 times an even-numbered term in $u_{2n}$, and it is clear that $s_{2n} = u_{2n} - u_n$. Then $$u_{2n} - u_n = (u_{2n} - \log (2n)) - (u_n - \log n) + \log 2 $$ follows from that assumed fact that $\log (2n) - \log n = \log (2n/n) = \log 2$. \\
\indent (iii) The sequence $u_n - \log n$ converges to Euler's constant $\gamma$, and $u_{2n} - \log (2n)$ is a subsequence so it must converge to the same value. Then $s_{2n}$ converges to $\gamma - \gamma + \log 2 = \log 2.$ \\
\indent Exercise 5 shows the rearranged sequence of terms converges to one half of the sum of the original sequence, so it converges to $\frac{1}{2}\log 2$. A calculator gives the first few terms as:
$$ 1, .5, .25, .583, .416, .292, .492\dots$$
and 
$$\tfrac{1}{2} \log 2 = .347$$
so it does look reasonable that this sequence converges to $\frac{1}{2}\log 2$.} %3/15 (sunday night, 10pm) [reviewed 10/06/20]
\exercise{For which numbers $x$ does the series $\sum_{n=0}^\infty x^n$ converge? If $D$ is the set of $x$ for which that series converges then we can define a function $f$ by 
$$f(x) = \sum^\infty_{n=0} x^n = 1 + x + x^2 + x^3 +  \dots \text{for } x \in D$$
Give a more direct formulation of $f$ which does not involve infinite sums. } %3/15
\solution{The series $\sum x^n$ converges when the sequence of partial sums, 
$$s_n = 1 + x + x^2 + \dots + x^n = \frac{1-x^{n+1}}{1-x}$$ 
converges. This is the case when $x^{n+1}$ converges and $x\neq 1$, which is when $-1 <x< 1$. Then for $x\in (-1, 1)$, $f$ is the function
$$ f(x) = \frac{1}{1-x}$$}%3/15 [reviewed 10/06/20]

\newpage 
\section{A functional approach}
\chapter{A powerful start}
\exercise{(page 79) Which of these functions is one-to-one? Find the inverse functions in those cases. 
$$\text{(i) } f(x) = x^2 \quad x \in \mathbb{R}$$
$$\text{(ii) } g(x) = 1/x \quad x\in \mathbb{R}, x\neq 0$$
$$\text{(iii) } h(x) = \frac{2x-1}{x+1} \quad x \in \mathbb{R}, x\neq -1$$
That second example is strangely related to its inverse: can you find some other functions with the same property?} %3/15
\solution{(i) This function is not one-to-one over the real numbers since $f(x) = f(-x)$. \\
\indent (ii) The inverse of $g$ is $g^{-1}(x) = 1/x$, that is $g = g^{-1}$. \\
\indent (iii) The inverse of $h$ is $h^{-1}(x) = \frac{-1-x}{x-2}$ \\
\indent A function with the same property as the second example is such that it equals its inverse. Those functions are symmetric over the line $y=x$, and $f(x) = x$ is one example of such a function.}%3/16
\exercise{A function is called \textit{strictly increasing} if whenever $x_1$ and $x_2$ are in its domain with $x_1 < x_2$ it follows that $f(x_1) < f(x_2)$. (Similarly it is \textit{strictly decreasing} if $x_1 < x_2$ implies $f(x_1) > f(x_2)$.) Show that a function which is strictly increasing is one-to-one and that its inverse function is also strictly increasing. Prove also the corresponding result about a decreasing function. \\
\indent Give an example of a one-to-one function which is neither increasing nor decreasing. } %3/16
\solution{If a function is strictly increasing or strictly decreasing then for any $x_1 \neq x_2$ then $f(x_1) \neq f(x_2)$. So every $x$ is mapped to a unique $y$. Then for a strictly increasing function, if $y_1 < y_2$ there are unique $x_1, x_2$ such that $f^{-1}(y_1) = x_1$ and $f^{-1}(y_2) = x_2$. Either $x_1 < x_2$ or $x_2 < x_1$, but it must be the case that $x_1 < x_2$ or else $f$ is not strictly increasing. So the inverse function is strictly increasing as well. The same logic applies for decreasing functions. \\
\indent The function $f(1) = 1, f(2) = 3, f(3) = 2$ on the set $\{1,2,3\}$ is one to one yet neither increasing nor decreasing.}%3/16 [reviewed 10/18/20]
\exercise{(i) Let $x_1$ and $x_2$ be any real numbers and let $\alpha$ and $\beta$ be non-negative numbers with $\alpha + \beta = 1$. Note that for any real number $T$, $(T+ x_1)^2 \geqslant 0$ and $(T + x_2)^2 \geqslant 0$ and hence that
$$\alpha (T+ x_1)^2 + \beta (T + x_2)^2 \geqslant 0$$
Multiply out that last expression and write it as a quadratic $aT^2 + bT + c$ for some $a, b$ and $c$. Since that quadratic is never negative use the '$b^2 - 4ac$' to show that 
$$(\alpha x_1 + \beta x_2)^2 \leqslant \alpha x_1^2 + \beta x_2^2$$ 
\indent (ii) Let $f$ be a function with domain equal to some interval. Then (as we defined in exercise 3 on page 37) $f$ is 'convex' if each of the chords of its graph lies on or above the graph.\\
By recalling that each number between $x_1$ and $x_2$ is of the form $\alpha x_1 + \beta x_2$ for some non-negative $\alpha$ and $\beta$ with $\alpha + \beta = 1$, show that $f$ is convex if and only if 
$$f(\alpha x_1 + \beta x_2) \leqslant \alpha f(x_1) + \beta f(x_2)$$
for each $x_1$, $x_2$ in $f$'s domain and each $\alpha, \beta \geqslant 0$ with $\alpha + \beta = 1$. \\
\indent (iii) Show that the function $g$ given by $g(x) = x^2\enspace (x\in \mathbb{R})$ is convex. \\
\indent (iv) By using a similar condition to that in (ii) but for a concave function show that the function $h$ given by $h(x) = \sqrt x \enspace(x\geqslant 0)$ is concave. \\
\indent (You might like to consider more generally the inverse of a strictly increasing convex function and show that it is concave.) } %3/16, 3/17, %3/18
\solution{(i) Multiplying out gives
$$\alpha(T + x_1)^2 + \beta(T + x_2)^2= (\alpha + \beta)T^2 + (2\alpha x_1 + 2\beta x_2) T + \alpha x_1^2 + \beta x_2^2$$  
Then since the quadratic is always $\geqslant 0$, either the zeroes are imaginary or there is only one zero. So $b^2-4ac\leqslant 0$ and  
$$b^2-4ac = (2\alpha x_1 + 2\beta x_2)^2 - 4(\alpha + \beta)(\alpha x_1^2 + \beta x_2^2) \leq 0 $$
so that 
$$(\alpha x_1 + \beta x_2)^2 \leqslant \alpha x_1^2 + \beta x_2^2$$ 
(using $\alpha + \beta = 1$). \\%3/17 (i)
\indent(ii) Given $x_1$ and $x_2$, every point between them can be represented as $\alpha x_1 + \beta x_2$, $\alpha + \beta = 1$. Then $f$ is convex if the point $f(x)$ is below the chord between $x_1$ and $x_2$ for each $x_1<x<x_2$. The point on the chord corresponding to $x = \alpha x_1 + \beta x_2$ is given by $y(x)$, where
\begin{align*}
y(x) - f(x_1) &= \tfrac{f(x_2)-f(x_1)}{x_2-x_1} (x-x_1). \\
&= \tfrac{f(x_2) - f(x_1)}{x_2-x_1} (\alpha x_1 + \beta x_2 - x_1) \\
&= \tfrac{f(x_2) - f(x_1)}{x_2-x_1} (-\beta x_1 + \beta x_2) \\
&= \beta(f(x_2) - f(x_1)) \\
y(x) &= \beta f(x_2) - \beta f(x_1) + f(x_1) \\
&= \alpha f(x_1) + \beta f(x_2)
\end{align*}
Therefore $f$ is convex if the point on the chord $(x, y(x))$ is above the point $(x, f(x))$ on the curve. That is,
$$y(x) = \alpha f(x_1) + \beta f(x_2) \geqslant f(\alpha x_1 + \beta x_2) = f(x)$$
for every $x_1<x_2$ in the domain of $f$ and every non-negative $\alpha, \beta$ with $\alpha + \beta = 1$ \\
\indent (iii) For any $x_1, x_2\in\mathbb{R}$ and $\alpha, \beta \geqslant 0$ with $\alpha + \beta =1$  
$$g(\alpha x_1 + \beta x_2) = (\alpha x_1 + \beta x_2)^2 \text{\quad and \quad} \alpha g(x_1) + \beta g(x_2) = \alpha x_1^2 + \beta x_2^2$$
so that $g$ is convex if 
$$(\alpha x_1 + \beta x_2)^2 \leqslant \alpha x_1^2 + \beta x_2^2$$
which was part (i). \\
\indent (iv) For concave functions, the condition is reversed; the chord between two points on the graph is below the graph for any point in the interval. Then the condition is 
$$h(\alpha x_1 + \beta x_2) \geqslant \alpha h(x_1) + \beta h(x_2)$$
or  
$$\sqrt{\alpha x_1 + \beta x_2}  \geqslant \alpha\sqrt x_1 + \beta\sqrt x_2$$
Squaring both sides,
\begin{align*} 
\alpha x_1 + \beta x_2 &\geqslant \alpha^2 x_1 + \beta^2 x_2 + 2\alpha\beta \sqrt{x_1 x_2}\\
&\geqslant (1-\beta)\alpha x_1 + (1-\alpha)\beta x_2 + 2\alpha\beta \sqrt{x_1 x_2} \\
&\geqslant \alpha x_1 + \beta x_2 -(\alpha\beta)(x_1 + x_2) + 2\alpha\beta\sqrt{x_1 x_2}
\end{align*}
which is true if 
$$x_1 + x_2 \geqslant \sqrt{x_1 x_2}$$
Since $x_1, x_2 \geqslant 0$,
$$x_1 + x_2 \geqslant x_2 = \sqrt{ x_2 x_2} \geqslant \sqrt{x_1 x_2}$$
so the condition holds and $h(x) = \sqrt x$ is concave. \\
\indent Alternatively, applying the identity from part (i) with $x_1 = \sqrt x_1$ and $x_2 = \sqrt x_2$ gives
$$\alpha (\sqrt x_1)^2 + \beta (\sqrt x_2)^2 \geqslant (\alpha\sqrt x_1+ \beta\sqrt x_2)^2$$ 
and taking the square root of both sides gives the desired inequality. \\ %10/19/20
\indent In general, if the condition 
$$f(\alpha x_1 + \beta x_2) \geqslant \alpha f(x_1) + \beta f(x_2)$$ 
holds and $f$ is strictly increasing, then $f$ has an inverse $f^{-1}$ and, writing $y_1 = f(x_1)$ and $y_2 =  f(x_2)$,
$$f^{-1}(f(\alpha x_1 + \beta x_2)) \geqslant f^{-1}(\alpha y_1 + \beta y_2)$$
simplifies to  
$$\alpha f^{-1}(y_1) + \beta f^{-1}(y_2) \geqslant f^{-1}(\alpha y_1 + \beta y_2)$$
so if $f$ is convex and strictly increasing then its inverse $f^{-1}$ is concave and vice-versa.} %3/18 (ii)-(iv) (FUCKING FINALLY) ~6-8pm [reviewed 10/19/20]

\newpage
\chapter{Exponentiation}
\exercise{(page 88) Let $a>0$. We know (almost from our primary school arithmetic) that 
$$a^x\times a^y = a^{x+y} \text{\quad and \quad} a^x \div a^y = a^{x-y}$$
for each pair of rational numbers $x$ and $y$. By considering sequences of rationals show that these rules extend to \textit{any} pair of numbers $x$ and $y$. \\
Deduce that if $a>1$ then the function $f(x) = a^x \enspace (x\in\mathbb{R})$ is strictly increasing and that if $0<a<1$ the function is strictly decreasing.} %3/18
\solution{If $x_n\to x$ and $y_n\to y$ are increasing sequences of rationals, then $a^{x_n} \to a^x$ and $a^{y_n} \to a^y$ as shown in the chapter text. The sequences $(a^{x_n}a^{y_n})$ and $(a^{x_n+y_n})$ are equal, so they converge to the same value. The sequence $(x_n + y_n)$ converges to $x + y$ so that $a^{x_n + y_n}$ converges to $a^{x+y}$. Similarly $(a^{x_n} a^{y_n})$ converges to $a^xa^y$. Then the sequences $a^{x_n+y_n}$ and $a^{x_n}a^{y_n}$ which have the same value at every term converge to the equal limits $a^{x+y} = a^xa^y$. \\
\indent The expression $a^x\div a^y$, can be rewritten as $a^x \times a^{-y}$, which was just showed to be equal to $a^{x+ (-y)} = a^{x-y}$. \\
\indent If $x_1<x_2$ then $f(x_2)/f(x_1) = a^{x_2} \div a^{x_1} = a^{x_2-x_1}$ so that if $0<a<1, \enspace a^{x_2-x_1} < 1$ and $f(x)$ is strictly decreasing, and if $a>1, \enspace a^{x_2-x_1} > 1$ and the function is strictly increasing.}%3/19 [reviewed 10/19/20]
\exercise{Let $f$ be any function with domain $\mathbb{R}$ for which: \\
(i) $f(1)$ is positive (call it $a$ say);\\
(ii) $f(x) \times f(y) = f(x + y)$ for each pair of rationals $x$ and $y$. \\
By first dealing with the integers show that $f(x) = a^x$ for each rational number $x.$ \\
\indent Now assume in addition that $f$ has the property that 
$$\textbf{if } x_1, x_2, x_3, \dots \to x \textbf{ then } f(x_1), f(x_2), f(x_3),\dots \to f(x)$$
Deduce that $f(x) = a^x$ for \textit{each} number $x$.} %3/19
\solution{With induction, if $f(1) = a^1$ and $f(n-1) = a^{n-1}$ then $f(n) = f((n-1) + 1) = f(n-1)\times f(1) = a^{n-1} a^1 = a^n$. So for the natural numbers $n>0$ $f(n) = a^n$. If $n= 0$ then $f(0) \times f(x) = f(x)$ so that $f(0) = 1$. \\
\indent For the negative integers, $f(x) \times f(-x) = f(0)$ and $f(-x) = 1/a^x = a^{-x}$.  \\
\indent Condition (ii) implies that $f(ax) = f(x)^a$. So if $r$ is a rational and $x/y = r$ where $x,y$ are integers, then $f(yr) = f(r)^y = f(x)$ and $f(r) = \sqrt[y]{f(x)} = \sqrt[y]{a^x} = a^{x/y}$ and so $f(x) = a^x$ for each rational number $x$. \\
\indent If the third condition holds and $(x_n)$ is a rational sequence converging to real number $x$, then $f(x)$ equals the limit of the sequence $a^{x_n}$ which is $a^x$.} %3/19 [reviewed 10/19/20]
\exercise{Let $a>0$. Show that for each pair of positive numbers $x$ and $y$ we have 
$$\log_a(xy) = \log_a x + \log_a y \text{\quad and \quad} \log_a\frac{x}{y} = \log_a x - \log_a y$$}%3/19
\solution{If $\log_a x = L_x$ and $\log_a y =L_y$ then 
$$a^{L_x + L_y} = a^{L_x} \times a^{L_y} = xy$$ 
thus $\log(xy) = L_x + L_y$. \\
\indent Likewise 
$$a^{L_x-L_y} = a^{L_x}\times a^{-L_y} = \frac{a^{L_x}}{a^{L_y}} = \frac{x}{y}$$
and $\log_a (x/y) = L_x - L_y$.}%3/19 [reviewed 10/19/20]
\exercise{Imagine that you had two copies of a ruler marked out in a 'logarithmic scale' as shown: \\
(In this case the number $x$ is marked at a distance proportional to $\log_10 x$ from the left-hand end.) Explain how you would use these rulers to multiply and divide two numbers. (This was the basis of the 'slide rule'.)} %3/19
\solution{Since $\log(x) +\log(y) = \log(xy)$, given two numbers $x$ and $y$ you could move one of the rulers (ruler 2) so that the line marked '1' is lined up with the line marked $x$ (on ruler 1). Then measuring out to $y$ on ruler 2 and looking at the projection of the line onto ruler 1 gives the distance $\log x + \log y$. The mark at this location indicating the number $z$ means that the distance measured is $\log z$. Therefore we have $\log x + \log y = \log z$ and $z=xy$. \\
\indent To divide two numbers $x\div y$, the $y$ marking on the second ruler must be lined up to the $x$ marking on the first and the distance measured in the reverse direction to 1. The reading of this point on the first ruler is $\log z = \log x - \log y$ and $z$ indicates the value of $\frac{x}{y}$.} %3/19 [reviewed 10/19/20]

\newpage
 
\chapter{Limits of functions}
\exercise{(page 95) In each of the following cases decide either that the limit is a real number (in which case find it) or $\infty$ or $-\infty$ or that it does not exist. Justify your answer in each case.
$$\text{(i) } \lim_{x\to 1} (x-[x]) \quad \text{(ii) } \lim_{x\to 2} |x -[x]-\tfrac{1}{2}| \quad \text{(iii) }\lim_{x\to 0} \log_{10} x_0$$ } %3/19
\solution{(i) Looking at the sequence $1 + (-1)^n/n\to 1$, the limit of $(x-[x])$ converges at 1 if the sequence 
$$(1+ (-1)^n/n) - [1 + (-1)^n /n]$$
converges. If $n$ is even then the $n$th term of the sequence evaluates to 
$$(1 + \tfrac{1}{n}) - [1 +\tfrac{1}{n}] = 1 + \tfrac{1}{n} - 1 = \tfrac{1}{n}\to 0$$
but if $n$ is odd the $n$th term of the sequence is  
$$(1 - \tfrac{1}{n}) - [1 - \tfrac{1}{n}] = 1 - \tfrac{1}{n} \to 1$$
\indent So the sequence $f(x_1), f(x_2), f(x_3), \dots$ has two subsequences that converge with different limits and therefore diverges. Then the limit of $f$ at $x=1$ does not exist. \\
\indent (ii) If $x_n\to2$ then $f(x_n)$ is the sequence
$$|x_n - [x_n] - \tfrac{1}{2}| \to |\tfrac{3}{2} - [x_n]|$$
\indent Given $\epsilon >0$ there is an $N$ with $2-\epsilon <x_n<2+\epsilon$ for all $n\geq N,$ so if $\epsilon = 1$ then $1 < x_n < 3$ past a certain point and either $[x_n] = 1$ or $[x_n] = 2$. But 
$$|\tfrac{3}{2} -1| = |\tfrac{1}{2} =  \tfrac{1}{2} = |-\tfrac{1}{2}| = |\tfrac{3}{2} - 2|$$ 
so that $|\tfrac{3}{2} - [x_n]| \to \frac{1}{2}$ and $\lim_{n\to 2}|x - [x] - \frac{1}{2}| = \frac{1}{2}$. \\
\indent (iii) If $x_n \to 0$ (and $x_n$ is positive for each $n$) then for $\epsilon = 1/10^k$, there is an $N$ with
$$x_n < \frac{1}{10^k} \implies \log_{10} x_n < -k$$ 
when $n\geqslant N$. Then for any $k$ there is an $N$ so that $f(x_n) < -k$ when $n\geqslant N$, and the limit tends to $-\infty$.} %3/19
\exercise{Let $f$ be the function given by 
$$f(x) = \begin{cases} 
\frac{|x|^2 + x|x| - 2}{x-1}\enspace & x\neq 1 \\
3 & x = 1
\end{cases} $$
Show that for each $x_0 \in \mathbb{R}$ the limit $\lim_{x\to x_0} f(x)$ exists and that for $x_0 \neq 1$ the limit equals $f(x_0)$ itself. \\
\indent Sketch the graph of $f$. \\
\indent To what number would you change the '3' in the definition of $f$ in order to get a function whose graph does not have a 'break'?} %3/19
\solution{Let $x_0 \neq 1$ and $x_n\to x_0$ be a convergent sequence. Past some $N$ none of the terms in the sequence $x_N, x_{N+1}, x_{N+2}$ are equal to 1. Then the terms of the sequence $(f(x_n))$ when $n\geqslant N$ evaluate to 
$$\frac{|x_n|^2 + x_n|x_n| - 2}{x_n-1} \to \frac{x_0^2 + x_0|x_0| - 2}{x_0-1}$$
which is defined for all $x_0 \neq 1$ and is equal to $f(x_0)$. \\
\indent If $x_0 = 1$ and $x\to x_0$, then taking $\epsilon = 1$ after a certain $N$ all terms $x_n$ are positive. Then for $n\geqslant N$,
$$f(x_n) = \frac{2x_n^2 - 2}{x_n-1} = 2\frac{x_n^2-1}{x_n-1} = 2(x_n+1) \to 4$$
as $x_n \to 1$. \\
\indent According to the graph of $f$, when $x\geqslant 0$ $f$ is the line $y = 2x + 2$ for $x\neq 1$. The number '3' in the definition of $f$ should be changed to 4 to get a graph that does not have a 'break'.} %3/19  

\newpage
\chapter{Continuous improvements}
\exercise{(page 106) Suppose that $f$ and $g$ are functions with $g$ continuous at some point $x_0$ and $f$ continuous at $g(x_0).$ Show that the composite function $f\circ g$ is continuous at $x_0$. \\
\indent Show that the function $h(x) = [\log_2 x]$the integer part of the $\log_2 x$is continuous at $x=3$.} %3/20
\solution{If $x_1, x_2, x_3, \dots\to x_0$ is a convergent sequence in the domain of $f\circ g$ then $(x_n)$ is a sequence in the domain of $g$ and $g(x_1), g(x_2), g(x_3), \dots$ converges to $g(x_0)$. Then $g(x_n)$ is a sequence in the domain of $f$ and $(f\circ g)(x_1), (f\circ g)(x_2), (f\circ g)(x_3),\dots \to (f\circ g)(x_0)$. \\
\indent The $\log$ function $g(x) = \log_2 x$ is continuous for $x>0$ so it is continuous at $x=3$. The integer part function $f(x) = [x]$ is continuous at all non-integer points, so it is continuous at $\log_2 3$. Then $h(x) = (f\circ g)(x) = [\log_2 x]$ is continuous at $x=3$.} %3/20  [reviewed 10/30/20]
\exercise{Let $n$ be a positive integer and let $r$ be any rational number. Show that the following functions are continuous: 
\begin{alignat*}{2}
\text{(i) }&f(x) = x^n &&(x\in \mathbb{R}) \\
\text{(ii) } &g(x) = x^{-n} &&(x\neq 0) \\
\text{(iii) } &h(x) = \sqrt[n] x \quad&& (x\geqslant 0) \\
\text{(iv) } &j(x) = x^r &&(x> 0) 
\end{alignat*}}
\solution{(i) If $x_1, x_2, x_3, \dots \to x_0$ is a convergent sequence of real numbers then $x_1^n, x_2^n, x_3^n, \dots$ is the product of convergent sequences and converges to $x_0^n$. Then $f(x)= x^n$ is continuous. \\
\indent (ii) $g(x)$ is the reciprocal of $f(x)$, so since $f(x)$ is continuous the sequence $g(x_1), g(x_2), g(x_3), \dotsc = 1/f(x_1), 1/f(x_2), 1/f(x_3), \dots$ converges to $g(x_0) =  1/f(x_0)$ for any convergent sequence $x_1, x_2, x_3,\dots \to x_0$ of non-zero real numbers. \\
\indent (iii) The $n$th root of $x$ is the inverse of the continuous function $f(x) = x^n$ with domain restricted to $x\geq 0$, so $h(x) = \sqrt[n] x$ is continuous on the range of $f,\enspace x\geq 0$. \\
\indent (iv) With $r$ rational, $r =m/n$ for integers $m, n$. Then $x^r = \sqrt[n]{x^m}$ is the composition of two continuous functions and $j(x)$ is continuous on its domain.}%3/20 [reviewed 10/30/20]
\exercise{Let $f$ be a continuous function with domain $D$ and range contained in $D$, and let $a\in D.$ Suppose that we define a sequence $(x_n)$ by the recurrence relation
$$x_1 = a \text{\quad and \quad} x_n = f(x_{n-1}) \text{\quad for \quad} n>1$$
and that the sequence converges to $x_0$. Show that $x_0 = f(x_0)$. \\
\indent Note that the function $f$ given by 
$$f(x) = \frac{x^3 + 2x^2 + 1}{8} \quad x\in\mathbb{R}$$ 
is continuous. Let $x_1 = 0$ and use $f$ to define a sequence $(x_n)$ in the above way. Use your calculator to work out the first few terms of this sequence and hence find, to three decimal places, a root of the equation 
$$x^3 + 2x^2 - 8x + 1 = 0$$} %3/20
\solution{The sequence $(x_n)$ is fully contained in the domain of $f$ by inductive reasoning. Then the sequence $f(x_1), f(x_2), f(x_3), \dots$ converges to $f(x_0)$. Since $x_n = f(x_{n-1})$ the sequences converge to the same limit. Therefore $x_0 = f(x_0)$. \\
\indent The first few terms of the sequence are 
$$.125, \enspace .12915,\enspace .12944, \enspace .12946$$ 
The sequence appears to converge to .129. Then $f(.129) =.129$ and therefore $x =.129$ is a root of the equation $f(x) - x$,
$$\frac{x^3 + 2x^2 + 1}{8} - x = x^3 + 2x^2 -8x + 1 = 0$$}%3/20 [reviewed 10/10/20]
\exercise{Assume that $f$ is a strictly increasing function with domain $(0, \infty)$ and range $\mathbb{R}$ which satisfies 
\begin{align*}
\text{(i) } &f(a) = 1\\
\text{(ii) } &f(x\times y) = f(x) + f(y) \text{\quad for each } x,y> 0 \end{align*}
Show that $f^{-1}$ is a continuous function which satisfies
\begin{align*}
\text{(i)}' \, &f^{-1}(1) = a \\
\text{(ii)}'\, &f^{-1}(x+y) = f^{-1}(x) \times f^{-1}(y) \text{\quad for each } x, y \in \mathbb{R}
\end{align*}
Deduce that $f(x) = \log_a x$ for each $x >0$}
\solution{The function $f$ is strictly increasing with an interval domain, so $f^{-1}$ is continuous on the range of $f$. Property (i)$'$ is a consequence of taking $f^{-1}$ on both sides of property (i). If $x$ and $y$ are in the domain of $f$, then $f(x)$ and $f(y)$ are in the domain of $f^{-1}$. By property (ii),
$$f^{-1}(f(x) + f(y)) = f^{-1}(f(x\times y)) = x \times y = f^{-1}(f(x)) \times f^{-1}(f(y))$$
Now if $x' = f(x)$ and $y' = f(y)$ are in the domain of $f^{-1}$, then
$$f^{-1}(x' + y') = f^{-1}(x') \times f^{-1}(y')\text{ for } x', y' \in \mathbb{R}$$ 
which is property (ii). \\
\indent An earlier problem showed that any function satisfying (i)$'$ and (ii)$'$ is the function $a^x$, so the function $f^{-1}(x) = a^x$ and $f(x) = \log_a x$.} %3/20 [reviewed 10/30/20]
\exercise{Let $f$ be a continuous function whose domain includes the interval $[a,b]$ and let $x_0 \in (a,b)$ have $f(x_0) > 0$. Show that $f$ is positive throughout some interval surrounding $x_0$.} 
\solution{The function $f$ is continuous, so for any sequence $(x_n)$ on the interval $[a,b]$ that converges to $x_0$ there is a $N$ with 
$$f(x_0) - \epsilon < f(x_n) < f(x_0) + \epsilon$$ 
for $n\geq N$. As long as $\epsilon$ is chosen so that $0 < f(x_0) - \epsilon$, then $f(x_n)$ is positive for $n\geq N$. \\
\indent If $(x_n)\to x_0$ is an increasing sequence then there is an $N$ for which $f$ is positive on the interval $(x_N, x_0)$. Likewise for a decreasing sequence $(y_n)\to x_0$ there is an $M$ so that $f$ is positive on $(x_0, y_M).$ Then on the interval $I = (x_N, y_M)$ and $x_0\in I$.}%3/20 [reviewed 10/30/20]

\newpage\chapter{Exp and log} 
\exercise{(page 118) Show that the function $f(x) = e^{-x} \enspace (x\in \mathbb{R})$ is continuous.\\
\indent Let $x_1 = 0$ and $x_n = f(x_{n-1})$ for $n>1$ (as in exercise 3 on page 107). Calculate the first few terms of the sequence $(x_n)$ and hence find, to three decimal places, a root of the equation $x + \log x = 0$.\\
\indent Sketch the graphs $y = \log x$ and $y =-x$ on the same axes and observe that the equation $x - \log x = 0)$ has a unique solution.} %3/21
\solution{First, the function $e^x$ is continuous. Since $f(x) = e^{-x} = 1/e^x$     is the quotient of two continuous functions and $e^x\neq0$, $f$ is continuous.  \\ 
\begin{figure}[h!]
\center
\includegraphics[width= .64\linewidth]{figure_1.png}
\caption{}
\label{fig:plot}
\end{figure} \\
\indent The first few terms of the sequence are 0, 1, .368, .692, .500, .606, .545, $\dots$ and the sequence tends to .567. A graph is below 
in Figure \ref{fig:plot} showing that $x + \log x =0$ has a unique solution.} %3/21 [reviewed 11/04/20, need to change the plot]
\exercise{Use the fact that $e^{\alpha \beta} = (e^\alpha)^\beta$ to show that 
\begin{align*}
\text{(i) } &a^x = e^{x\log a} \text{ for each positive number $a$ and each number $x$;}\\
\text{(ii) } &\log_a x = \log x / \log a \text{ for each positive $a$ and $x$ with $a\neq 1.$}
\end{align*}}%3/21
\solution{(i) $e^{x \log a} = (e^{\log a})^x = a^x$. \\
\indent (ii) 
\begin{align*}
\log_a x = y &\implies x = a^y \\
&\implies \log x = \log a^y \\
&\implies \log x = y \log a \\
&\implies y = \log x / \log a =  \log_a x
\end{align*}}%3/23 [reviewed 11/04/20]
\exercise{(i) Let $x$ and $x_0$ be two different positive numbers. By referring to the shaded area illustrated below show that 
$$(x-x_0)\frac{1}{x} < \log x - \log x_0 < (x-x_0) \frac{1}{x_0}$$
Deduce that 
$$\lim_{x\to x_0} = \frac{\log x- \log x_0}{x - x_0} = \frac{1}{x_0}$$
\indent (ii) Let $P$ be the point $(x_0, \log x_0)$ on the graph of the log function and let $Q$ be any other point $(x, \log x)$ on that graph. Find in the terms of $x_0$ and $x$ the gradient of the chord $PQ$. Show that this gradient tends to $1/x_0$ as $Q$ approaches $P$. (We are therefore tempted to say that the gradient of the log function at $P$ equals $1/x_0$.)} %3/23
\solution{The log function is the area under the curve of $1/x$ from $x=1$ to $x=x$, so the expression $\log x - \log x_0$ is the area under $1/x$ from $x=x_0$ to $x=x$. The log function is strictly decreasing so the rectangle of area with its left edge touching the curve will contain area above the curve, and the rectangle of area with its right edge touching the curve will contain less than the area under the curve. The former is described by $(x-x_0) 1/x_0$ and the latter is described by $(x-x) 1/x$. Hence the inequality
$$(x-x_0)\frac{1}{x} < \log x - \log x_0 < (x-x_0) \frac{1}{x_0}.$$
Dividing on all sides by $(x-x_0)$ and taking the limit as $x\to x_0$ gives that 
$$\frac{1}{x_0} < \lim_{x\to x_0} \frac{\log x - \log x_0}{x-x_0} < \frac{1}{x_0}$$
so the limit is constrained on both sides by $1/x_0$ and converges to that limit.
\indent (ii) The gradient of $PQ$ is 
$$\frac{\log x - \log x_0}{x-x_0}$$ 
which was just showed to tend to $1/x_0$ as $x\to x_0$.}%3/23 [reviewed 11/04/20]

\newpage
\chapter{Going round in circles}
\exercise{(page 132) Show that the cosine function is continuous and that 
$$\lim_{x\to x_0} \frac{\cos x - \cos x_0}{x-x_0} =-\sin x_0$$
Interpret that result in terms of gradients.} %3/23
\solution{Given that the sine function is continuous, the cosine function is $\cos x =\sin(\frac{\pi}{2}-x)$ which is the composition of continuous functions and therefore continuous. \\
\indent Using the double angle formula,
$$\frac{\cos x - \cos x_0}{x-x_0} = \frac{-2\sin\frac{x-x_0}{2}\sin\frac{x+x_0}{2} }{x-x_0} = -1\times \frac{\sin\frac{x-x_0}{2}}{\frac{x-x_0}{2}}\times \sin\frac{x+x_0}{2} \to -1\times 1 \times \sin x = -\sin x.$$
\indent Alternatively, using $\cos x = \sin(\pi/2-x)$, 
$$\frac{\cos x - \cos x_0}{x-x_0} = \frac{\sin(\pi/2-x)-\sin(\pi/2-x_0)}{-[(\frac{\pi}{2}-x)-(\frac{\pi}{2}-x_0)]}\to -\lim_{y\to y_0}\frac{\sin y -\sin y_0}{y-y_0} = -\cos y_0 = -\sin x.$$
\indent In terms of gradients that means that the gradient of the cosine curve at any point $x$ is $-\sin x$.}%3/23 [reviewed 11/04/20 Needs more work]
\exercise{Prove that 
$$\sin^{-1}x = \frac{\pi}{2} - \cos^{-1} x$$
for each $x\in[-1,1].$} %3/23
\solution{The fact that $\sin(\frac{\pi}{2} - y) = \cos y$ with $\cos y = x$ gives that $\sin(\frac{\pi}{2}-\cos^{-1}x) = x$. Then for any $x$ in the domain of $\sin^{-1}$ and $\cos^{-1}$,
\begin{align*}
\sin^{-1}x &= \frac{\pi}{2} - \cos^{-1} x \\
\iff x &= \sin\left(\frac{\pi}{2} - \cos^{-1} x\right)\\
\iff x &= x
\end{align*} }%3/25 [reviewed 11/09/20]
\exercise{Prove that 
\begin{align*}
\text{(i) } &\cosh^2 x -\sinh^2 x = 1 \\
\text{(ii) } &\sinh(x+y) = \sinh x \cosh y + \sinh y \cosh x
\end{align*}
and that if tanh is defined by 
$$\tanh =\frac{\sinh x}{\cosh x} \quad x\in\mathbb{R}$$
then 
$$\text{(iii) } \tanh(2x) = \frac{2\tanh x}{1 + \tanh^2 x}$$} %3/25
\solution{(i)
$$\left(\frac{e^x + e^{-x}}{2}\right)^2 -\left(\frac{e^x-e^{-x}}{2}\right)^2 = \frac{e^{2x} + 2 + e^{-2x} - (e^{2x} - 2 + e^{-2x})}{4} = \frac{4}{4} = 1$$
\indent (ii)
\begin{align*}
\sinh(x+y) &= \frac{e^{x+y} - e^{-x-y}}{2} \\
&= \frac{\tfrac{1}{2}(e^{x+y} + e^{x-y} - e^{-x+y} - e^{-x-y}) + \tfrac{1}{2}(e^{x+y}-e^{x-y} +e^{-x+y} -e^{-x-y})}{2} \\
&= \frac{(e^x-e^{-x})(e^y+e^{-y})}{4} + \frac{(e^x + e^{-x})(e^y - e^{-y})}{4} \\
&= \sinh x \cosh y + \cosh x \sinh y
\end{align*}
\indent (iii) 
\begin{align*}
\frac{2\tanh x}{1 +\tanh^2 x} &= 2\frac{\sinh x}{\cosh x}\cdot \frac{1}{1 + \frac{\sinh^2 x}{\cosh^2 x}}  \\
&= 2\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} \cdot \frac{2\cosh^2 x}{(e^x + e^{-x})^2 + (e^x-e^{-x})^2}  \\
&= \frac{2(e^x-e^{-x})(e^{x}+e^{-x})^2}{(e^x+e^{-x})2(e^{2x}+e^{-2x})} \\
&= \frac{e^{2x}-e^{-2x}}{e^{2x}+e^{-2x}} \\
&= \tanh (2x)
\end{align*}}%3/25 [reviewed 11/09/20]
\exercise{For any $x\in \mathbb{R}$ let $y = \sinh^{-1} x.$ Show that 
$$e^{2y} - 2xe^y - 1 = 0$$
and deduce that 
$$\sinh^{-1} x = \log(x + \sqrt{1 + x^2})$$} %3/25
\solution{
\begin{align*}
e^{2y} -2xe^y - 1 &= e^{2y} -2\left(\frac{e^y-e^{-y}}{2}\right)e^y - 1. \\
&= e^{2y} - (e^y - e^{-y})e^y - 1 \\
& = 0
\end{align*}
The quadratic formula gives
$$e^y = \frac{2x \pm \sqrt{4x^2 +4}}{2} = x\pm \sqrt{x^2 + 1}$$
and $ x - \sqrt{x^2 +1} < 0 $ so 
$$e^y = x \pm \sqrt{x^2+1} \implies y = \log(x + \sqrt{x^2 +1})$$
so that $\sinh^{-1}x = \log(x + \sqrt{1 + x^2})$.} %3/25 [reviewed 11/09/20]
\exercise{Let the functions $f$ and $g$ be defined by 
$$f(x) = \begin{cases} \sin(1/x) &\text{if } x\neq 0 \\ 0 & \text{if } x =0\end{cases} \quad g(x) = \begin{cases} x\sin(1/x) &\text{if }x\neq 0 \\ 0 &\text{if } x=0\end{cases}$$
Show that $f$ is not continuous at $x=0$ but that $g$ is continuous. Sketch the graphs of $f$ and $g$.} %3/25
\solution{If $x_n\to 0$ is a sequence of positive terms then $1/x_n$ tends to infinity, so the sequence $\sin(1/x_n)$ diverges. Then the limit of $f(x)$ as $x\to 0$ does not exist. \\
\indent The limit of $x\sin(1/x)$ as $x\to 0$ is the product of a convergent sequence that tends to 0 and a bounded sequence $\sin 1/x_n \in [-1, 1]$. Alternatively, $-1\leq \sin 1/x_n \leq 1$ implies that $x\sin1/x_n \leq |x|$. Then $-x_n \leq x_n\sin1/x_n\leq x_n$ and $g(x)$ is bounded by sequences that converge to 0. So the limit $\lim_{x\to 0} g(x) = 0 = g(0)$ and $g$ is continuous at 0. %[reviewed 11/09/20]
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{p132ex5f.pdf}
		\caption{Graph of f(x)}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{p132ex5g.pdf}
		\caption{Graph of g(x)}
	\end{subfigure}
	\label{fig:p132ex5}
\end{figure}}

\newpage
\chapter{Two acts with an interval}
\exercise{(page 142) Let $f$ be a continuous function whose domain includes the interval $[a,b]$ and assume that $f(a)<0$ and $f(b)>0$. Suppose that we wish to find a number within $\epsilon \enspace (>0)$ of a root of the equation $f(x)=0$. Show that the bisection method outlined in the flow-chart on page 136 will always terminate at such a number. \\
\indent Use the bisection method to find a number within .002 of a root of the equation $\tan x - x =0$ between $\pi/2$ and $3\pi/2$. \\
\indent (In fact that root turns out to be precisely the point where the function $h(x) = (\sin x)/x\enspace (x>0)$ achieves its minimum, as illustrated on page 139.)} %3/26
\solution{The bisection method involves two sequences, $l_n$ and $m_n$, such that 
$$l_{n+1} = \begin{cases}\frac{(l_n+m_n)}{2} &\text{if }f((l_n+m_n)/2) \leqslant 0 \\
l_n& \text{if } f((l_n+m_n)/2) > 0\end{cases}$$
\indent and
$$m_{n+1} = \begin{cases} \frac{(l_n + m_n)}{2} &\text{if }f((l_n + m_n)/2) \geqslant 0 \\ m_n&\text{if } f((l_n + m_n)/2) < 0\end{cases}$$
where $l_1 = a$ and $m_1 = b$. Then $(l_n)$ defines an increasing sequence bounded above by $b$ and $(m_n)$ defines a decreasing sequence bounded below by $a$, so the sequences converge to $l$ and $m$ respectively. Now
$$l_n-m_n = \frac{l_n-m_n}{2}$$
implies that $l=m$. Then by the continuity of $f$, the sequences $f(l_n)\to f(l)$ and $f(m_n)\to f(m)$. Since $f(l_n) \leqslant 0$ and $f(m_n) \geqslant 0$ for all $n$, we have $0\leqslant f(m)=f(l)\leqslant 0$ and both sequences converge to zero. Then the process will terminate, i.e. there is a $N$ so that $l_n$ and $m_n$ will be within $\epsilon (>0)$ of $l$ and $m$, which are a root of $f$. \\
\indent Applying the bisection method to $f(x) = \tan x -x$ on the interval $[\frac{\pi}{2}, \frac{3\pi}{2}]$ gives $l_{14} = 4.49303$ and $m{14} = 4.493797$ so the root is within .002 of .493.} %3/26
\exercise{Show that a cubic equation (i.e. one of the form $ax^3 + bx^2 + cx + d = 0$ where $a\neq 0)$ has at least one real root.} %3/26
\solution{Dividing by $a$, the cubic equation can be represented as the monic polynomial 
$$x^3 + b_1x^2 + c_1x + d_1 = 0.$$
\indent This equation has at least one root if for some $x_1<x_2$, $\enspace f(x_1) < 0$ and $f(x_2) > 0$. Then by the intermediate value theorem $f(c) = 0$ for some $x_1 < c < x_2$. Because $x^3$ outgrows smaller powers of $x$, for some large negative $x$ the function is negative, and for some large positive $x$ the function is positive.} %3/27
\exercise{Let $f$ be a continuous function whose domain is $[a,b]$ and whose range is a subset of $[a,b]$. By considering the function $g$ given by $g(x) = f(x)-x$ show that there is at least one $x_0$ in $[a,b]$ with $x_0 = f(x_0)$. \\
\indent Consider the function $f$ given by $f(x) = \cos x\enspace (x\in[0,\pi/2])$. Show that the range is a subset of $[0,\pi/2]$ and by sketching the graphs of $y=f(x)$ and of $y=x$ observe that in this case there is precisely one $x_0$ with $x_0 = f(x_0)$.\\
\indent Choose any $x_1\in[0,\pi/2]$ and (as in exercise 3 on page 107) define a sequence $(x_n)$ by $x_n = f(x_{n-1})$ for each $n>1.$ Calculate the first few terms of this sequence and hence find, correct to four decimal places, the unique root of the equation $\cos x - x = 0$.} %3/27
\solution{Since the range of $f$ is a subset of its domain $[a,b]$, $f(a)\geqslant a$ and $f(b)\leqslant b$. Therefore $g(a) = f(a)-a \geqslant 0$ and $g(b) = f(b) - b \leqslant 0$. By the intermediate value theorem and the continuity of $g$, there is an $x_0$ with $g(x_0) = 0$, and consequently $f(x_0) = x_0$. \\
\indent The cosine function is continuous on the interval $[0,\pi/2]$ so its range is a closed interval and bounded interval. Since it is strictly decreasing the interval is between $\cos 0$ and $\cos \pi/2$. Then the range is $[0, 1]$ which is a subset of $[0, \pi/2].$ The graph shows there is only one intersection between $y=x$ and $f(x)$.\\
\begin{figure}[h!]
\center
\includegraphics[width=.70\linewidth]{p142ex3.pdf}
\end{figure} \\ %3/27
\indent Using $x_1 = .75$, the first few terms of the sequence are .75, .7317, .7440, .7357, .7413, .7376, .7401, .7384, .7395, .7388, .7393, .7389, .7392, .7390, .7391, .7391, $\dots$ and so unique root of $\cos x - x =0$ is $x=.7391$ correct to four decimal places. }
\exercise{Let $f$ be a continuous function with domain $[a,b]$. By the last theorem $f$'s range is of the form $[\alpha, \beta]$ for some $\alpha$ and $\beta$. Assume that $f(x_0) = \beta$ and let $P$ be the point $(x_0, f(x_0))$ on the graph of $f$. Show that \\
\indent (i) if $x_0 < x \leqslant b$ and $Q$ is the point $(x, f(x))$ on the graph of $f$, then the gradient of the chord $PQ$ is less than or equal to 0;\\
\indent (ii) if $a\leqslant x < x_0$ and $Q$ is the point $(x, f(x))$ on the graph of $f$, then the gradient of the chord $PQ$ is greater than or equal to 0. } %3/27
\solution{The gradient of the chord PQ in either case is
$$m_{PQ}= \frac{f(x) - f(x_0)}{x-x_0}.$$ 
\indent Because the range of $f$ is $[\alpha, \beta]$, for any $x$ in the domain of $f$ $f(x) \leqslant \beta = f(x_0)$. So $f(x) - f(x_0) \leqslant 0$ and the numerator of the gradient is negative or zero.\\
\indent In case (i), $x_0 < x$ implies $x-x_0>0$ and the denominator of the gradient is positive. Therefore the gradient $m_{PQ}$ is less than or equal to 0. \\
\indent In case (ii), $x < x_0$ implies $x-x_0<0$ and the denominator is negative. Then the gradient is greater than or equal to 0.} %3/27

\newpage
\section{Calculus at last} 
\chapter{Differentiation}
\exercise{(page 149) Let $m$ be a positive integer. Show that for any numbers $x$ and $x_0$ 
$$(x-x_0)(x^{m-1} + x^{m-2}x_0 + x^{m-3}x_0^2 + \dots + xx_0^{m-2} + x_0^{m-1})$$
$$=x^m - x_0^m$$
and deduce that 
$$\lim_{x\to x_0} \frac{x^m-x_0^m}{x-x_0} = mx_0^{m-1}$$
Hence show that if the function $f$ is given by $f(x) = x^m \enspace (x\in\mathbb{R})$ then $f$ is differentiable with derivative given by $f'(x) = mx^{m-1}$.} %3/28
\solution{By induction on $m$, if $m=1$, then 
$$(x-x_0)(x^{1-1} + x_0^{1-1}) = x-x_0$$
and if the identity holds for $m$, then for $m+1$
\begin{align*}
\mathrlap{(x-x_0)(x^m + x^{m-1}x_0 + x^{m-2}x_0^2 + x^{m-3}x_0^3 + \dots + xx_0^{m-1} + x_0^{m})}\\
&=(x-x_0)\left(x_m + (x^{m-1} + x^{m-2}x_0 + \dots + xx_0^{m-2} + x_0^{m-1})x_0\right) \\
&=(x-x_0)x^m + (x^m-x_0^m)x_0 \\
&= x^{m+1} - x_0x^m + x^mx_0 - x_0^{m+1} \\
&= x^{m+1} - x_0^{m+1}.
\end{align*}
So the limit
$$\lim_{x\to x_0} \frac{x^m-x_0^m}{x-x_0} = \lim_{x\to x_0} \sum_{i=1}^m x^{m-i}x_0^{i-1} \to \sum_{i=1}^m x_0^{m-i}x_0^{i-1} = \sum_{i=1}^m x_0^{m-1} = m x_0^{m-1}$$  
and the derivative of $f(x) = x^m$ at $x=x_0$ is $f'(x_0) = mx^{m-1}$ for all $x_0\in\mathbb{R}$.} %3/28
\exercise{Let $f$ be a differentiable function with domain $D$, let $k$ be any number and let $g$ be the function given by
$$g(x) = kf(x)\quad x\in D$$
Show that $g$ is differentiable and that $g'(x) = kf'(x)$ for each $x\in D$.} %3/28
\solution{If $f$ is differentiable on $D$ then the derivative of $g$ at $x_0 \in D$ is
$$g'(x_0) = \lim_{x\to x_0} \frac{g(x)-g(x_0)}{x-x_0} = \frac{kf(x)-kf(x_0)}{x-x_0} = kf'(x_0)$$} %3/28
\exercise{(i) Let $f$ be a function which is differentiable at $x_0$ with $f(x_0) \neq 0$ and let $g$ be the function given by $g(x) = 1/f(x)$. Show that 
$$\lim_{x\to x_0}\frac{g(x)-g(x_0)}{x-x_0} = \lim_{x\to x_0} -\frac{1}{f(x)}\cdot \frac{1}{f(x_0)}\cdot \frac{f(x)-f(x_0)}{x-x_0}$$ 
and deduce that $g$ is differentiable at $x_0$ with derivative
$$g'(x_0) = -\frac{f'(x_0)}{(f(x_0))^2}$$
(ii) Now let $g(x) = x^{-m}\enspace (x\neq 0)$ where $m$ is a positive integer. Use the first part of this exercise to show that $g'(x) = -mx^{-m-1}.$ \\
\indent Hence show that the rule 
$$f(x) = x^n \implies f'(x) = nx^{n-1}$$
works for any integer $n$.} %3/28
\solution{(i) First
$$g(x) -g(x_0) = \frac{1}{f(x)} - \frac{1}{f(x_0)} = \frac{f(x_0) - f(x)}{f(x)f(x_0)} = \frac{1}{f(x)}\cdot \frac{1}{f(x_0)}\cdot (-1)\cdot (f(x)-f(x_0))$$
so that 
$$g'(x_0) = \lim_{x\to x_0} \frac{g(x)-g(x_0)}{x-x_0} = \frac{1}{f(x)}\cdot \frac{1}{f(x_0)}\cdot (-1) \cdot \frac{f(x)-f(x_0)}{x-x_0}\to (-1)\frac{1}{f(x_0)^2} f'(x_0)$$
as desired. \\
\indent (ii) If $f(x) = x^m$ and $g(x) = x^{-m} = 1/f(x)$, then by part (i) and exercise 1,
$$g'(x) = \frac{-f'(x)}{f(x)^2}=\frac{-mx^{m-1}}{x^{2m}} = -mx^{m-1-2m} = -mx^{-m-1}$$
so that $g(x) = x^{-m} \implies f'(x) = -mx^{-m-1}$ and the rule introduced in exercise 1 holds for both positive and negative integers.} %3/28
\exercise{(i) Let $l$ be a line of gradient $\alpha\enspace (\neq 0)$ in the coordinate $(x,y)$-plane and let $l'$ be the reflection of $l$ in the line $y=x$: find the gradient of $l'$.\\
\indent Now let $f$ be a function with inverse $g$ if $x_0$ is in $f$'s domain and $g$ has gradient $\alpha \enspace (\neq 0)$ at $f(x_0)$, as illustrated below, what do you expect the gradient of $f$ to be at $x_0$? \\
\indent Now prove that result formally: assume that $g$ is differentiable at $f(x_0)$ with $g'(f(x_0)) = \alpha \enspace(\neq 0)$ and deduce from the definition of the derivative that $f'(x_0) = 1/\alpha.$ \\
\indent (ii) Now let $m$ be a positive integer and let $f$ and $g$ be the functions given by 
$$f(x) = x^{1/m} \quad (x>0) \quad \text{and} \quad g(x) = x^m \quad (x>0)$$
Use the first part of the exercise to show that $f'(x) = (1/m)x^{(1/m)-1}$.\\
\indent (We shall extend this rule even further in the next exercises and show that 
$$f(x) = x^r \implies f'(x) = rx^{r-1}$$
for any rational number $r$, thus confirming that differentiation of powers of $x$ is exactly as expected.)} %3/28
\solution{(i) First of all the fact that $g$ is differentiable means that $g$ is continuous, and $g$ is the inverse of $f$ means that $f$ is continuous. The derivative $g'(f(x_0)) = \alpha$ means that
$$\lim_{f(x)\to f(x_0)} \frac{g(f(x)) - g(f(x_0))}{f(x)-f(x_0)} = \alpha. $$ 
so that continuity of $f$ and $g = f^{-1}$ implies 
$$\lim_{f(x)\to f(x_0)} \frac{g(f(x))-g(f(x_0))}{f(x)-f(x_0)} = \lim_{x\to x_0} \frac{x-x_0}{f(x)-f(x_0)}= \frac{1}{f'(x)} $$ 
so that $f'(x_0) = 1/\alpha$. \\
\indent (ii) With $f$ and $g$ as defined above, and using the fact that $g'(x) = mx^{m-1}$ (from exercise 1),
$$g'(f(x)) = m(f(x))^{m-1} = m(x^{1/m})^{m-1} = mx^{1-(1/m)}.$$
Part (i) just showed that $f'(x) = 1/g'(f(x))$, so this implies 
$$f'(x) = \frac{1}{mx^{1-(1/m)}} = (1/m)x^{(1/m)-1}$$}%3/29

\newpage
\chapter{Combinations of functions}
\exercise{(page 157) Let $a>0$ with $a\neq 1.$ \\
\indent (i) Use the fact that $a^x = e^{x\log a}$ (exercise 2 page 118) to show that if $f(x) = a^x\enspace (x\in \mathbb{R})$ then $f$ is differentiable with derivative given by $f'(x) = a^x\log a$.\\
\indent (ii) Use the fact that 
$$\log_a x = \frac{\log x}{\log x}$$
(exercise 2 page 118 again) to show that if $g(x) = \log_a x \enspace (x > 0)$ then $g$ is differentiable with derivative given by $g'(x) = 1/(x\log a).$} %3/29
\solution{(i) The function $f = a^x = e^{x\log a}$ can be written $f = (h \circ g)$ where $g(x) = x\log a$ and $h(x) = e^x$. By the chain rule $f$, is differentiable with derivative 
$$f'(x) = (h\circ g)'(x) = g'(x)h'(g(x)) = (\log a) e^{x\log a} = a^x \log a.$$
\indent (ii) If $g(x) = \log_a x$ then $g(x) = \frac{\log x}{\log a}$ and $g$ is differentiable with derivative 
$$g'(x) = \frac{(\log x)' (\log a) - (\log x) (\log a)'}{(\log a)^2} = \frac{\frac{1}{e^{\log x}}(\log a) - (\log x) 0}{(\log a)^2}=\frac{1}{x\log a}$$ }%3/29
\exercise{Let the functions $f$ and $g$ be given by 
$$f(x) = \cosh^{-1}(x/2) \enspace (x>2) \quad \text{and}\quad g(x) = \log(x+\sqrt{x^2-4})\enspace (x>2)$$
Use our various results concerning differentiation to show that $f$ and $g$ are differentiable with $f' = g'$. Does this imply $f$ and $g$ are equal? What do you think it \textit{does} imply about $f$ and $g$? (We shall actually deduce the necessary theorems in the next section.)}
\solution{Since $\cosh^{-1} x$ is the inverse of $\cosh x$, the derivative of $\cosh^{-1}x$ is equal to 
$$\frac{1}{(\cosh)'(\cosh^{-1}x)}$$
The equation for  $\cosh x$ is 
$$\cosh(x) = \frac{e^{x}+e^{-x}}{2}$$
so the derivative is
$$(\cosh)'(x) = \frac{e^{x} -e^{-x}}{2} = \sinh x$$
Then the derivative of $\cosh^{-1} x$ is 
$$(\cosh^{-1})'(x) = \frac{1}{\sinh(\cosh^{-1}x)}$$
which simplifies using the identity $\cosh^2x - \sinh^2 x = 1$ to
$$(\cosh^{-1})'(x) = \frac{1}{\sqrt{\cosh^2(\cosh^{-1}x)-1}} = \frac{1}{\sqrt{x^2 - 1}}$$
so the derivative of $f(x) = \cosh^{-1}(x/2)$ is
$$f'(x) = \frac{1}{2\sqrt{(x/2)^2 -1}} =\frac{1}{\sqrt{x^2-4}}$$
by the chain rule.\\
\indent For $g$, the derivative of $\log x$ is $1/x$, so the chain rule gives
$$g'(x) = \left(1 + \tfrac{1}{2}\cdot \frac{1}{\sqrt{x^2 -4}}\cdot 2x\right)\frac{1}{x + \sqrt{x^2-4}} = \left(\frac{\sqrt{x^2-4}+x}{\sqrt{x^2-4}}\right)\frac{1}{x+\sqrt{x^2-4}}= \frac{1}{\sqrt{x^2-4}}$$
so that $f' = g'$. This does not imply $f=g$, but that $f=g+C$ where $C$ is a constant.}%3/29 (11pm at night, help from discord)
\exercise{(i) The function
$$y = F(x) = \sqrt{1-x^2} \quad x\in (-1,1)$$
can be expressed in the alternative 'parametric' form
$$x=f(t) = \cos t\quad y=g(t) = \sin t\quad t\in (0,\pi)$$
Find $F'(x)$ and verify that it equals $g'(t)/f'(t)$. \\
\indent (ii) In general suppose that the function $y= F(x)$ is expressed in parametric form $x=f(t),\enspace y=g(t)$ where $f$ and $g$ are differentiable and $f'(t) \neq 0$. Show that 
$$F'(x) = \frac{g'(t)}{f'(t)}$$
Express this result in terms of $dy/dx$ etc. and note that once again this \textit{appears} to behave as a sensible fraction.}%3/29
\solution{(i) 
$$F'(x) = \frac{-x}{\sqrt{1-x^2}} \overset{x=\cos t}{\implies} F'(x) = \frac{-\cos t}{\sqrt{1-\cos^2 t}} = -\frac{\cos t}{\sin t}$$
$$f'(t) = -\sin t, \quad g'(t) = \cos t$$
$$g'(t)/f'(t) = -\frac{\cos t}{\sin t} = F(x)$$
\indent (ii) If $g(t) = F(f(t))$ then by the chain rule
$$ g'(t) = f'(t) F'(f(t)) \implies F'(x) = \frac{g'(t)}{f'(t)}$$ 
so that $dF(x)/dx = dy/dx$.}%3/30
\exercise{Let the functions $f$, $g$ and $h$ be given by
$$f(x) = \begin{cases}\sin(1/x) &x\neq 0 \\ 0 &x=0\end{cases}\qquad g(x) = \begin{cases} x\sin(1/x) &x\neq 0\\ 0&x=0\end{cases}$$
$$h(x) =\begin{cases} x^2\sin(1/x)&x\neq 0 \\ 0&x=0\end{cases}$$
(as in exercise 5 on page 132). Show that all three functions are differentiable for $x\neq 0$ but that only $h$ is differentiable at $x=0.$ } %3/30
\solution{For $x\neq 0$ each of the three functions is equal to some combination of product and composition of differentiable functions and is therefore itself differentiable. The function $f$ is not even continuous at $x=0$ (the sequence $1/n$ converges to 0 but the sequence $f(1/n)=\sin(n)$ diverges), so it cannot be differentiable at 0. The function $g$ is continuous at 0, but the derivative at zero is equal to
$$\lim_{x_n\to0} \frac{g(0) -  g(x_n)}{0-x_n} = \lim_{x_n\to0}\frac{x_n\sin (1/x_n)}{x_n} = \lim_{x_n\to 0} \sin(1/x_n).$$
\indent Again the limit $\sin(1/x_n) = \sin n$ when $x_n =1/n$ diverges and the derivative of $g$ diverges at 0. However for $h$, if $x_n\to 0$, then
$$\lim_{x_n\to 0} \frac{h(0) - h(x_n)}{0-x_n} = \lim_{x_n\to0} \frac{x_n^2\sin(1/x_n)}{x_n} = \lim_{x_n\to 0} x_n\sin(1/x_n)$$
which is the product of a bounded sequence ($\sin x$ is bounded by $[-1, 1]$) and a sequence which converges to 0, so the derivative converges to 0.}%3/30
\exercise{When working out limits of the type $\lim_{x\to x_0}(f(x)/g(x))$ we can use the fact that limits behave in a sensible way to deduce that the answer is $\lim_{x\to x_0} f(x)$ divided by $\lim_{x\to x_0} g(x)$. But if both these limits are 0 it is impossible to draw any conclusions about the limit of the quotient. However derivatives now help us to solve the problem.\\
\indent Let $f$ and $g$ be functions which are both differentiable at $x_0$ with $f(x_0) = g(x_0) = 0$ and with $g'(x_0) \neq 0$. Assume that the domains of $f$ and $g$ are suitably overlapping so that $\lim_{x\to x_0}(f(x)/g(x))$ can be considered. Show that 
$$\lim_{x\to x_0} \frac{f(x)}{g(x)} = \frac{f'(x_0)}{g'(x_0)}$$
Evaluate the following limits
$$\text{(i) } \lim_{x\to 1} \frac{e^x}{x^2+1} \quad \text{(ii) } \lim_{x\to 0} \frac{\sin x}{e^x-1}$$
We extend this method further in the next exercises.  }%3/30
\solution{By definition of the derivative,
$$\frac{f'(x_0)}{g'(x_0)} = \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x-x_0} \cdot \frac{x-x_0}{g(x) - g(x_0)} = \lim_{x\to x_0}\frac{f(x) - f(x_0)}{g(x) - g(x_0)}  = \lim_{x\to x_0} \frac{f(x)}{g(x)}$$
\indent (i)
$$\lim_{x\to 1}\frac{e^x}{x^2 +1} = \frac{e}{2}$$
\indent (ii)
$$\lim_{x\to 0} \frac{\sin x}{e^x-1} = \lim_{x\to 0}\frac{\cos x}{e^x} = 1$$.} %3/30

\newpage
\chapter{A mean theorem}
\exercise{(page 165) We have seen that if $f$ is a function then so is $f'$ (perhaps with a smaller domain.) So we can consider the differentiability of the function $f'$ and work out its derivative $(f')'$ of $f'$ (or $d^2y/dx^2$): this is called the \textit{second derivative} of $f$. In a similar way we can repeatedly differentiate $f$ and find its $n$th derivative denoted by $f^{(n)}$ or ($d^ny/dx^n$). \\
\indent (i) For each positive integer $n$ find the $n$th derivative of the functions 
$$f(x) = x^4 \enspace x\in \mathbb{R}\text{\quad and \quad} g(x) = \sin x \enspace x\in \mathbb{R}$$
\indent (ii) Let $f(x) = x^2(x^2 -2)\enspace x\in\mathbb{R}$. Show that $f$ has stationary points at $x=-1, 0$ and 1.\\
\indent Sketch the graph of $f$.\\
\indent Show also that at $f'$s local maximum $f''$ is negative and at each of its local minima $f''$ is positive.\\
\indent (iii) Let $f$ and $h$ be the functions we have met before which are defined by 
$$f(x) = x^3 \enspace x\in \mathbb{R} \quad h(x) = \begin{cases} x^2\sin(1/x)&x\neq 0\\0&x=0\end{cases} $$
Show that $f$ and $h$ each has a stationary point at $x=0$ but that neither of these stationary points is a local maximum or minimum.\\
\indent Show that the graph of $f''$ actually crosses the $x$-axis at 0 ($f$ is said to have a \textit{point of inflection} at $x=0$).\\
\indent (You may think that at a stationary point $x_0$ of a function $f$
\begin{align*}
&f''(x_0) < 0 \implies f \text{ has a local maximum at } x_0 \\
&f''(x_0) >0 \implies f \text{ has a local minimum at } x_0 \\
&f''(x_0) = 0\implies f \text{ has a point of inflection at } x_0 
\end{align*}
But that's not entirely true and we shall learn the full story in the next section.)} %3/30
\solution{(i)
The $n$th derivative of $f^{(n)}(x) = x^4$ is 
$$\frac{4!}{(4-n)!}x^{4-n}$$ 
and the $n$th derivative of $g(x) = \sin x$ is 
$$g^{(n)} (x) = \begin{cases} \cos x & n = 4k + 1 \\ -\sin x & n = 4k+ 2 \\ -\cos x & n = 4k+ 3 \\ \sin x & n = 4k \end{cases}$$ 
where $k$ is a natural number. \\
\indent (ii) The derivative of $f(x) = x^2(x^2-2)$ is 
$$f'(x) = 2x(x^2-2) + 2x(x^2) = 4x^3 - 4x$$
so that $f(-1) = f(1) = f(0) = 0$. 
\begin{figure}[h!]
	\centering
	\includegraphics[width=.4\linewidth]{p165ex1(ii).pdf}
	\caption{Graph of f(x)}
\end{figure} \\ 
\indent The graph shows that the local maximum of $f$, is at $x=0$ and the function $f''(x) = 12x^2 -4$ at $x=0$ takes the value $f''(0) = -4$ which is negative. At the minima of $f$, $x=-1$ and $x=1$, the second derivative is $f''(-1) = 12-4 = 8 = f''(1)$ which is positive.\\ 
\indent (iii) Since $f'(x) = 3x^2, \enspace f'(0)=0$ and
$$h'(0) = \lim_{x\to0}\frac{h(x)-h(0)}{x-0} = \lim_{x\to0}\frac{x^2\sin(1/x)}{x} \to 0$$
so both functions have a stationary point at $x=0$. The graphs of $f$ and $h$ show that $x=0$ is stationary but not a maximum or minimum. The graph of $f''$ shows that it does cross the $x$-axis at $x=0$.
\newpage 
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{p165ex1(iii)f.pdf}
		\caption{Graph of f(x)}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{p165ex1(iii)h.pdf}
		\caption{Graph of h(x)}
	\end{subfigure}
	\label{fig:p165ex1(iii)}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=.4\linewidth]{p165ex1(iii)f''.pdf}
	\caption{Graph of $f''(x)$}
\end{figure} }
\exercise{Let $f$ and $g$ be functions with suitably-overlapping domains and assume that each of the functions can be differentiated $n$ times. Use the principle of mathematical induction to show that the product $fg$ is differentiable $n$ times and that 
\begin{align*}
(fg)^n = \binom{n}{0}fg^{(n)} + \binom{n}{1}f'g^{(n-1)} &+ \binom{n}{2}f''g^{(n-2)} + \dotsb \\
&+ \binom{n}{r} f^{(r)}g^{(n-r)} + \dotsb + \binom{n}{n}f^{(n)} g
\end{align*}
where $\binom{n}{r}$ is the 'binomial coefficient' $n!/(r!(n-r!))$. This is known as \textit{Leibniz' rule}.}
\solution{In the case $n=1$,
$$(fg)^{(1)} = fg' + f'g = \binom{1}{0} fg' + \binom{1}{1} f'g$$
and the hypothesis holds. If the rule is true for $n-1,$ then
\begin{align*}(fg)^{(n)} = \frac{d}{dx}(fg)^{(n-1)} &= \frac{d}{dx}(fg^{(n-1)} + \dots + \binom{n-1}{r}f^{(r)}g^{(n-1-r)} + \dots + f^{(n-1)}g) \\
&= fg^{(n)} + \dots + \left[\binom{n-1}{r} + \binom{n-1}{r-1}\right]f^{(r)}g^{(n-r)} + \dots + f^{(n)}g
\end{align*}
which simplifies to the identity.} %4/4
\exercise{Apply the mean value theorem to the function $f$ given by 
$$f(x) = \sin^{-1}x \quad x \in [-1,1]$$
between 0 and $x$ to deduce that 
$$x\leqslant \sin^{-1}x\leqslant \frac{x}{\sqrt{1-x^2}}$$
for each $x\in [0,1).$} %3/30
\solution{First note that the derivative of the inverse sine function is 
$$\frac{d}{dx}\sin^{-1}x = \frac{1}{\cos(\sin^{-1} x)} = \frac{1}{\sqrt{1-x^2}}$$
The mean value theorem says that there is a $c$ in the interval $[0,x]$ with
$$f'(c) = \frac{1}{\sqrt{1-c^2}} = \frac{f(x)-f(0)}{x} = \frac{\sin^{-1}x}{x}$$
so that at $x=c$,
$$\frac{x}{\sqrt{1-c^2}} = \sin^{-1}x$$
Since $c\leqslant x$,
$$x\leqslant \frac{x}{\sqrt{1-c^2}} \leqslant \frac{x}{\sqrt{1-x^2}}$$
which gives the desired inequality 
$$x\leqslant \sin^{-1}x \leqslant \frac{x}{\sqrt{1-x^2}}$$}%4/4
\exercise{Let $f$ and $g$ be functions which are continuous on $[a,b]$ and differentiable on $(a,b)$, where $a<b$, and such that $g'(x)$ is never zero. We wish to prove that there exists $c\in(a,b)$ with
$$\frac{f'(c)}{g'(c)} = \frac{f(b)-f(a)}{g(b)-g(a)}$$
What's wrong with the following 'proof'?
\indent 'Applying the mean value theorem to $f$ and to $g$ shows that there exists $c\in(a,b)$ with
$$f'(c) = \frac{f(b)-f(a)}{b-a} \quad \text{ and } \quad g'(c) = \frac{g(b)-g(a)}{b-a}$$
Dividing the left-hand expression by the right-hand one shows that 
$$\frac{f'(c)}{g'(c)} = \frac{f(b)-f(a)}{g(b)-g(a)}$$
as required.' \\
\indent By considering the function $h$ given by
$$h(x) = f(x) - \frac{f(b)-f(a)}{g(b)-g(a)}g(x) \quad x\in[a,b]$$
find a valid proof of the above result.} %3/30
\solution{The proof is incorrect because the $c$ that the mean value theorem gives for $f'$ and $g'$ are not the same. \\
\indent Using the fact that $h(x)$ is continuous on $[a,b]$, differentiable on $(a,b)$, and $h(a) = h(b)$; Rolle's theorem can be applied. Then there is a $c\in(a,b)$ so that $h'(c) = 0$, which means
$$h'(c) = f'(c) - \frac{f(b)-f(a)}{b-a}g'(c) = 0 \implies \frac{f'(c)}{g'(c)} = \frac{f(b)-f(a)}{b-a}$$
at $x=c$.}%4/4
\exercise{We saw in exercise 5 on page 157 that if $f$ and $g$ are differentiable at $x_0$ (with suitably-overlapping domains) with $f(x_0) = g(x_0) = 0$ and $g'(x_0) \neq 0$ then
$$\lim_{x\to x_0} \frac{f(x)}{g(x)} = \frac{f'(x_0)}{g'(x_0)}$$
But what if $g'(x_0) = 0?$ We can use the previous exercise to extend this result. So assume now that $f$ and $g$ are differentiable in an interval around. $x_0$ with $f(x_0) = g(x_0) = 0$ and that
$$\lim_{x\to x_0}\frac{f'(x)}{g'(x)}$$
exists. Then show that
$$\lim_{x\to x_0} \frac{f(x)}{g(x)} = \lim_{x\to x_0} \frac{f'(x)}{g'(x)}$$
This is known as \textit{L'Hopital's rule} (after the French mathematician Guillaume L'Hopital who published it in 1696, although. he apparently learnt it from Johann Bernoulli). Use it to evaluate the following limits, where $\alpha$ is a fixed number.
\begin{align*}
\text{(i) } & \lim_{x\to 1}\frac{\log x}{x-1} \quad &\text{(ii) } & \lim_{x\to 0} \frac{\cos x -1}{x^2} \\ 
\text{(iii) } & \lim_{x\to 0} \frac{\log(1+ \alpha x)}{x} &\text{(iv) } &\lim_{n\to\infty} \left(1+\frac{\alpha}{n}\right)^n 
\end{align*}} %3/30
\solution{If $f(x_0) =  g(x_0) = 0$ and $\lim_{x\to x_0} f'(x)/g'(x)$ exists, then
$$\lim_{x\to x_0}\frac{f'(x)}{g'(x)} = \lim_{x\to x_0} \frac{f(x)-f(x_0)}{g(x)-g(x_0)} = \lim_{x\to x_0} \frac{f(x)}{g(x)}$$
\indent (i) The expression $\frac{\log x}{x-1}$ evaluated at $x=1$ gives $0/0$, so taking the limit as the derivative of the numerator over the derivative of the denominator approaches 1 gives $\lim_{x\to 1}\frac{1/x}{1} = 1$\\
\indent (ii) $\frac{\cos x -1}{x^2}$ evaluated at 0 gives $0/0$. Applying l'hopital's rule shows that the limit is $\frac{-\sin x}{2x}\to \frac{-1}{2}$. \\
\indent (iii) The expression at $x=0$ is $\log (1) /0 =0/0$, so taking the derivative shows the limit to be $\frac{\alpha/(1+\alpha x)}{1}\to \alpha$.  \\
\indent (iv) Rewriting the limit, $\lim_{n\to\infty}(1+\alpha/n)^n = \lim_{n\to\infty} e^{n\log(1+\alpha/n)} = \lim_{x\to 0} e^{\log(1+x\alpha)/x} \to e^\alpha$.}%4/4
\exercise{As we defined earlier a function $f$ is strictly increasing if whenever $a<b$ in $f's$ domain it follows that $f(a) < f(b)$: similarly a function is increasing if $a<b$ implies that $f(a) \leqslant f(b)$ (with corresponding definitions of 'strictly decreasing' and 'decreasing'). \\
\indent Now let $f$ be a differentiable function whose domain is an interval. Show that:
\begin{align*}
\text{(i) }& \text{ if $f'(x)>0$ for each $x$ then $f$ is strictly increasing;}\\
\text{(ii) }& \text{ if $f'(x)\geqslant0$ for each $x$ then $f$ is increasing;}\\
\text{(iii) }& \text{ if $f'(x)<0$ for each $x$ then $f$ is strictly decreasing;}\\
\text{(iv) }& \text{ if $f'(x)\leqslant0$ for each $x$ then $f$ is decreasing.}
\end{align*}
Deduce that $\sin x \leqslant x$ for each $x\geqslant0$.} %4/5
\solution{The definition of the derivative is 
$$f'(x) = \lim{x_n\to x}\frac{f(x_n)-f(x)}{x_n-x}$$ 
So if $(x_n)$ is a decreasing sequence that converges to $x$, then $x_n\geqslant x$ and the quantity $x_n-x > 0$ for all $n$. Then
$$f'(x) > 0 \iff \lim_{x_n\to x} f(x_n) - f(x) >0$$
which proves (i) and (iv). If $f'(x) = 0$ then the function takes values arbitrarily close to $f(x)$ at values $x_n$ arbitrarily close to $x$the function is constant at those points which proves (ii) and (iv). \\
\indent The derivative of $\sin x$ is $\cos x$ and the derivative of $x$ is 1, so since $\sin 0 = 0$, $\cos x \leqslant 1$ implies that $\sin x \leqslant x$.} %4/5
\exercise{(i) Let $f$ and $g$ be differentiable functions with domain an interval $D$ and with $f' = g'$ (i.e. $f'(x) = g'(x)$ for each $x\in D$). Show that $f$ and $g$ differ by a constant; i.e. that there exists a number $k$ with $f(x) = g(x) + k$ for each $x\in D$. \\
\indent (ii) Use the result of exercise 2 on page 157 to show that 
$$\cosh^{-1}(x/2) = \log(x + \sqrt{x^2-4}) - \log 2 \text{ for each $x\geqslant 2$}$$} %4/5
\solution{If $f'=g'$ then the derivative of the function $h(x) = f(x)-g(x)$ is
\begin{align*}
h'(x_0) &= \lim_{x\to x_0} \frac{(f(x)-g(x))- (f(x_0)-g(x_0))}{x-x_0} \\ 
&= \lim_{x\to x_0} \frac{f(x)-f(x_0)}{x-x_0} -  \frac{g(x)-g(x_0)}{x-x_0} \\
&= f'(x_0)-g'(x_0) = 0
\end{align*}
so that $h'(x) = 0$ for each $x\in D$ and $h$ is a constant function. \\
\indent (ii) Exercise 2 on page 157 showed that $f(x)=\cosh^{-1}(x/2) $ and $g(x) = \log(x + \sqrt{x^2 -4})$ have the same derivative, so the differ by a constant. Then 
$$f(2) -g(2) = \cosh^{-1}1 -\log(2 + \sqrt{2^2-4}) = 0 -  \log 2$$
which shows $f(x) = g(x) -\log 2$.}%4/5
\exercise{Let $f$ be a function with domain $(0, \infty)$ and range $\mathbb{R}$ and let $g$ be a function with domain $\mathbb{R}$ and range $(0,\infty)$. Assume that
$$f'(x) = 1/x\quad x>0\quad \text{and}\quad g'(x)=g(x)\quad x\in\mathbb{R}$$
Use exercise 6 to show that $g$ is strictly increasing (and hence that it has an inverse). Then use exercise 4 on page 150 to find the derivative of $g$'s inverse, and show that $g$'s inverse and $f$ differ by a constant. Hence\\
\indent (i) give an alternate proof that the log and exp functions are inverses of each other;\\
\indent (ii) Show that $g(x) = e^{x+k}$ for some constant $k$.} %4/5
\solution{The range of $g$ is strictly positive, so $g'(x)=g(x)>0$ and $g$ is strictly increasing. The derivative of $g$ inverse is
$$(g^{-1})'(x) = \frac{1}{g'(g^{-1}(x))} = \frac{1}{x}$$
So $f'=(g^{-1})'$ and the functions differ by a constant. \\
\indent (i) The log function satisfies $f(x)=1/x$ and the exp function satisfies $g'(x) = g(x)$, so $\log x = \exp^{-1} x + k$. Plugging in $x =1$ gives $k=0$ and $\log x = exp^{-1}x$. \\
\indent (ii) Log satisfies $f(x)$ so $\log x$ and $g^{-1}(x)$ differ by a constant. Then $\log x = g^{-1}(x) + k$ and for $x = g(x')$, $\log g(x') =  x+k$ so that $g(x') = e^{x+k}$.}%4/5

\newpage
\chapter{Polynomial approximations}
\exercise{(page 178) Find the Taylor series (about $x=0$) of the function cos and of the function cosh.\\
\indent In each case suppose that we wish to find a polynomial which approximates to the function to within $\epsilon \enspace(>0)$ throughout the interval $[-k,k]$.  Show that such a polynomial exists.} %4/6
\solution{The derivatives of the cos function at $x=0$ are:
$$f(0) = \cos 0 = 1, \quad f'(0) = -\sin 0 = 0, \quad f''(0) = -\cos 0 = -1, \quad f^{(3)}(0)=\sin 0 = 0$$
$$f^{(4)}(0) = \cos 0 = 1\dots$$
and so on. The derivatives of the function $g(x) = \cosh x$ at $x=0$ are
$$g(0)=\cosh 0 = 1,\quad g'(0) = \sinh0 = 0, \quad g''(0) = \cosh 0 = 1 \dots$$
and so on. Then the Taylor series about $x=0$ of $\cos x$ is 
$$\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} \pm \dots$$
and the Taylor series of $\cosh x$ is
$$\cosh x = 1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \dots$$
\indent Taylor's theorem says that the difference between $f(x)$ and the polynomial approximation of degree $n$ at $x$ is equal to 
$$\frac{f^{(n+1)}(c)}{(n+1)!} x^{n+1}$$
for some $c$ between 0 and $x$. The range of cosine is $[-1,1]$ and $x$ is in the interval $[-k,k]$, so
$$\left|\frac{f^{(n+1)(c)}}{(n+1)!} x^{n+1}\right| < \bigg|\frac{1}{(n+1)!}k^{n+1}\bigg|$$
which is a sequence that converges to 0 as $n$ tends to infinity. Then there exists an $N$ for which the difference 
$$f(x) - \left(1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \dots \pm \frac{x^{N}}{N!}\right) < \left|\frac{k^{N+1}}{(N+1)!}\right| < \epsilon$$
\indent For the $\cosh$ function, the range is bounded above by $e^x$, so the difference between $g(x)$ and the polynomial approximation is 
$$\frac{g^{(n+1)}(c)}{(n+1)!}x^{n+1} < \frac{(e\cdot k)^{n+1}}{(n+1)!}$$
which is another sequence that tends to 0, and by a similar argument a polynomial exists of degree $N$ that approximates $g(x)$ to within $\epsilon.$} %4/6
\exercise{Let $f$ be the function given by $f(x) = \log(1+x) \enspace (x>-1).$ Find the Taylor series of $f$ (about $x=0).$\\
\indent Suppose that we wish to find a polynomial which approximates $f$ to within $\epsilon\enspace (>0)$ throughout the interval $[-\tfrac{1}{2}, 1].$ Show that such a polynomial exists.} %4/6
\solution{The derivatives of $f(x) = \log (1+x)$ at $x=0$ are
$$f(0) = \log 1 = 0,\quad f'(0) = \frac{1}{1+0} = 1,\quad f''(0) = -\frac{1}{(1+0)^2} = -1,\quad f^{(3)}(0) = \frac{2}{(1+0)^3} = 2, \dots $$
$$f^{(4)}(0) =-\frac{3\cdot2}{(1+0)^4} = -6,\quad  f^{(5)}(0) = \frac{4\cdot3\cdot2}{(1+0)^5} = 24, \quad \dotsb, \quad f^{(n)}(0) = (-1)^{n-1}(n-1)!$$
The Taylor series of $f$ about $x=0$ is
$$f(x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} \pm \dots$$
Taylor's theorem gives the margin of error as
$$\frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}$$
and in the interval $[-\tfrac{1}{2}, 1]$ the absolute value $|x^n|\leqslant1$. So
$$\left|\frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}\right| =\left| \frac{x^{n+1}}{(n+1)}\right| \leqslant \frac{1}{n+1}$$
so for any $\epsilon$ there is a polynomial approximation of degree $N>1/\epsilon$ so that the difference between $f$ and the approximation is less than $\epsilon$.}%4/6
\exercise{Let $g$ be a function which can be differentiated arbitrarily often and whose domain includes $a$. By applying the above form of Taylor's theorem to the function $f$ given by $f(x) = g(x+a)$ show that the polynomial
$$g(a) + g'(a)(x_0-a) + \frac{g''(a)}{2!}(x_0-a)^2 +\dotsb+\frac{g^{(n)}(a)}{n!}(x_0-a)^n$$
differs from $g(x_0)$ by an amount equal to $g^{(n+1)}(c)(x_0-a)^{n+1}/(n+1)!$ for some $c$ between $a$ and $x_0$. (This is the more general form of Taylor's theorem.)\\
\indent The expression
$$g(a) + g'(a)(x-a) + \frac{g''(a)}{2!}(x-a)^2 +\dotsb+\frac{g^{(n)}(a)}{n!}(x-a)^n + \dotsb$$
is called the \textit{Taylor's series of $g$ (about $x=a$)}\\
\indent Find the Taylor series of the log function about $x=1$.} %4/6
\solution{Taylor's theorem for $x=0$ says the $n$-degree polynomial approximation of $f$ about the point $x=0$ differs from $f$ by
$$\frac{f^{(n+1)}(c)}{(n+1)!}x_0^{n+1}$$ 
for some $c$ between 0 and $x_0$. Since $f^{(n)}(x) = g^{(n)}(x-a)$, the equation
$$f(x) = \left[f(0) + f'(0)x + \frac{f''(0)}{2!}x^2 + \dotsb + \frac{f^{(n)}(0)}{n!}x^n\right] + \frac{f^{(n+1)}(c)}{(n+1)!}x^{n+1}$$
can be rewritten
$$g(x+a) = \left[g(a) + g'(a)x + \frac{g''(a)}{2!}x^2 + \dotsb + \frac{g^{(n)}(a)}{n!}x^n\right] + \frac{g^{(n+1)}(c+a)}{(n+1)!}x^{n+1}$$ 
and as a result, for every $x_0= x+a$ in an interval around $x_0=0+a$, there is a $c_0=c+a$ between $x_0$ and $a$ for which the polynomial
$$g(x_0) = \left[g(a) + g'(a)(x_0-a) + \frac{g''(a)}{2!}(x_0-a)^2 +\dotsb+\frac{g^{(n)}(a)}{n!}(x_0-a)^n\right] + \frac{g^{(n+1)}(c_0)}{(n+1)!}(x_0-a)^{n+1}$$
so that $g(x_0)$ and the above polynomial differ by $g^{(n+1)}(c)(x_0-a)^{n+1}/(n+1)!$ as desired. \\
\indent The Taylor series of the log function about $x=1$ is
$$\log(1) + \tfrac{1}{1}(x-1) + \tfrac{-1}{1^2}(x-1)^2/2! +\dotsb+\frac{(-1)^{n-1}}{(n+1)}(x-1)^n + \dotsb$$}%4/6
\exercise{Complete the proof of the last theorem (i.e. for general $a$). Find the stationary points of the function given by $f(x) = x^3e^x\enspace (x\in\mathbb{R})$ and determine their nature. Hence sketch the graph of $f$.} %4/6
\solution{The assumptions for the proof of the last theorem are: $f$ is differentiable arbitrarily many times in an interval around $x=a$ and the $m$th derivative ($m>1$) is the first non-zero derivative at $a$. Taylor's theorem about $x=a$ gives that 
\begin{align*}
f(x) - f(a) &= f'(a)(x-a) + \dots + \frac{f^{(m)}(c)}{(n+1)!}(x-a)^m\\
&= 0 + \frac{f^{(m)}(c)}{(n+1)!}(x-a)^m
\end{align*}
for some $c$ between $x$ and $a$. If $x$ is chosen so that $f^{(m)}(x)$ is between 0 and $f^{(m)}(a)$, then $f^{(m)}(c)$ and $f^{(m)}(a)$ have the same sign. Hence if $m$ is even, \\
\indent 1. $f(x) - f(a) < 0$ ($x=a$ is a local maximum of $f$) if and only if $f^{(m)}(c) < 0$, and \\
\indent 2. $f(x) - f(a) > 0$ ($x=a$ is a local minimum of $f$) if and only if $f^{(m)}(c) > 0$ \\
\indent If $m$ is odd, then the $(x-a)^m$ term changes sign depending on whether $x<a$ or $x>a$, so that $x=a$ is neither a maximum nor a minimum of $f$. \\
\indent The stationary points of $f(x) = x^3e^x$ are the zeroes of its derivative 
$$f'(x) = 3x^2e^x + x^3e^x = \underset{\text{never }0}{e^x}\cdot x^2\cdot(3+x)=0$$
so the stationary points are at $x=0$ and $x=-3$. The first nonzero derivative of $x=0$ is $f^{(3)}(0) = 6$. Since 3 is odd, $x=0$ is neither a maximum nor minimum of $f$. The first nonzero derivative of $x=-3$ is $f''(3) = e^3(6(-3) + 3(-3)^2 + (-3)^3 + 3(-3)^2) = 9e^3 > 0$. Since $m=2$ is even and the $m$th derivative of $f$ is positive, $x=-3$ is a local minimum of $f$. 
\begin{figure}[H]
	\centering
	\includegraphics[width=.45\linewidth]{p178ex4.pdf}
	\caption{Graph of f(x)}
\end{figure} }%4/6 [need to force this thing on the same page.

\newpage
\chapter{Series revisited}
\exercise{(page 187) By using various tests of convergence of series established in chapter 2 find the radius of convergence of each of the following series:
\begin{align*}
\text{(i) } & 1 + x^2 + \frac{x^4}{2!} + \frac{x^6}{3!} + \dots \\
\text{(ii) } & x + 2x^2 + 3x^3 + 4x^4 + \dots \\
\text{(iii) } & 1 + x + 2!x^2 + 3!x^3 + \dots
\end{align*}
In the case of each series with a positive radius of convergence find a neat expression for the function to which it converges (and whose Taylor series it therefore is). } %4/8
\solution{(i) By the ratio test the series converges (absolutely) when the limit of
$$\left|\frac{x^{2(n+1)}/(n+1)!}{x^{2n}/n!}\right| = \left|\frac{x^2}{(n+1)}\right|$$
converges to a number less than one. For any fixed $x$ the sequence $x^2/(n+1)\to 0$ so the radius of convergence is infinite. By inspection the above series is the same as the series representation of $f(x)=e^x$ with all of the $x$'s replaced by $x^2$. Then the series represents the function $f(x^2) = e^{x^2}$.   \\
\indent (ii) The ratio test gives
$$\left|\frac{(n+2)x^{n+2}}{(n+1)x^{n+1}}\right| = \left|\frac{1+\frac{2}{n}}{1+\frac{1}{n}}x\right|\to |x|$$
so the series converges when $|x| <1$; the radius of convergence $r=1$. The power series for the function $f(x) = (1+x)^{-2}$ is
$$1 +\frac{(-2)x}{1!} + \frac{(-2)(-3)x^2}{2!} + \frac{(-2)(-3)(-4)x^3}{3!} + \dots$$
which is 
$$1 - 2x + 3x^2 -4x^3 + \dotsb$$ 
replacing $x$ with $-x$ gives
$$1 +2x + 3x^2 + 4x^3 + \dotsb$$
and multiplying through by $x$ gives the original series
$$x + 2x^2 + 3x^3 + 4x^4 + \dotsb$$
After applying the same steps to the function $f(x) = (1+x)^{-2}$, the resulting the function is 
$$g(x) = \frac{x}{(1-x)^2}$$
\indent (iii) In this case the ratio test gives
$$\left|\frac{(n+1)!x^{n+1}}{n!x^n}\right| = |(n+1)x|$$
which diverges for $x\neq 0$. Therefore the series only converges for $x=0$ and the radius of convergence is 0.}%4/8
\exercise{By repeatedly differentiating the following functions find the first few terms of their Taylor series (about x=0);
$$f(x) = \tan x\quad g(x) =\tan^{-1}x$$
(In the case of $f$ the derivatives soon get a bit complicated so you might prefer to prove first that 
$$f'(x) = 1 + (f(x))^2$$
and to use this result to help you find the higher derivatives.) \\
\indent Now assume that Taylor series behave in a `natural' way and \\
\indent(i) calculate the first few terms of the product of the Taylor series of $\tan x$ and the Taylor series of $\cos x$ and observe that you get the terms of the Taylor series of $\sin x$. \\
\indent (ii) use the above series for $f$ and $g$ to calculate the first few terms of the series of $f(g(x))$ and of the series of $g(f(x))$.} %4/8
\solution{Since 
$$f'(x) = d/dx(\sin x/\cos x) = 1 + \frac{\sin^2 x}{\cos^2 x} =1 +\tan^2 x = 1 + (f(x))^2$$
The derivatives can be easily calculated as
\begin{align*}
f(0) &= \tan 0 = 0\\
f'(0) &= 1 + (f(0))^2 = 1\\
f''(0) &= 0 + 2f'(0)(f(0)) = 0\\
f^{(3)}(0) &= 2(f'(0))^2 + 2f''(0)f(0) = 2(1) + 0 =2\\
f^{(4)}(0) &= 4f''(0)f'(0) + 2f''(0)f'(0) + 2f^{(3)}(0)f(0) = 0 +0 + 0 =0\\
f^{(5)}(0) &= 4(f''(0))^2+4f^{(3)}(0)f'(0) + 2(f''(0))^2 + 2f^{(3)}(0)f'(0) + 2f^{(3)}f'(0) + 2f^{(4)}(0)f(0) \\
&= 0 + 4(2)(1) + 0 + 2(2)(1) + 2(2)(1) + 0 =8 +4+4 = 16\\
&\vdots \\
\end{align*}
so the Taylor series is 
$$f(x) = x + \frac{2x^3}{3!} + \frac{16x^5}{5!} + \dots$$
\indent For $g(x) = \tan^{-1}x$ the derivatives are 
\begin{align*}
g'(x) &= (1+x^2)^{-1}\\
g''(x) &=(-2x)(1+x^2)^{-2}\\
g^{(3)}(x) &= (-2)(1+x^2)^{-2} + (8x^2)(1+x^2)^{-3}\\
g^{(4)}(x) &= (8x)(1+x^2)^{-3} + (16x)(1+x^2)^{-3} + (-42x^3)(1+x^2)^{-4}\\
&=(24x)(1+x^2)^{-3} + (-42x^3)(1+x^2)^{-4} \\
g^{(5)}(x) &= (24)(1+x^2)^{-3} + (-144x^2)(1+x^2)^{4} + (-126x^2)(1+x^2)^{-4} + (336x^4)(1+x^2)^{-5}
\end{align*}
so that 
\begin{align*}
g(0) &= 0 \\
g'(0) &= 1\\
g''(0) &= 0\\
g^{(3)}(0) &= -2 \\
g^{(4)}(0) &= 0 \\
g^{(5)}(0) &= 24
\end{align*}
and the Taylor series is
\begin{align*}
g(x) &= x -\frac{2x^3}{3!} + \frac{24x^5}{5!} + \dotsb \\
&= x-\frac{x^3}{3} + \frac{x^5}{5} + \dotsb
\end{align*}
\indent(i) The product of the Taylor series for $\cos x$ and $f(x)=\tan x$ is
$$\left(1-\frac{x^2}{2!}+\frac{x^4}{4!} + \dotsb\right)\left(x + \frac{2x^3}{3!} + \frac{16x^5}{5!} + \dotsb\right)$$
$$= x - \frac{x^3}{2!} + \frac{2x^3}{3!} - \frac{2x^5}{2!3!} + \frac{x^5}{4!} + \frac{16x^5}{5!} + \dotsb$$
$$= x - \frac{x^3}{3!} + \frac{x^5}{5!} + \dotsb$$
which is the power series for $\sin x$. \\
\indent (ii) The series $f(g(x))$ would be 
\begin{align*}
f(g(x)) &= g(x) + \frac{2g(x)^3}{3!} + \frac{16g(x)^5}{5!} + \dotsb \\
&= \left(x -\frac{x^3}{3} + \frac{x^5}{5} +\dotsb \right) + \frac{2}{3!}\left(x - \frac{x^3}{3} + \frac{x^5}{5} + \dotsb \right)^3 + \dotsb \\
&= x + \left(-\frac{x^3}{3} +\frac{2x^3}{3!}\right) + \left(\frac{x^5}{5} -\frac{3(2)x^5}{3(3!)} + \frac{16x^5}{5!}\right) + \dotsb \\
&= x + 0 + 0 + \dotsb
\end{align*}
so that $f(g(x)) = x$. Similarly the series $g(f(x))$ is
\begin{align*}
g(f(x)) &= f(x) - \frac{f(x)^3}{3} + \frac{f(x)^5}{5} + \dotsb \\
&= \left(x+\frac{2x^3}{3!}+\frac{16x^5}{5!} +\dotsb\right) - \frac{1}{3}\left(x + \frac{2x^3}{3!} + \frac{16x^5}{5!} +\dotsb\right)^3 + \dotsb\\
&= x + \left(\frac{x^3}{3} - \frac{x^3}{3}\right) + \left(\frac{16x^5}{5!} -\frac{3(2)x^5}{3(3!)} + \frac{x^5}{5}\right) + \dotsb \\
&= x + 0 + 0 + \dotsb
\end{align*}
so that $f(g(x)) = g(f(x)) = x$. }%4/8
\exercise{Differentiate the series in exercise 2 to 
\begin{align*}
\text{(i) }& \text{find the first few terms of the Taylor series of $\sec^2 x$ (where $\sec x = 1/\cos x$);}\\
\text{(ii) }& \text{confirm that the Taylor series of $g'$ seems to be the series of $(1+x^2)^{-1}.$}
\end{align*}} %4/8
\solution{(i) Differentiating the series for $f(x)$ gives
\begin{align*}
f(x) &= x + \frac{x^3}{3} + \frac{2x^5}{15} + \dotsb\\
\Rightarrow f'(x) &= 1 + x^2 + \frac{2x^4}{3} + \dotsb
\end{align*}
and $d/dx\tan x = 1/\cos^2 x = \sec^2 x$ shows that the above series is the Taylor series for $\sec^2 x$.  \\
\indent (ii) Differentiating the second series gives
\begin{align*}
g(x) &= x - \frac{x^3}{3} + \frac{x^5}{5} + \dotsb \\
\Rightarrow g'(x) &= 1 - x^2 + x^4 - x^6 + \dotsb 
\end{align*}
while the power series for $(1-x)^{-1}$ is the geometric series
$$S(x) = 1 + x + x^2 + x^3 + \dots$$
Since the series $g'(x)$ has the same terms as $S(-x^2)$, it seems that the Taylor series of $g'(x)$ is the same as the Taylor series of $(1+x^2)^{-1} = S(-x^2)$.}%4/8

\newpage
\section{An integrated conclusion}
\chapter{A familiar area}
\exercise{(page 204) (i) For each non-negative integer $r$ let $t_r$ be the \textit{triangular number} $\frac{1}{2}r(r+1)$. Show that
$$t_r^2 - t_{r-1}^2 = r^3$$
and deduce that 
$$1^3 + 2^3 + 3^3 + \dotsb + n^3 = (\tfrac{1}{2}n(n+1))^2$$
(ii) Let $f$ be the function given by 
$$f(x) = x^3\quad x\in\mathbb{R}$$
Show that $f$ is integrable over [0,1] and find
$$\int_0^1 x^3 \, dx$$} %4/9
\solution{Plugging in,
\begin{align*}
t_r^2 - t_{r-1}^2 &= (\tfrac{1}{2}r(r+1))^2 - (\tfrac{1}{2}(r-1)r)^2 \\
&=\tfrac{1}{4}r^2(r^2+2r+1) - \tfrac{1}{4}(r^2-2r+1)r^2 \\
&=\tfrac{1}{4}r^2(r^2+2r+1-r^2+2r-1)\\
&=\tfrac{1}{4}r^2(4r)\\
&= r^3
\end{align*}
so that 
\begin{align*}
1^3 + 2^3 + \dotsb + n^3 &= (t_1^2 -t_0^2) + (t_2^2 -t_1^2) + \dotsb + (t_n^2 - t_{n-1}^2)\\
&= t_n^2 -t_0^2 \\
&=(\tfrac{1}{2}n(n+1))^2
\end{align*}
\indent (ii) The partition $\{0, \tfrac{1}{n}, \tfrac{2}{n},\dotsb,1\}$ is a partition of $[0,1]$ into $n+1$ intervals for each positive integer $n$. The lower estimate given by this partition is 
$$l_n = \sum_{r=1}^n(\tfrac{r}{n}-\tfrac{r-1}{n})\inf\{x^3\mid x\in[\tfrac{r-1}{n},\tfrac{r}{n}]\}$$ 
since $x^3$ is strictly increasing this simplifies to
$$l_n = \sum_{r=1}^n \tfrac{1}{n}\left(\tfrac{r-1}{n}\right)^3 = \frac{1}{n^4}\sum_{r=0}^{n-1} r^3$$
Using the identity from part (i), this can be rewritten
$$l_n = \frac{(\frac{1}{2}(n-1)n)^2}{n^4} = \frac{n^4-2n^3+n^2}{4n^4}\to \frac{1}{4}$$
so that the limit of the sequence $l_n$ as $n\to \infty$ is $1/4$. \\
\indent In the case of the upper estimates, the equation is 
$$m_n = \sum_{r=1}^n(\tfrac{r}{n}-\tfrac{r-1}{n})\sup\{x^3\mid x\in[\tfrac{r-1}{n},\tfrac{r}{n}]\}$$
which again simplifies to
$$m_n = \sum_{r=1}^n \tfrac{1}{n}\left(\tfrac{r}{n}\right)^3 = \frac{1}{n^4}\sum_{r=1}^n r^3$$
so that
$$m_n = \frac{(\frac{1}{2}n(n+1))^2}{n^4} = \frac{n^4+2n^3+n^2}{4n^4}\to \frac{1}{4}$$
and both $l_n$ and $m_n$ converge to the same limit, $\alpha = \frac{1}{4}$ which is the integral of $f(x) = x^3$ over the interval $[0,1]$.}%4/9
\exercise{(i) Let $\alpha$ be a number which is not a multiple of $2\pi$ and let $r$ be a positive integer. Show that
$$\sin(r\alpha) =\frac{\cos((r-\tfrac{1}{2})\alpha) -\cos((r+\tfrac{1}{2})\alpha)}{2\sin\tfrac{1}{2}\alpha}$$
and deduce that
$$\sin\alpha + \sin2\alpha + \sin3\alpha + \dotsb + \sin n\alpha = \frac{\cos\tfrac{1}{2}\alpha - \cos((n + \tfrac{1}{2}\alpha)}{2\sin\tfrac{1}{2})\alpha}$$
\indent (ii) Let $f$ be the function given by
$$f(x) = \sin x\quad x\in\mathbb{R}$$
Show that $f$ is integrable over $[0,\pi/2]$ and find
$$\int_0^{\pi/2} \sin x\, dx$$} %4/10
\solution{(i) Using the formula $\cos(a+b) = \cos a \cos b -\sin a\sin b$,
\begin{align*}
\cos(r\alpha -\tfrac{1}{2}\alpha) &= \cos r\alpha \cos\alpha/2 + \sin r\alpha \sin \alpha/2 \\
\cos(r\alpha + \tfrac{1}{2}\alpha) &= \cos r\alpha \cos\alpha/2 - \sin r\alpha \sin \alpha/2 \\
\cos(r\alpha -\tfrac{1}{2}\alpha) - \cos(r\alpha +\tfrac{1}{2}\alpha) &= 2\sin r\alpha \sin\alpha/2
\end{align*}
so that 
$$\frac{\cos((r-\tfrac{1}{2})\alpha) -\cos((r+\tfrac{1}{2})\alpha)}{2\sin\tfrac{1}{2}\alpha} = \frac{2\sin r\alpha \sin\tfrac{1}{2}\alpha}{2\sin\tfrac{1}{2}\alpha} = \sin r\alpha$$
Then 
\begin{align*}
\sum \sin r\alpha &= \frac{1}{2\sin\alpha}\bigg[\Big(\cos\tfrac{1}{2}\alpha - \cos((1+\tfrac{1}{2})\alpha)\Big)  + \Big(\cos((2-\tfrac{1}{2})\alpha) -\cos((2+\tfrac{1}{2})\alpha)\Big) + \dotsb \\
&+ (\cos((n-\tfrac{1}{2})\alpha) -\cos((n+\tfrac{1}{2})\alpha)\bigg] \\
&= \frac{\cos\tfrac{1}{2}\alpha - \cos((n+\tfrac{1}{2})\alpha)}{\sin\tfrac{1}{2}\alpha}
\end{align*} 
\indent (ii) The lower estimates given by the partition $[0, \tfrac{1}{n}(\pi/2), \tfrac{2}{n}(\pi/2) \dotsb, \tfrac{n}{n}(\pi/2)]$ are
\begin{align*}
l_n &= \sum_{r=1}^n (\frac{r}{n}(\pi/2)-\frac{r-1}{n}(\pi/2))\inf\{\sin x\mid x\in[\frac{r-1}{n}(\pi/2),\frac{r}{n}(\pi/2)]\}\\
&= \sum\frac{\pi}{2n}\sin \frac{r-1}{2n}\pi = \frac{\pi}{2n}(\sin \frac{0}{2n}\pi +\dotsb + \sin \frac{n-1}{2n}\pi))\\
&= \frac{\pi}{2n}\cdot \frac{\cos\frac{\pi}{4n} - \cos((n-1+\frac{1}{2})\frac{\pi}{2n})}{2\sin\frac{\pi}{4n}}\\
&= \frac{\cos\frac{\pi}{4n} - \cos(\frac{\pi}{2}-\frac{\pi}{4n})}{\frac{4n}{\pi}\sin\frac{\pi}{4n}}
\end{align*}
The denominator is $(\sin x)/x$, which tends to 1 as $x$ tends to 0. Then $l_n$ is a sequence of lower estimates that tends to
$$l_n \to \frac{(1-\cos\frac{\pi}{2})}{1} = 1-\cos\tfrac{\pi}{2} = 1$$
Likewise the upper estimates are
$$m_n =  \sum\frac{\pi}{2n}\sin\frac{r\pi}{2n} =\frac{\cos\frac{\pi}{4n}-\cos(\frac{\pi}{2}+\frac{\pi}{4n})}{\frac{4n}{\pi}\sin\frac{1}{2n}}$$
so that
$$m_n\to 1-\cos\frac{\pi}{2} = 1$$
and $f(x)=\sin x$ is integrable over $[0,1]$. The integral is $\int_0^1\sin x\, dx = 1$}%4/10
\exercise{Let $a<b$ and let $f$ be an increasing function which is bounded on $[a,b]$. Consider the partition $a=a_0<a_1<\dotsb<a_n = b$ which divides $[a,b]$ into $n$ equal strips and let
$$l_n = \sum^n_{r=1}(a_r-a_{r-1})\inf\{f(x):a_{r-1}\leqslant x\leqslant a_r\}$$
$$m_n = \sum^n_{r=1}(a_r=a_{r-1})\sup\{f(x):a_{r-1}\leqslant x\leqslant a_r\}$$
Show that $m_n-l_n\to 0$ as $n\to \infty$ and deduce that $f$ is integrable over $[a,b].$\\
\indent Prove that the function $f$ given by 
$$f(x) = [x^3]\quad \text{(the `integer part' of $x^3$)}\quad x\in\mathbb{R}$$
is integrable over any interval $[a,b]$ and find
$$\int_0^{1\tfrac{1}{2}} [x^3]\,dx$$ } %4/10
\solution{If $f$ is an increasing function then $\inf f(x):[a_{r-1},a_r] = f(a_{r-1})$ and $\sup f(x) = f(a_r)$ for any $a_{r-1}<a_r$. Therefore if $P$ divides $[a,b]$ into $n$ equal strips, then
$$l_n = \sum (a_r-a_{r-1})f(a_{r-1}) = \sum \frac{b-a}{n}f(a_r) =\frac{b-a}{n}(f(a_0) + f(a_1) + \dotsb + f(a_{n-1}))$$
and
$$m_n = \sum (a_r-a_{r-1})f(a_r) = \frac{b-a}{n}(f(a_1) + f(a_2) + \dotsb + f(a_n))$$
so that 
$$m_n-l_n = \frac{b-a}{n}(f(b)-f(a)) \to 0$$
as $n\to \infty$. Then all increasing bounded functions on. $[a,b]$ are integrable on $[a,b]$. \\
\indent If $f(x) = [x^3]$ then $f$ is increasing and bounded over any interval. $[a,b]$, so it is integrable. The interval $[0, \tfrac{3}{2}]$ can be divided into $n$ equal parts so that the estimates are 
$$l_n = \sum_{r=1}^n\tfrac{3}{2n}f(a_{r-1}) = \tfrac{3}{2n}(f(0) + f(1\cdot\tfrac{3}{2n}) + \dotsb + f((r-1)\cdot\tfrac{3}{2n}) + \dotsb + f((n-1)\cdot\tfrac{3}{2n}))$$
and 
$$m_n = \sum_{r=1}^n\tfrac{3}{2n}f(a_r)= \tfrac{3}{2n}(f(1\cdot\tfrac{3}{2n}) + f(2\cdot\tfrac{3}{2n})+ \dotsb + f(r\cdot\tfrac{3}{2n}) + \dotsb + f(n\cdot\tfrac{3}{2n}))$$
Now $f(x) = 0$ if $x^3 < 1$ and $f(x) = 1$ if $x^3\geqslant 1$. Then if $(r\cdot\tfrac{3}{2n})^3 <1$ then $f(r\cdot\tfrac{3}{2n}) =0$. This is the case for all $r$ such that $r<\tfrac{2n}{3}$. Hence, assuming $n$ is divisible by 3,
$$\sum_{r=1}^n f(a_r) = f(a_1)+ \dots + f(a_{\frac{2n}{3}}) + \dotsb + f(a_n) = 0 + \dotsb + 1 + \dotsb + 1 = \frac{n}{3}$$
and likewise
$$\sum_{r=1}^n f(a_{r-1}) = f(a_0) + \dots + f(a_{\frac{2n}{3}}) + \dotsb + f(a_{n-1}) = 0 + \dotsb + 1 +\dotsb + 1 =\frac{n}{3} -1$$
Hence 
$$l_n = \frac{3}{2n}(\frac{n}{3}-1) = \frac{1}{2} -\frac{3}{2n}\to  1/2$$
and 
$$m_n = \frac{3}{2n}(\frac{n}{3}) = \frac{1}{2}\to 1/2$$
so that the integral of $f$ is 1/2.}%4/11
\exercise{We saw in the worked example on page 189 that
$$\int_0^1 x^2\, dx = \tfrac{1}{3}$$
Prove that the same function is integrable over $[a,b]$ for any numbers $a$ and $b$ and find
$$\int_a^b x^2\, dx$$} %4/11
\solution{If $0<a<b$ then $f(x)=x^2$ is increasing over $[a,b]$ and therefore integrable. Likewise if $a<b<0$ $f$ is decreasing over $[a,b]$. Then the only case to be considered is $a<0<b$. The lower estimate of the function $f(x) = x^2$ given by a partition of $[a,b]\ni 0$ into $n$ intervals of equal width is
$$l_n = \sum_{r=1}^n (a_r-a_{r-1})\inf\{x^2\mid a_{r-1}\leqslant x\leqslant a_r\}$$
Now for exactly one $a_k = a+\tfrac{k}{n}(b-a)= \tfrac{(n-k)a +kb}{n}$ it is the case $a_{k-1}<0<a_k$ and in this case $\inf\{x^2\mid a_{k-1}<x<a_k\} = 0$. For $r<k$ $\inf\{x^2\mid a_{r-1}<x<a_r\} = a_r^2$ and for $r>k$ the infimum is $a_{r-1}^2$. Then
\begin{align*}
l_n &= \frac{b-a}{n}\sum_{r=1}^n \inf\{x^2\mid\tfrac{(n-(r-1))a+(r-1)b}{n} <x<\tfrac{(n-r)a+rb}{n}\}\\
&= \frac{b-a}{n}\left(\left(\tfrac{(n-1)a+b}{n}\right)^2 + \left(\tfrac{(n-2)a+2b}{n}\right)^2 +\dotsb + \inf\{x^2\mid a_{k-1}<x<a_k\} +\dotsb + \left(\tfrac{(n-(n-1))a+(n-1)b)}{n}\right)^2 \right)\\
&= \frac{b-a}{n}\cdot\frac{1}{n^2}\sum_{r=1}^{n-1}((n-r)a+rb)^2\\
&=\frac{b-a}{n^3}\left(a^2\sum_{r=1}^{n-1}(n-r)^2 +2ab\sum_{r=1}^{n-1}r(n-r) +b^2\sum_{r=1}^{n-1}r^2\right)\\
&=\frac{b-a}{n^3}\cdot\left((a^2+b^2)\tfrac{1}{6}(n-1)(n)(2n-1) + 2ab\left[n(n-1)(n)\tfrac{1}{2} - \tfrac{1}{6}(n-1)(n)(2n-1)\right]\right)\\
&= \frac{b-a}{n^3}\cdot\left((a^2+b^2)(\tfrac{n^3}{3}+\dotsb) + 2ab(\tfrac{n^3}{2}-\tfrac{n^3}{3}+\dotsb)\right)\\
&\to (b-a)[(a^2+b^2)\tfrac{1}{3} + 2ab\tfrac{1}{6}] = \frac{(b-a)(a^2+b^2+ab)}{3} = \frac{b^3-a^3}{3}
\end{align*}
The upper estimates are 
\begin{align*}
m_n &= \frac{(b-a)}{n}\sum_{r=1}^n\sup\{x^2\mid\frac{r-1}{n}(b-a)<x<\frac{r}{n}(b-a)\} \\
&\to \frac{b^3-a^3}{3}
\end{align*}
so that 
$$\int_a^b x^2\, dx = \frac{b^3-a^3}{3}$$}%4/13 fixed with help from discord
\exercise{Let $f$ be a function which is integrable over $[a,b]$ and let $g$ be the function $-f$; i.e. $g(x) = -f(x)$ for each $x$. Let $L$ and $M$ be the usual sets of under- and over-estimates of the integral of $f$ over $[a,b]$ and let $L'$ and $M'$ be the corresponding sets for $g$. Show that 
\begin{align*}
\text{(i) }& l\in L \text{ if and only if } -l\in M';\\
\text{(ii) }& m\in M\text{ if and only if } -m\in L';\\
\text{(iii) }& g\text{ is integrable over $[a,b]$ with}
\end{align*}
$$\int_a^b (-f) = \int_a^b g= -\int_a^b f$$} %4/12
\solution{(i) First note that if $g(x) = -f(x)$ then
$$\sup\{g(x)\} = \sup\{-f(x)\} = -\inf\{f(x)\}$$
If $l$ is an under-estimate for the integral of $f$ corresponding to the partition $P$, then
$$l = \sum_{r=1}^n (a_r-a_{r-1})\inf\{f(x)\mid a_{r-1}\leq x\leq a_r\}$$
and $-l$ is
\begin{align*}
-l &= \sum_{r=1}^n (a_r-a_{r-1})(-1)\inf\{f(x)\mid a_{r-1}\leq x\leq a_r\}\\
&= \sum_{r=1}^n (a_r-a_{r-1})\sup\{g(x)\mid a_{r-1}\leq x\leq a_r\} 
\end{align*}
and so $-1\in M'$. If $-1\in M'$ then
$$-(-l) = -\sum\sup\{g(x)\}\Delta x = \sum\inf\{-g(x)\}\Delta x = \sum\inf\{f(x)\}\Delta x = l\in L$$
\indent (ii) The same logic applies: if $m\in M$. then
$$-m = -\sum\sup\{f(x)\}\Delta x = \sum\inf\{-f(x)\}\Delta x = \sum\inf\{g(x)\}\Delta x = l' \in L'$$
and the converse. \\
\indent (iii) If $f$ is integrable over $[a,b]$ then 
$$\sup L =\alpha =  \inf M$$
but $\alpha \geqslant l\in L$ means that $-\alpha \leqslant -m\in M'$ so that 
$$-\alpha = \inf M'$$
and part (ii) shows that $\alpha \leqslant m\in M$ if and only if $-\alpha \geqslant m'\in  M'$ which shows
$$-\alpha = \inf M'$$
To recapitulate,
$$\sup L' = -\alpha = \inf M'$$
and 
$$\int_a^b g = -\int_a^b f$$}%4/12

\newpage
\chapter{An even more familiar area}
\exercise{(page 217) (Integration by parts.) For differentiable functions $f$ and $g$ with domain $[a,b]$ let the function $F$ be given by
$$F(x) = f(x)g(x) - \int_a^xf'g \quad x\in[a,b]$$
Show that $F$ is an indefinite integral of $fg'$ and deduce that 
$$\int_a^b fg' = \big[f(x)g(x)\big]_a^b - \int_a^b f'g$$
Hence evaluate
$$\text{(i) } \int^{\pi/2}_0 x\sin x\, dx\quad \text{(ii) }\int_1^e \log x\, dx\quad \text{(iii) }\int_0^{\pi/2}e^x\sin x\, dx$$} %4/15
\solution{First the derivative of $\int_a^x f'g$ is
$$\lim_{x\to x_0} \frac{\int_a^xf'g-\int_a^{x_0}f'g}{x-x_0} = \lim_{x\to x_0} \frac{\int_a^xf'g +\int_{x_0}^a f'g}{x-x_0} = \lim_{x\to x_0}\frac{1}{x-x_0}\int_{x_0}^x f'g$$
But
$$(x-x_0)\,\underset{[x_0,x]}{\inf (f'g)} \leqslant \int_{x_0}^x f'g \leqslant (x-x_0)\,\underset{[x_0,x]}{\sup (f'g)}$$
so that 
$$f'(x_0)g(x_0) \leqslant \lim_{x\to x_0} \frac{1}{x-x_0}\int_{x_0}^xf'g \leqslant f'(x_0)g(x_0)$$
and 
$$\frac{d}{dx}\int_a^x f'g = f'g$$
Then the derivative of $F(x)$ is
$$F'(x) = f'(x)g(x) + f(x)g'(x) - f'(x)g(x) = f(x)g'(x)$$
so that $F$ is an indefinite integral of $fg'$ and $F(x) = \int_a^xfg' +k$. Taking $x=a$ shows that
$$F(a) = f(a)g(a) - \int_a^af'g = f(a)g(a) = \int_a^afg' + k = 0+k$$
so that
\begin{align*}
\int_a^b fg' &= F(b)-k \\
&= f(b)g(b) - \int_a^bf'g - f(a)g(a) \\
&= \big[f(x)g(x)\big]_a^b - \int_a^bf'g
\end{align*}
\indent (i) The integral of $x\sin x$ with $f(x) =x$ and $g(x) = \sin x$ evaluates to
$$\int_0^{\pi/2}x\sin x\, dx = \big[x\sin x\big]_a^b - \int_0^{\pi/2}\sin x\, dx = \frac{\pi}{2} - (-\cos\frac{\pi}{2} +\cos 0) = \frac{\pi}{2}-1$$
\indent (ii) With $f(x) = \log x$ and $g(x) = x$,
\begin{align*}
\int_1^e \log x\, dx &= \big[x\log x \big]_1^e - \int_1^e 1\,dx \\
&= e\log e - 0 - (e-1) \\
&= 1
\end{align*}
\indent (iii) With $f(x) = e^x$ and $g(x) = -\cos x$,
\begin{align*}
\int_0^{\pi/2} e^x\sin x &= \big[e^x\cos x\big]_0^{\pi/2} - \int_0^{\pi/2}e^x(-\cos x) \\
&= - 1 +\int_0^{\pi/2}e^x(\cos x)\\
\int_0^{\pi/2}e^x(\cos x) &= \big[e^x(\sin x)\big]_0^{\pi/2} - \int_0^{\pi/2}e^x(\sin x) \\
&= e^{\pi/2} - \int_0^{\pi/2}e^x(\sin x)
\end{align*}
so that 
$$2\int_0^{\pi/2}e^x \sin x = -1 +e^{\pi/2}$$
and 
$$\int_0^{\pi/2}e^x(\sin x) = \frac{e^{\pi/2} - 1}{2}$$}%4/15
\exercise{(Integration by substitution.) Let $g$ be a differentiable function with domain $[a,b]$ and which has a continuous derivative $g'$. Let $f$ be a continuous function such that the composite function $f\circ g$ is well defined for each $x\in[a,b]$. Show that
$$\int_a^b (f\circ g) \times g' = \int_{g(a)}^{g(b)} f$$
(Using the fuller `dx' notation and putting $g(x) = u$ would give
\begin{align*}
\int_a^bf(g(x))\times g'(x)\, dx &= \int_{(x=)a}^b f(g(x))\frac{du}{dx}dx\\
&=\int_{(u=)g(a)}^{g(b)}f(u)\, du
\end{align*}
which once again looks very algebraically `natural'.)
Use this method to find indefinite integrals of
$$\text{(i) }2x\sin x^2 \quad \text{(ii) } \frac{e^x}{1+e^{2x}}\quad \text{(iii) }\tan x\left(x\in\left(-\frac{\pi}{2},\frac{\pi}{2}\right)\right)$$} %4/17
\solution{An indefinite integral of $f$ is $F$ where
$$F(x) = \int_{a}^x f + k$$
for some constant $k$. Then the function $F$ corresponding to the limits $g(a), g(b)$ is
$$F(g(x)) = \int_{g(a)}^{g(x)} f +k$$
However the derivative of $F(g(x))$ is also $f(g(x))g'(x)$, so 
$$F(g(x)) = \int_a^x (f\circ g)\times g' + k$$
and since $k = F(g(a))$, for $x=b$ this is 
$$F(g(b))-F(g(a)) = \int_{g(a)}^{g(b)}f = \int_a^b(f\circ g)\times g'$$
\indent (i) Using $g(x) = x^2$, and taking $a$ to be 0,
$$\int_a^x 2x\sin x^2 = \int_{0^2}^{x^2} \sin x = -\cos x^2 + k$$
\indent (ii) Taking $f(x) = \tfrac{1}{1+x^2}$ and $g(x) = e^x$, then
$$\int_a^x \frac{e^x}{1+e^{2x}} = \int_{e^a}^{e^x} \frac{1}{1+x^2} = [\tan^{-1}x]^{e^x}_1 + k = \tan^{-1}e^x - \frac{\pi}{4} + k$$
so the integral $\int \frac{e^x}{1+e^{2x}} = \tan^{-1}e^x +k$. \\
\indent (iii) $\tan = \sin/\cos$ so with $f(x) = -1/x$ and $g(x)= \cos x$,
$$\int \tan x = \int \frac{\sin x}{\cos x} = -\int_{\cos a}^{\cos x} \frac{1}{x} = -\log \cos x + k $$
which is equivalent to $\log \sec x + k$.}%4/23
\exercise{(Improper integrals.) Our definition of an integral was for a bounded function over a closed bounded interval. We can extend this idea to other intervals and unbounded functions in the following sorts of ways, giving rise to the so-called 'improper integrals'\\
E.g. $\int_a^b f$ for an $f$ bounded on $[a,x]$ for each $x\in [a,b)$ but not on $[a,b]$: let 
$$F(x) =\int_a^x f \quad x\in [a,b)$$
Then we say that $\int_a^bf$ exists if and only if $\lim_{a\to b} F(x)$ exists, and in that case the value of the integral is defined to be that limit. \\
e.g. $\int_a^\infty f$ exists if and only if $\lim_{x\to \infty} F(x)$ exists, and in that case the value of the integral is defined to be that limit. \\
\indent Decide whether the following improper integrals exist and evaluate those which do:
$$\text{(i) } \int_0^1 \frac{1}{\sqrt{1-x^2}}\, dx\quad \text{(ii) } \int_0^\infty \frac{x}{(1+x^2)^2}\, dx\quad \text{(iii) } \int_0^1\frac{1}{x}\, dx$$} %4/23
\solution{(i)
$$\lim_{x\to 1} \int_0^x \frac{1}{\sqrt{1-x^2}} = \lim_{x\to 1} \sin^{-1} x = \frac{\pi}{2} $$
\indent (ii)
$$\int_0^\infty \frac{x}{(1+x^2)^2} = \lim_{x\to\infty} -\frac{1}{2}(1+x^2)^{-1}+ \frac{1}{2} = \frac{1}{2}$$
\indent (iii) 
$$\lim_{x\to 0} \int_x^1 \frac{1}{x} = \lim_{x\to 0} \log 1 - \log x = \lim_{x\to0} \log \frac{1}{x} $$
which does not converge (tends to infinity).}%4/23 [reviewed 8/20, fixed ii)]

\exercise{(The intergral test for the convergence of series.) Let $f$ be a decreasing function with domain $[1,\infty)$ and with $f(x) \geqslant 0$ for each $x\geqslant 1.$ For each positive integer $n$ let 
$$x_n = f(1) + f(2) + f(3) + \dotsb + f(n-1) - \int_1^n f$$
Follow the techniques employed on pages 47-8 to show that the sequence $(x_n)$ is increasing and bounded above and hence convergent. Deduce that the series 
$$f(1) + f(2) + f(3) + \dotsb$$
converges if and only if the integral
$$\int_1^\infty f$$
exists.\\
\indent Use that result (or a slightly modified form of it) to test the convergence of the following series:
\begin{align*}
\text{(i) } & \sum_{n=1}^\infty \frac{1}{\sqrt n} &\text{(ii) }& \sum_{n=2}^\infty \frac{1}{n\log n} \\
\text{(iii) } & \sum_{n=3}^\infty \frac{1}{n\log n\log(\log n)} & \text{(iv) }& \sum_{n=2}^\infty \frac{1}{n(\log n)^2}
\end{align*}} %4/24
\solution{The number $f(1) + f(2) + f(3) + \dotsb + f(n-1)$ is the area of the rectangles of width one with the upper left corner touching the curve $f$ between $x=1$ and $x=n$. The number $\int_1^n$ is the area under the curve from $x=1$ to $x=n$. Then the sequence $x_n = f(1) + f(2) + \dots f(n-1) - \int_1^n f$ is increasing because $x_n = x_{n-1} + (f(n-1)  - \int_{n-1}^n f)$ and $f$ is decreasing, so the area under the curve is less than the area of the rectangle that touches $f$ on its left side. So $x_{n-1} < x_n$. The sequence is bounded above by $f(1)$ since all the differences of areas can fit in a rectangle with height $f(1)$ and width 1. Therefore the sequence $x_n$ converges. \\
\indent Since $x_n$ converges and $x_n$ is the sum of the series $f(1) + f(2) + f(3) + \dotsb$ and the integral, either both the series and the integral converge or they both diverge. Therefore the series converges if and only if the integral exists. \\
\indent (i) $x_n = \sum_{n=1}^\infty \frac{1}{\sqrt n}$ converges if and only if $\lim_{n\to\infty}\int_1^n \frac{1}{\sqrt t} \, dt$ exists. This evaluates to 
$$\lim_{n\to\infty} [2\sqrt{t}]_1^n = \lim_{n\to\infty} 2(\sqrt n - \sqrt 1)$$
which diverges, so the sum diverges. \\%6/25 5:20 AM 
\indent (ii) The integral can be solved by substituting $u = \log n$, and it evaluates to 
$$\int \frac{1}{t\log t} = \log (\log t)$$
so that 
$$\lim_{n\to \infty} \int_2^n \frac{1}{t\log t}\, dt = \lim_{n\to\infty} \left[\log (\log t)\right]_2^n $$
\indent As $n$ tends to infinity, $\log (\log n)$ tends to infinity also. So the limit tends to infinity and the series diverges. \\ %7/5
\indent (iii) Substituting $u = \log(\log n)$ simplifies the integral to 
$$\int_3^\infty \frac{1}{n\log n \log (\log n)} \, dn = \int_{\log (\log 3)}^{\infty} \frac{1}{u}\, du = \lim_{n\to \infty} \log (\log (\log n)) - \log(\log(\log 3)) $$
which tends to infinity, so the series diverges. \\
\indent (iv) Substituting $u= 1/\log n$, the integral is
$$\int_2^\infty \frac{1}{n(\log n)^2} \, dn= \int_2^\infty -u^2 \, du= \left[-u\right]_2^\infty = \lim_{n\to\infty} -\frac{1}{\log n} + \frac{1}{\log 2}$$
The integral evaluates to $1/\log 2$, so the series converges.}%7/7 [reviewed 8/20] 

\exercise{(An alternative form of the error term in a Taylor series.) Let $f$ be differentiable more than $n$ times on some interval containing 0 and $x$.  Prove by induction on $n$ that 
\begin{align*}
f(x) = &f(0) + xf'(0) + \frac{x^2}{2!}f''(0) + \dotsb + \frac{x^n}{n!}f^{(n)}(0) \\
&+ \frac{1}{n!} \int_0^x (x-t)^nf^{(n+1)}(t) \, dt
\end{align*}
Hence show that for each $x \in (-1, 1]$ the difference between 
$$\log (1+x)\text{\quad and \quad} x-\frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dotsb \pm \frac{x^n}{n}$$
converges to 0 as $n\to \infty$ (i.e. the Taylor series about $x=0$ of $\log (1+x)$ converges to $\log(1+x)$ for $x\in (-1,1])$.} %6/21
\solution{Integration by parts shows that 
\begin{align*}
\frac{1}{n!}\int_0^x(x-t)^nf^{(n+1)}(t)\, dt &= \frac{1}{n!}(x-t)^{n}f^{n}(t)\Big\rvert_0^x + \frac{1}{(n-1)!}\int_0^x (x-t)^{n-1} f^{(n)}(t)\, dt\\
&= -\frac{x^n}{n!}f^{(n)}(x) - \int_0^x (x-t)^{n-1}f^{(n)}(t)\, dt
\end{align*}
When $n=0$, the integral is
$$\int_0^xf'(t)\, dt = f(x) - f(0)$$
so the above equality is true by induction. \\
\indent For $f(x) = \log (1+x)$, the equation is 
$$\log (1+x) = \left(x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dotsb \pm \frac{x^n}{n}\right) + \frac{1}{n!}\int_0^x(x-t)^n \frac{d^{n+1}\log(t+1)}{dt^{n+1}}\, dt$$
\indent Then the integral is the difference between $\log(1+x)$ and the Taylor series around $x=0$. The $n$th derivative of $\log(t+1)$ is $(-1)^{n-1}(n-1)!(t+1)^{-n}$, so as $n$ goes to infinity, the integral is
$$\lim_{n\to \infty} \frac{1}{n!}\int_0^x (x-t)^n (-1)^{n}n!\frac{1}{(t+1)^{n+1}}\, dt = \lim_{n\to \infty} (-1)^n\int_0^x\left(\frac{1}{t+1}\right)\left(\frac{x-t}{t+1}\right)^n\, dt$$
\indent When $x\in (-1, 1]$, the magnitude of the expression $(x-t)/(t+1)$ is less than one and as $n\to \infty $ the integral tends to 0. Then the Taylor series of $\log(x+1)$ converges to $\log(x+1)$ for those $x$.}%7/8 [reviewed 8/20]

\exercise{(Integration of power series.) Show that if the power series 
$$a_0 + a_1x + a_2 x^2 + a_3 x^3 + \dotsb$$
converges to $f(x)$ for $x\in(-r, r)$ then the `integrated' series
$$a_0x + \tfrac{1}{2}a_1x^2 +\tfrac{1}{3}a_2x^3 + \tfrac{1}{4}a_3x^4 + \dotsb$$
converges for each $x\in(-r, r)$ and its sum is $F(x)$ where $F$ is an indefinite integral of $f$. \\
\indent Hence show that 
$$\tan^{-1} x = x-\frac{x^3}{3} + \frac{x^5}{5} -\frac{x^7}{7} + \dotsb \quad x\in(-1,1)$$ 
and deduce that 
$$\pi = 4(1-\tfrac{1}{3} + \tfrac{1}{5} - \tfrac{1}{7} + \dotsb)$$} %6/21 
\solution{If $a_0 + a_1x + a_2 x^2 + a_3 x^3 + \dots \to f(x)$ then $a_0x + \tfrac{1}{2}a_1x ^2 + \tfrac{1}{3} a_2x^3 + \tfrac{1}{4} a_3x^4 + \dotsb = \int_0^x f(x) - F(0)$. Since $a_0x + \frac{1}{2}a_1x^2 + \dotsb + \frac{1}{n+1}a_nx^{n+1} = \int_0^x a_0 + a_1x + \dots + a_nx^n$ it holds by induction on $n$ that $a_0x + \frac{1}{2}a_1 x^2 + \dotsb = \int a_0 + a_1x + \dotsb$. \\
\indent Then since $\tan^{-1} x = \int \frac{1}{1+x^2},$ the taylor series of $\tan^{-1}x$ is equal to the integral of the taylor series for $\frac{1}{1+x^2}$,
$$\frac{1}{1+x^2} = 1 - x^2 + x^4 - x^6 \pm \dotsb $$ 
which is 
$$\tan^{-1} x = \int\frac{1}{1+x^2 } = x - \frac{x^3}{3} + \frac{x^5}{5} - \frac{x^7}{7} \pm \dotsb$$.
The fact that $\tan \frac{\pi}{4} = 1$ gives the desired result
$$ \tan^{-1} 1 = 1 - \frac{1}{3} + \frac{1}{5} -\frac{1}{7} + \dotsb$$
$$ \frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} -\frac{1}{7} + \dotsb$$
$$\pi = 4\left(1 - \frac{1}{3} + \frac{1}{5} -\frac{1}{7} + \dotsb\right)$$} %8/14 [reviewed 8/18 (review again after finishing notes)]

\exercise{(The irrationality of $\pi$.) Assume that $\pi$ is the rational $M/N$ where $M$ and $N$ are positive integers. Let $k$ be a positive integer with $N^k\pi^{2k+1}/k!$ less than 1 (how do we know that such a $k$ exists?) and let $f$ be the function given by 
$$f(x) = \frac{N^k}{k!} x^k(x-\pi)^k \quad x\in [0,\pi]$$
\indent (i) Show that $f$ and all its derivatives have integer values at $x=0$ and at $x=\pi$. \\
\indent (ii) Prove that $$0 < \int_0^\pi f(x)\sin x\, dx < 1$$ \\
\indent (iii) By repeatedly integrating by parts show that 
$$\int_0^\pi f(x)\sin x \, dx$$
is an integer.\\
\indent Deduce that $\pi$ is irrational. } %6/21
\solution{(i) Using the product rule, we can write 
$$f'(x) = g'(x)h(x) + g(x)h'(x)$$
where $g(x) = \frac{N^k}{k!}$ and $h(x) = (x-\pi)^k$. However any non-constant derivative of $g(x)$ is 0 at $x = 0$ and similarly any non-constant derivative of $h(x)$ is 0 at $x=\pi$. The first constant derivatives of $f$ and $g$ are the $k$th derivative, so
\begin{align*}
f^{(k)}(x) &= g^{(k)}(x) h(x) + \dotsb + g(x)h^{(k)}(x) \\
&= N^k(x-\pi)^k + \dotsb + N^k x^k
\end{align*}
where the terms that evaluate to zero at $x=0$ or $x=\pi$ are omitted. Then 
$$f^{(k)}(0) = N^k(-\pi)^k \text{\quad and \quad} f^{(k)}(\pi) = N^k\pi^k.$$ 
\indent By assumption $\pi = M/N$, so $f^{(k)}(0) = - f^{(k)}(\pi) = M^k$ which is an integer. \\
\indent (ii) For $0 < x < \pi$, $\sin(x) \leq 1$ and 
\begin{align*}
f(x) &= \frac{N^k}{k!} x^k(x-\pi)^k \\
&< \frac{N^k}{k!} \pi^k \pi^k \\
&= \frac{N^k}{k!} \pi^{2k+1} \cdot \frac{1}{\pi} \\
&< 1 \cdot \frac{1}{\pi}
\end{align*} 
so that 
$$\int_0^\pi f(x)\sin(x) < \int_0^\pi\frac{1}{\pi} = \frac{x}{\pi}\Big\vert_0^\pi = 1 $$
\indent Then since $f(x)\sin x$ has some non-zero ranges between $[0,\pi]$ the result is $0 < \int_0^\pi f(x)\sin x < 1$. \\
\indent (iii) Integration by parts with $u = f(x)$ and $dv = \sin x$ shows that 
$$\int_0^\pi f(x)\sin x\, dx = f(x)(-\cos x) \Big\vert_0^\pi - \int_0^\pi f'(x)(-\cos x) \, dx$$
and 
$$\int_0^\pi f'(x)(-\cos x)\, dx = f'(x)(-\sin x)\Big\vert_0^\pi - \int_0^\pi f''(x)(-\sin x)\, dx$$
\indent The fact that the derivatives of $f$ at $x=0$ and $x=\pi$ are integers, showed in (i), and that $\cos0 = 1, \cos\pi = -1, \sin 0 = \sin \pi = 0$ means that all of the terms of the integral are integer valued. Therefore the integer evaluates to an integral. \\
\indent However, (ii) showed that $0 < \int_0^\pi f(x)\sin x < 1$, but there are no integers between 0 and 1. This is a contradiction, so the conclusion is $\pi$ is irrational.}%8/17 [reviewed 8/18] 

\end{document} 
